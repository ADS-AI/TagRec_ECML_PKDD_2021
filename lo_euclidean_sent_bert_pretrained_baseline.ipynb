{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lo_euclidean_sent_bert_pretrained_baseline.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jm5lKps5G_RO",
        "outputId": "4bc391ec-7053-4fab-81bb-0f6b52555127"
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "import torch\n",
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQyDg--XHHaK",
        "outputId": "0402f260-1f9d-407f-e527-11c1c0b4e07a"
      },
      "source": [
        "!pip install sentence-transformers==0.2.6.1\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentence-transformers==0.2.6.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/46/b7d6c37d92d1bd65319220beabe4df845434930e3f30e42d3cfaecb74dc4/sentence-transformers-0.2.6.1.tar.gz (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 5.4MB/s \n",
            "\u001b[?25hCollecting transformers>=2.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b5/d5/c6c23ad75491467a9a84e526ef2364e523d45e2b0fae28a7cbe8689e7e84/transformers-4.8.1-py3-none-any.whl (2.5MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5MB 11.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==0.2.6.1) (4.41.1)\n",
            "Requirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==0.2.6.1) (1.9.0+cu102)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==0.2.6.1) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==0.2.6.1) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==0.2.6.1) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==0.2.6.1) (3.2.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.8.0->sentence-transformers==0.2.6.1) (2019.12.20)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers>=2.8.0->sentence-transformers==0.2.6.1) (3.13)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers>=2.8.0->sentence-transformers==0.2.6.1) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=2.8.0->sentence-transformers==0.2.6.1) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers>=2.8.0->sentence-transformers==0.2.6.1) (20.9)\n",
            "Collecting huggingface-hub==0.0.12\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/ee/97e253668fda9b17e968b3f97b2f8e53aa0127e8807d24a547687423fe0b/huggingface_hub-0.0.12-py3-none-any.whl\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 50.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers>=2.8.0->sentence-transformers==0.2.6.1) (4.5.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 47.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.1->sentence-transformers==0.2.6.1) (3.7.4.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers==0.2.6.1) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers==0.2.6.1) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=2.8.0->sentence-transformers==0.2.6.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=2.8.0->sentence-transformers==0.2.6.1) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=2.8.0->sentence-transformers==0.2.6.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=2.8.0->sentence-transformers==0.2.6.1) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers>=2.8.0->sentence-transformers==0.2.6.1) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=2.8.0->sentence-transformers==0.2.6.1) (7.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers>=2.8.0->sentence-transformers==0.2.6.1) (3.4.1)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-0.2.6.1-cp37-none-any.whl size=74032 sha256=ee4dddb16cffc1ce301c82f08bdf323360fe0fabcc239db2b5aa93595aea1ba5\n",
            "  Stored in directory: /root/.cache/pip/wheels/d7/fa/17/2b081a8cd8b0a86753fb0e9826b3cc19f0207062c0b2da7008\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: huggingface-hub, sacremoses, tokenizers, transformers, sentence-transformers\n",
            "Successfully installed huggingface-hub-0.0.12 sacremoses-0.0.45 sentence-transformers-0.2.6.1 tokenizers-0.10.3 transformers-4.8.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNS3eYtGUDzB",
        "outputId": "347a54d9-d14a-4a44-9bb8-f714433aa498"
      },
      "source": [
        "!pip install tensorflow==1.13.1\n",
        "! pip install tensorflow-hub==0.7.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.13.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/29/6b4f1e02417c3a1ccc85380f093556ffd0b35dc354078074c5195c8447f2/tensorflow-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (92.6MB)\n",
            "\u001b[K     |████████████████████████████████| 92.6MB 47kB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.8.1)\n",
            "Collecting tensorboard<1.14.0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 42.9MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 45.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (3.12.4)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.19.5)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.36.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.34.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.3.4)\n",
            "Collecting mock>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/03/b7e605db4a57c0f6fba744b11ef3ddf4ddebcada35022927a2b5fc623fdf/mock-4.0.3-py3-none-any.whl\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.13.1) (57.0.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.1) (3.1.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (4.5.0)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.13.1) (1.5.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.4.1)\n",
            "\u001b[31mERROR: kapre 0.3.5 has requirement tensorflow>=2.0.0, but you'll have tensorflow 1.13.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, mock, tensorflow-estimator, keras-applications, tensorflow\n",
            "  Found existing installation: tensorboard 2.5.0\n",
            "    Uninstalling tensorboard-2.5.0:\n",
            "      Successfully uninstalled tensorboard-2.5.0\n",
            "  Found existing installation: tensorflow-estimator 2.5.0\n",
            "    Uninstalling tensorflow-estimator-2.5.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
            "  Found existing installation: tensorflow 2.5.0\n",
            "    Uninstalling tensorflow-2.5.0:\n",
            "      Successfully uninstalled tensorflow-2.5.0\n",
            "Successfully installed keras-applications-1.0.8 mock-4.0.3 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0\n",
            "Collecting tensorflow-hub==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/0e/a91780d07592b1abf9c91344ce459472cc19db3b67fdf3a61dca6ebb2f5c/tensorflow_hub-0.7.0-py2.py3-none-any.whl (89kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 6.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-hub==0.7.0) (3.12.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-hub==0.7.0) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-hub==0.7.0) (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.4.0->tensorflow-hub==0.7.0) (57.0.0)\n",
            "Installing collected packages: tensorflow-hub\n",
            "  Found existing installation: tensorflow-hub 0.12.0\n",
            "    Uninstalling tensorflow-hub-0.12.0:\n",
            "      Successfully uninstalled tensorflow-hub-0.12.0\n",
            "Successfully installed tensorflow-hub-0.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nm1Gp0CHKuX",
        "outputId": "60d69c4d-6956-491c-ad94-f4e35979b99a"
      },
      "source": [
        "!pip install transformers==2.8.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==2.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\r\u001b[K     |▋                               | 10kB 23.6MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20kB 20.3MB/s eta 0:00:01\r\u001b[K     |█▊                              | 30kB 16.7MB/s eta 0:00:01\r\u001b[K     |██▎                             | 40kB 15.5MB/s eta 0:00:01\r\u001b[K     |███                             | 51kB 7.2MB/s eta 0:00:01\r\u001b[K     |███▌                            | 61kB 8.5MB/s eta 0:00:01\r\u001b[K     |████                            | 71kB 8.9MB/s eta 0:00:01\r\u001b[K     |████▋                           | 81kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 92kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 102kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 112kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 122kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 133kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 143kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 153kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 163kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 174kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 184kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 194kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 204kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 215kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 225kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 235kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 245kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 256kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 266kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 276kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 286kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 296kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 307kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 317kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 327kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 337kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 348kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 358kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 368kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 378kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 389kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 399kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 409kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 419kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 430kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 440kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 450kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 460kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 471kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 481kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 491kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 501kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 512kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 522kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 532kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 542kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 552kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 563kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 573kB 7.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (2019.12.20)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/de/807c75923e84530b8a94003d761bcea33ebd5469b3d56c1141208360f39f/boto3-1.17.101-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 55.7MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/aa/1437691b0c7c83086ebb79ce2da16e00bef024f24fec2a5161c35476f499/sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 42.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (1.19.5)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/e3/5e49e9a83fb605aaa34a1c1173e607302fecae529428c28696fb18f1c2c9/tokenizers-0.5.2-cp37-cp37m-manylinux1_x86_64.whl (5.6MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6MB 18.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (4.41.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (0.0.45)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting s3transfer<0.5.0,>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/d0/693477c688348654ddc21dcdce0817653a294aa43f41771084c25e7ff9c7/s3transfer-0.4.2-py2.py3-none-any.whl (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.7MB/s \n",
            "\u001b[?25hCollecting botocore<1.21.0,>=1.20.101\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/01/76/f67a56460eba1997dd89b6b34b68150da1cf8cba0f5161cc4326383b4240/botocore-1.20.101-py2.py3-none-any.whl (7.7MB)\n",
            "\u001b[K     |████████████████████████████████| 7.7MB 39.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.101->boto3->transformers==2.8.0) (2.8.1)\n",
            "\u001b[31mERROR: botocore 1.20.101 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3, sentencepiece, tokenizers, transformers\n",
            "  Found existing installation: tokenizers 0.10.3\n",
            "    Uninstalling tokenizers-0.10.3:\n",
            "      Successfully uninstalled tokenizers-0.10.3\n",
            "  Found existing installation: transformers 4.8.1\n",
            "    Uninstalling transformers-4.8.1:\n",
            "      Successfully uninstalled transformers-4.8.1\n",
            "Successfully installed boto3-1.17.101 botocore-1.20.101 jmespath-0.10.0 s3transfer-0.4.2 sentencepiece-0.1.96 tokenizers-0.5.2 transformers-2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "9x_LgbAWHPUL",
        "outputId": "a78d22a3-c00c-42e3-8801-0630c576136b"
      },
      "source": [
        "import pandas as pd\n",
        "lo_data = pd.read_csv(\"what_you_learnt_lo_labelled.csv\", delimiter=\"|\")\n",
        "lo_data\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>learning_objectives</th>\n",
              "      <th>taxonomy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A complete chemical equation represents the re...</td>\n",
              "      <td>science&gt;&gt;chemical reactions and equations</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A chemical equation is balanced so that the nu...</td>\n",
              "      <td>science&gt;&gt;chemical reactions and equations</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In a combination reaction two or more substanc...</td>\n",
              "      <td>science&gt;&gt;chemical reactions and equations</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Decomposition reactions are opposite to combin...</td>\n",
              "      <td>science&gt;&gt;chemical reactions and equations</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Reactions in which heat is given out along wit...</td>\n",
              "      <td>science&gt;&gt;chemical reactions and equations</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>412</th>\n",
              "      <td>Pollutants are the substances which contaminat...</td>\n",
              "      <td>science&gt;&gt;pollution of air and water</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413</th>\n",
              "      <td>Carbon monoxide nitrogen oxides carbon dioxide...</td>\n",
              "      <td>science&gt;&gt;pollution of air and water</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>414</th>\n",
              "      <td>Increasing levels of greenhouse gases like CO ...</td>\n",
              "      <td>science&gt;&gt;pollution of air and water</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>Water pollution is the contamination of water ...</td>\n",
              "      <td>science&gt;&gt;pollution of air and water</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416</th>\n",
              "      <td>Water which is purified and fit for drinking i...</td>\n",
              "      <td>science&gt;&gt;pollution of air and water</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>417 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   learning_objectives                                   taxonomy\n",
              "0    A complete chemical equation represents the re...  science>>chemical reactions and equations\n",
              "1    A chemical equation is balanced so that the nu...  science>>chemical reactions and equations\n",
              "2    In a combination reaction two or more substanc...  science>>chemical reactions and equations\n",
              "3    Decomposition reactions are opposite to combin...  science>>chemical reactions and equations\n",
              "4    Reactions in which heat is given out along wit...  science>>chemical reactions and equations\n",
              "..                                                 ...                                        ...\n",
              "412  Pollutants are the substances which contaminat...        science>>pollution of air and water\n",
              "413  Carbon monoxide nitrogen oxides carbon dioxide...        science>>pollution of air and water\n",
              "414  Increasing levels of greenhouse gases like CO ...        science>>pollution of air and water\n",
              "415  Water pollution is the contamination of water ...        science>>pollution of air and water\n",
              "416  Water which is purified and fit for drinking i...        science>>pollution of air and water\n",
              "\n",
              "[417 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGgcEhdyJtLS"
      },
      "source": [
        "test_features = lo_data[\"learning_objectives\"]\n",
        "test_labels = lo_data[\"taxonomy\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gQk4flGJziL",
        "outputId": "c9bf4f00-d9a8-441d-f0c6-bf9a869b30de"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "!pip install inflection\n",
        "\n",
        "from bokeh.io import output_file, output_notebook, show\n",
        "from bokeh.plotting import figure\n",
        "from bokeh.transform import linear_cmap\n",
        "from bokeh.util.hex import hexbin\n",
        "from bokeh.models import HoverTool\n",
        "from bokeh import colors\n",
        "import inflection\n",
        "\n",
        "from nltk.stem import PorterStemmer \n",
        "ps = PorterStemmer()\n",
        "from gzip import open as gopen\n",
        "from pandas.core.common import flatten\n",
        "import gensim.models.poincare as poincare\n",
        "def get_cleaned_taxonomy(taxonomy):\n",
        "  cleaned_taxonomy = []\n",
        "  for value in taxonomy:\n",
        "      value = ' '.join(value.split(\"_\"))\n",
        "      # taxonomy_words = [inflection.singularize(val)  for token in value for val in token.split(\" \") if val.isalpha()]\n",
        "      cleaned_taxonomy.append( value )\n",
        "  return cleaned_taxonomy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting inflection\n",
            "  Downloading https://files.pythonhosted.org/packages/59/91/aa6bde563e0085a02a435aa99b49ef75b0a4b062635e606dab23ce18d720/inflection-0.5.1-py2.py3-none-any.whl\n",
            "Installing collected packages: inflection\n",
            "Successfully installed inflection-0.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzKemSOeJznt",
        "outputId": "9388e838-7545-4df2-eb24-f9301dabc537"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer('bert-large-nli-stsb-mean-tokens')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "100%|██████████| 1.24G/1.24G [01:04<00:00, 19.4MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wf-zhy4jNidu",
        "outputId": "b53e6d00-f557-4aae-d195-dc7e542f4f7c"
      },
      "source": [
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentenceTransformer(\n",
              "  (0): BERT(\n",
              "    (bert): BertModel(\n",
              "      (embeddings): BertEmbeddings(\n",
              "        (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
              "        (position_embeddings): Embedding(512, 1024)\n",
              "        (token_type_embeddings): Embedding(2, 1024)\n",
              "        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder): BertEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (2): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (3): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (4): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (5): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (6): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (7): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (8): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (9): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (10): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (11): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (12): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (13): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (14): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (15): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (16): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (17): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (18): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (19): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (20): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (21): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (22): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (23): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (pooler): BertPooler(\n",
              "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (activation): Tanh()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): Pooling()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0zsIiTRPTU7",
        "outputId": "d142a92c-1e3e-4bac-f5fc-4e96aa8cf3e1"
      },
      "source": [
        "test_feature_emb = model.encode(list(test_features.values))\n",
        "test_feature_emb = np.vstack(test_feature_emb)\n",
        "test_feature_emb.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(417, 1024)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_LhMXyJR0ZA",
        "outputId": "13029fb5-d25f-45ee-8e2f-5524f69df596"
      },
      "source": [
        "test_labels = list(set(lo_data[\"taxonomy\"].values))\n",
        "emb_data_test = get_cleaned_taxonomy(test_labels)\n",
        "test_taxonomy_vectors = model.encode(emb_data_test)\n",
        "test_taxonomy_vectors = np.vstack(test_taxonomy_vectors)\n",
        "test_taxonomy_vectors.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(48, 1024)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgswOc-RT2VW"
      },
      "source": [
        "test_labels = np.array(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OsILKscSTQ0",
        "outputId": "bb273bde-42b6-47a6-be09-06a38871ad9f"
      },
      "source": [
        "cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "test_feature_emb = torch.tensor(test_feature_emb, dtype=torch.float)\n",
        "test_taxonomy_vectors = torch.tensor(test_taxonomy_vectors, dtype=torch.float)\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "for test_emb in test_feature_emb:    \n",
        "  distances = cos(test_emb.reshape(1,-1),test_taxonomy_vectors)#torch.topk(cos(outputs,test_poincare_tensor),20,largest=True)\n",
        "  distances,indices = torch.topk(distances,2,largest=True)\n",
        "  predictions.append(test_labels[indices.cpu().numpy()])\n",
        "print(len(predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "417\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5wj2gXYFkrQ"
      },
      "source": [
        "labels=lo_data[\"taxonomy\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOt8hvs-CZfn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ae1bd3c-a66f-4dc3-8a8e-fc55af205c8b"
      },
      "source": [
        "from sklearn .preprocessing import LabelEncoder\n",
        "LE= LabelEncoder()\n",
        "labels = LE.fit_transform(labels)\n",
        "labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
              "        2,  2,  2,  2,  2,  2,  2,  2, 34, 34, 34, 34, 22, 22, 22, 22, 22,\n",
              "       22, 22, 22, 22, 22, 22,  9,  9,  9,  9,  9,  9,  9, 18, 18, 18, 18,\n",
              "       18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 17, 17, 17, 17, 17, 17, 25,\n",
              "       25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 19, 19, 19, 19, 19, 19,\n",
              "       19, 12, 12, 12, 12, 12, 12, 12, 26, 26, 26, 26, 26, 26, 26, 26, 26,\n",
              "       26, 26, 26, 39, 33, 33, 33, 33, 33, 33, 42, 28, 28, 28, 28, 28, 28,\n",
              "       28, 28, 28, 28, 28, 28, 28, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1, 41, 41, 41, 41, 41, 41, 41, 44,\n",
              "       44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 45, 45, 45, 45, 45, 45, 45,\n",
              "       45, 45, 11, 11, 11, 11, 11, 11, 31, 31, 31, 31, 31, 13, 13, 13, 13,\n",
              "       13, 13, 13, 13, 16, 16, 16, 16, 16, 16, 16, 16, 47, 47, 47, 47, 47,\n",
              "       47, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 46, 46, 46,\n",
              "       46, 46, 46, 46, 46, 46, 32, 32, 32, 32, 32, 32, 32, 20, 20, 20, 20,\n",
              "       20, 20, 20, 20, 20, 20, 20, 20, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "       10, 10, 10, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 43,\n",
              "       43, 43, 43, 43, 43, 43, 27, 27, 27, 27, 27, 27, 27, 27, 27,  6,  6,\n",
              "        6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,\n",
              "        8,  8,  8,  3,  3,  3,  3,  3,  3,  3,  3, 36, 36, 36, 36, 36, 36,\n",
              "       36, 36, 36, 36, 36, 36, 36, 36, 36, 14, 14, 14, 14, 14, 14, 14, 14,\n",
              "       14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 38, 38, 38,\n",
              "       38, 38, 38, 38, 38, 38,  4,  4,  4,  4, 37, 37, 37, 37, 37, 37, 37,\n",
              "       37, 23, 23, 23, 23, 23, 23, 24, 23, 40, 40, 40, 40, 40, 40, 40, 40,\n",
              "       40, 40, 40, 35, 35, 35, 35, 35, 35])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adb4gTNgGKUP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87245518-c3cc-4ad5-b996-4aa0480e700d"
      },
      "source": [
        "labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
              "        2,  2,  2,  2,  2,  2,  2,  2, 34, 34, 34, 34, 22, 22, 22, 22, 22,\n",
              "       22, 22, 22, 22, 22, 22,  9,  9,  9,  9,  9,  9,  9, 18, 18, 18, 18,\n",
              "       18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 17, 17, 17, 17, 17, 17, 25,\n",
              "       25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 19, 19, 19, 19, 19, 19,\n",
              "       19, 12, 12, 12, 12, 12, 12, 12, 26, 26, 26, 26, 26, 26, 26, 26, 26,\n",
              "       26, 26, 26, 39, 33, 33, 33, 33, 33, 33, 42, 28, 28, 28, 28, 28, 28,\n",
              "       28, 28, 28, 28, 28, 28, 28, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1, 41, 41, 41, 41, 41, 41, 41, 44,\n",
              "       44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 45, 45, 45, 45, 45, 45, 45,\n",
              "       45, 45, 11, 11, 11, 11, 11, 11, 31, 31, 31, 31, 31, 13, 13, 13, 13,\n",
              "       13, 13, 13, 13, 16, 16, 16, 16, 16, 16, 16, 16, 47, 47, 47, 47, 47,\n",
              "       47, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 46, 46, 46,\n",
              "       46, 46, 46, 46, 46, 46, 32, 32, 32, 32, 32, 32, 32, 20, 20, 20, 20,\n",
              "       20, 20, 20, 20, 20, 20, 20, 20, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "       10, 10, 10, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 43,\n",
              "       43, 43, 43, 43, 43, 43, 27, 27, 27, 27, 27, 27, 27, 27, 27,  6,  6,\n",
              "        6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,\n",
              "        8,  8,  8,  3,  3,  3,  3,  3,  3,  3,  3, 36, 36, 36, 36, 36, 36,\n",
              "       36, 36, 36, 36, 36, 36, 36, 36, 36, 14, 14, 14, 14, 14, 14, 14, 14,\n",
              "       14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 38, 38, 38,\n",
              "       38, 38, 38, 38, 38, 38,  4,  4,  4,  4, 37, 37, 37, 37, 37, 37, 37,\n",
              "       37, 23, 23, 23, 23, 23, 23, 24, 23, 40, 40, 40, 40, 40, 40, 40, 40,\n",
              "       40, 40, 40, 35, 35, 35, 35, 35, 35])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azkCfK-bCoXd"
      },
      "source": [
        "final_predictions = []\n",
        "for prediction in predictions:\n",
        "  final_predictions.append(LE.transform(prediction))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ss31VSaXTuG1",
        "outputId": "d629a89f-bbcb-48db-a81b-d7379b7a9592"
      },
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 5\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, k=1)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, k=1)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 1)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    # print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",s|ess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(417, 1) (417,)\n",
            "update_recall:  0.38848920863309355\n",
            "recall 0.38848920863309355\n",
            "STREAM_VARS:  [162.0, 255.0, 0.0, 0.0]\n",
            "TMP_RANK:  TopKV2(values=array([[ 5],\n",
            "       [ 5],\n",
            "       [27],\n",
            "       [ 4],\n",
            "       [ 7],\n",
            "       [ 5],\n",
            "       [ 0],\n",
            "       [ 0],\n",
            "       [ 4],\n",
            "       [ 5],\n",
            "       [ 4],\n",
            "       [ 4],\n",
            "       [ 0],\n",
            "       [ 0],\n",
            "       [ 0],\n",
            "       [ 0],\n",
            "       [ 0],\n",
            "       [ 0],\n",
            "       [ 0],\n",
            "       [ 0],\n",
            "       [27],\n",
            "       [27],\n",
            "       [29],\n",
            "       [ 0],\n",
            "       [27],\n",
            "       [ 0],\n",
            "       [ 0],\n",
            "       [27],\n",
            "       [27],\n",
            "       [27],\n",
            "       [ 0],\n",
            "       [29],\n",
            "       [ 0],\n",
            "       [ 0],\n",
            "       [ 2],\n",
            "       [ 2],\n",
            "       [41],\n",
            "       [ 2],\n",
            "       [ 2],\n",
            "       [ 2],\n",
            "       [ 2],\n",
            "       [ 0],\n",
            "       [30],\n",
            "       [ 5],\n",
            "       [27],\n",
            "       [34],\n",
            "       [19],\n",
            "       [20],\n",
            "       [20],\n",
            "       [20],\n",
            "       [20],\n",
            "       [ 2],\n",
            "       [14],\n",
            "       [14],\n",
            "       [20],\n",
            "       [35],\n",
            "       [10],\n",
            "       [ 9],\n",
            "       [14],\n",
            "       [26],\n",
            "       [14],\n",
            "       [ 4],\n",
            "       [ 3],\n",
            "       [ 4],\n",
            "       [18],\n",
            "       [36],\n",
            "       [36],\n",
            "       [30],\n",
            "       [20],\n",
            "       [10],\n",
            "       [36],\n",
            "       [36],\n",
            "       [36],\n",
            "       [10],\n",
            "       [20],\n",
            "       [14],\n",
            "       [36],\n",
            "       [36],\n",
            "       [17],\n",
            "       [17],\n",
            "       [22],\n",
            "       [17],\n",
            "       [20],\n",
            "       [11],\n",
            "       [23],\n",
            "       [25],\n",
            "       [25],\n",
            "       [25],\n",
            "       [25],\n",
            "       [25],\n",
            "       [25],\n",
            "       [25],\n",
            "       [25],\n",
            "       [25],\n",
            "       [25],\n",
            "       [25],\n",
            "       [25],\n",
            "       [25],\n",
            "       [25],\n",
            "       [25],\n",
            "       [25],\n",
            "       [25],\n",
            "       [25],\n",
            "       [26],\n",
            "       [26],\n",
            "       [12],\n",
            "       [26],\n",
            "       [26],\n",
            "       [27],\n",
            "       [ 0],\n",
            "       [26],\n",
            "       [26],\n",
            "       [26],\n",
            "       [26],\n",
            "       [26],\n",
            "       [26],\n",
            "       [26],\n",
            "       [26],\n",
            "       [26],\n",
            "       [26],\n",
            "       [26],\n",
            "       [ 7],\n",
            "       [40],\n",
            "       [42],\n",
            "       [11],\n",
            "       [20],\n",
            "       [35],\n",
            "       [43],\n",
            "       [35],\n",
            "       [ 6],\n",
            "       [28],\n",
            "       [ 6],\n",
            "       [27],\n",
            "       [14],\n",
            "       [14],\n",
            "       [ 7],\n",
            "       [14],\n",
            "       [14],\n",
            "       [14],\n",
            "       [14],\n",
            "       [46],\n",
            "       [14],\n",
            "       [ 7],\n",
            "       [ 0],\n",
            "       [ 9],\n",
            "       [ 4],\n",
            "       [ 0],\n",
            "       [25],\n",
            "       [25],\n",
            "       [43],\n",
            "       [27],\n",
            "       [ 5],\n",
            "       [ 4],\n",
            "       [21],\n",
            "       [34],\n",
            "       [ 1],\n",
            "       [ 1],\n",
            "       [ 5],\n",
            "       [ 1],\n",
            "       [ 5],\n",
            "       [ 0],\n",
            "       [14],\n",
            "       [41],\n",
            "       [41],\n",
            "       [41],\n",
            "       [41],\n",
            "       [27],\n",
            "       [41],\n",
            "       [ 1],\n",
            "       [ 3],\n",
            "       [ 3],\n",
            "       [ 3],\n",
            "       [43],\n",
            "       [45],\n",
            "       [ 3],\n",
            "       [10],\n",
            "       [45],\n",
            "       [ 8],\n",
            "       [18],\n",
            "       [36],\n",
            "       [45],\n",
            "       [45],\n",
            "       [10],\n",
            "       [45],\n",
            "       [36],\n",
            "       [45],\n",
            "       [45],\n",
            "       [14],\n",
            "       [43],\n",
            "       [11],\n",
            "       [17],\n",
            "       [ 8],\n",
            "       [10],\n",
            "       [11],\n",
            "       [17],\n",
            "       [31],\n",
            "       [31],\n",
            "       [31],\n",
            "       [13],\n",
            "       [31],\n",
            "       [13],\n",
            "       [14],\n",
            "       [15],\n",
            "       [13],\n",
            "       [13],\n",
            "       [ 0],\n",
            "       [21],\n",
            "       [16],\n",
            "       [16],\n",
            "       [16],\n",
            "       [46],\n",
            "       [14],\n",
            "       [14],\n",
            "       [34],\n",
            "       [14],\n",
            "       [14],\n",
            "       [14],\n",
            "       [14],\n",
            "       [47],\n",
            "       [13],\n",
            "       [13],\n",
            "       [47],\n",
            "       [27],\n",
            "       [16],\n",
            "       [38],\n",
            "       [13],\n",
            "       [14],\n",
            "       [14],\n",
            "       [25],\n",
            "       [14],\n",
            "       [34],\n",
            "       [25],\n",
            "       [14],\n",
            "       [25],\n",
            "       [25],\n",
            "       [20],\n",
            "       [ 7],\n",
            "       [18],\n",
            "       [10],\n",
            "       [19],\n",
            "       [46],\n",
            "       [20],\n",
            "       [20],\n",
            "       [20],\n",
            "       [42],\n",
            "       [ 7],\n",
            "       [35],\n",
            "       [10],\n",
            "       [20],\n",
            "       [35],\n",
            "       [42],\n",
            "       [10],\n",
            "       [10],\n",
            "       [10],\n",
            "       [10],\n",
            "       [10],\n",
            "       [10],\n",
            "       [20],\n",
            "       [ 8],\n",
            "       [10],\n",
            "       [10],\n",
            "       [20],\n",
            "       [20],\n",
            "       [20],\n",
            "       [10],\n",
            "       [10],\n",
            "       [10],\n",
            "       [20],\n",
            "       [10],\n",
            "       [10],\n",
            "       [10],\n",
            "       [10],\n",
            "       [10],\n",
            "       [10],\n",
            "       [20],\n",
            "       [18],\n",
            "       [11],\n",
            "       [11],\n",
            "       [18],\n",
            "       [18],\n",
            "       [18],\n",
            "       [10],\n",
            "       [20],\n",
            "       [10],\n",
            "       [20],\n",
            "       [20],\n",
            "       [10],\n",
            "       [ 2],\n",
            "       [43],\n",
            "       [43],\n",
            "       [43],\n",
            "       [43],\n",
            "       [47],\n",
            "       [43],\n",
            "       [46],\n",
            "       [27],\n",
            "       [27],\n",
            "       [27],\n",
            "       [ 0],\n",
            "       [29],\n",
            "       [29],\n",
            "       [29],\n",
            "       [27],\n",
            "       [27],\n",
            "       [ 6],\n",
            "       [ 6],\n",
            "       [ 6],\n",
            "       [ 6],\n",
            "       [ 6],\n",
            "       [ 6],\n",
            "       [ 7],\n",
            "       [ 7],\n",
            "       [ 7],\n",
            "       [ 7],\n",
            "       [15],\n",
            "       [ 7],\n",
            "       [ 7],\n",
            "       [ 6],\n",
            "       [ 6],\n",
            "       [ 2],\n",
            "       [ 7],\n",
            "       [ 8],\n",
            "       [ 8],\n",
            "       [21],\n",
            "       [ 8],\n",
            "       [42],\n",
            "       [18],\n",
            "       [ 3],\n",
            "       [ 3],\n",
            "       [ 3],\n",
            "       [ 3],\n",
            "       [20],\n",
            "       [10],\n",
            "       [10],\n",
            "       [36],\n",
            "       [36],\n",
            "       [36],\n",
            "       [36],\n",
            "       [36],\n",
            "       [18],\n",
            "       [17],\n",
            "       [36],\n",
            "       [14],\n",
            "       [36],\n",
            "       [36],\n",
            "       [17],\n",
            "       [36],\n",
            "       [18],\n",
            "       [36],\n",
            "       [14],\n",
            "       [14],\n",
            "       [13],\n",
            "       [31],\n",
            "       [13],\n",
            "       [13],\n",
            "       [14],\n",
            "       [14],\n",
            "       [14],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [14],\n",
            "       [14],\n",
            "       [14],\n",
            "       [14],\n",
            "       [38],\n",
            "       [34],\n",
            "       [19],\n",
            "       [ 7],\n",
            "       [35],\n",
            "       [35],\n",
            "       [35],\n",
            "       [ 0],\n",
            "       [ 4],\n",
            "       [27],\n",
            "       [ 0],\n",
            "       [ 0],\n",
            "       [15],\n",
            "       [26],\n",
            "       [26],\n",
            "       [26],\n",
            "       [26],\n",
            "       [27],\n",
            "       [25],\n",
            "       [25],\n",
            "       [25],\n",
            "       [25],\n",
            "       [25],\n",
            "       [25],\n",
            "       [25],\n",
            "       [25],\n",
            "       [25],\n",
            "       [40],\n",
            "       [40],\n",
            "       [40],\n",
            "       [16],\n",
            "       [40],\n",
            "       [40],\n",
            "       [40],\n",
            "       [40],\n",
            "       [40],\n",
            "       [40],\n",
            "       [35],\n",
            "       [35],\n",
            "       [35],\n",
            "       [ 4],\n",
            "       [35],\n",
            "       [14]]), indices=array([[0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0]], dtype=int32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cg1TB_34ULH8",
        "outputId": "2c635afc-8b69-4584-c297-ef5b4a5a0cdb"
      },
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 5\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, k=2)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, k=2)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 2)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    # print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",s|ess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(417, 2) (417,)\n",
            "update_recall:  0.539568345323741\n",
            "recall 0.539568345323741\n",
            "STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 225.0, 192.0, 0.0, 0.0]\n",
            "TMP_RANK:  TopKV2(values=array([[ 5,  4],\n",
            "       [ 5,  4],\n",
            "       [27,  0],\n",
            "       [ 5,  4],\n",
            "       [14,  7],\n",
            "       [ 5,  4],\n",
            "       [ 4,  0],\n",
            "       [14,  0],\n",
            "       [ 4,  0],\n",
            "       [ 5,  4],\n",
            "       [ 5,  4],\n",
            "       [35,  4],\n",
            "       [ 4,  0],\n",
            "       [ 4,  0],\n",
            "       [29,  0],\n",
            "       [ 4,  0],\n",
            "       [14,  0],\n",
            "       [27,  0],\n",
            "       [25,  0],\n",
            "       [27,  0],\n",
            "       [29, 27],\n",
            "       [29, 27],\n",
            "       [29, 27],\n",
            "       [27,  0],\n",
            "       [27,  0],\n",
            "       [29,  0],\n",
            "       [27,  0],\n",
            "       [29, 27],\n",
            "       [29, 27],\n",
            "       [29, 27],\n",
            "       [27,  0],\n",
            "       [29, 27],\n",
            "       [27,  0],\n",
            "       [29,  0],\n",
            "       [11,  2],\n",
            "       [11,  2],\n",
            "       [41,  1],\n",
            "       [ 2,  1],\n",
            "       [ 4,  2],\n",
            "       [ 6,  2],\n",
            "       [ 6,  2],\n",
            "       [35,  0],\n",
            "       [34, 30],\n",
            "       [ 5,  4],\n",
            "       [34, 27],\n",
            "       [34,  5],\n",
            "       [22, 19],\n",
            "       [20,  8],\n",
            "       [42, 20],\n",
            "       [27, 20],\n",
            "       [20, 10],\n",
            "       [47,  2],\n",
            "       [20, 14],\n",
            "       [14,  8],\n",
            "       [20,  8],\n",
            "       [45, 35],\n",
            "       [10,  8],\n",
            "       [ 9,  4],\n",
            "       [14, 13],\n",
            "       [26, 12],\n",
            "       [14,  9],\n",
            "       [ 5,  4],\n",
            "       [ 4,  3],\n",
            "       [ 8,  4],\n",
            "       [36, 18],\n",
            "       [36,  3],\n",
            "       [36, 18],\n",
            "       [30,  3],\n",
            "       [20, 18],\n",
            "       [17, 10],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36,  8],\n",
            "       [18, 10],\n",
            "       [20, 19],\n",
            "       [36, 14],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [17,  8],\n",
            "       [17, 11],\n",
            "       [22, 17],\n",
            "       [17, 11],\n",
            "       [20, 11],\n",
            "       [17, 11],\n",
            "       [24, 23],\n",
            "       [25, 19],\n",
            "       [25, 19],\n",
            "       [25, 14],\n",
            "       [25, 14],\n",
            "       [25, 19],\n",
            "       [25, 24],\n",
            "       [25, 24],\n",
            "       [25, 19],\n",
            "       [25, 24],\n",
            "       [25, 13],\n",
            "       [25, 14],\n",
            "       [25, 19],\n",
            "       [25, 14],\n",
            "       [25, 19],\n",
            "       [25, 19],\n",
            "       [25, 19],\n",
            "       [25,  4],\n",
            "       [25, 23],\n",
            "       [26, 12],\n",
            "       [26, 12],\n",
            "       [26, 12],\n",
            "       [26, 12],\n",
            "       [26, 12],\n",
            "       [27, 26],\n",
            "       [25,  0],\n",
            "       [26, 16],\n",
            "       [26, 16],\n",
            "       [26, 12],\n",
            "       [26, 16],\n",
            "       [26, 16],\n",
            "       [26, 16],\n",
            "       [26,  0],\n",
            "       [26, 16],\n",
            "       [26, 16],\n",
            "       [26, 12],\n",
            "       [26, 12],\n",
            "       [44,  7],\n",
            "       [40, 19],\n",
            "       [42, 39],\n",
            "       [11,  8],\n",
            "       [46, 20],\n",
            "       [35, 28],\n",
            "       [43, 10],\n",
            "       [42, 35],\n",
            "       [42,  6],\n",
            "       [28,  1],\n",
            "       [28,  6],\n",
            "       [29, 27],\n",
            "       [27, 14],\n",
            "       [14,  5],\n",
            "       [14,  7],\n",
            "       [14,  7],\n",
            "       [14,  5],\n",
            "       [14,  0],\n",
            "       [35, 14],\n",
            "       [46, 14],\n",
            "       [14,  7],\n",
            "       [47,  7],\n",
            "       [27,  0],\n",
            "       [ 9,  0],\n",
            "       [ 5,  4],\n",
            "       [14,  0],\n",
            "       [28, 25],\n",
            "       [25, 19],\n",
            "       [43, 31],\n",
            "       [29, 27],\n",
            "       [ 5,  0],\n",
            "       [ 5,  4],\n",
            "       [34, 21],\n",
            "       [34,  0],\n",
            "       [41,  1],\n",
            "       [28,  1],\n",
            "       [ 5,  4],\n",
            "       [ 1,  0],\n",
            "       [ 5,  0],\n",
            "       [ 4,  0],\n",
            "       [27, 14],\n",
            "       [41,  1],\n",
            "       [41, 16],\n",
            "       [41,  1],\n",
            "       [41,  1],\n",
            "       [29, 27],\n",
            "       [41,  0],\n",
            "       [41,  1],\n",
            "       [44,  3],\n",
            "       [14,  3],\n",
            "       [28,  3],\n",
            "       [43, 10],\n",
            "       [45, 20],\n",
            "       [22,  3],\n",
            "       [10,  4],\n",
            "       [45, 14],\n",
            "       [20,  8],\n",
            "       [21, 18],\n",
            "       [36, 18],\n",
            "       [45,  3],\n",
            "       [45,  8],\n",
            "       [10,  3],\n",
            "       [45, 18],\n",
            "       [36,  8],\n",
            "       [45, 43],\n",
            "       [45, 27],\n",
            "       [16, 14],\n",
            "       [43,  4],\n",
            "       [19, 11],\n",
            "       [17, 11],\n",
            "       [36,  8],\n",
            "       [10,  8],\n",
            "       [19, 11],\n",
            "       [30, 17],\n",
            "       [31, 13],\n",
            "       [31, 13],\n",
            "       [31, 13],\n",
            "       [14, 13],\n",
            "       [34, 31],\n",
            "       [14, 13],\n",
            "       [14, 13],\n",
            "       [15, 14],\n",
            "       [14, 13],\n",
            "       [16, 13],\n",
            "       [27,  0],\n",
            "       [44, 21],\n",
            "       [16, 13],\n",
            "       [16, 13],\n",
            "       [26, 16],\n",
            "       [46, 26],\n",
            "       [27, 14],\n",
            "       [14, 13],\n",
            "       [34, 27],\n",
            "       [14, 13],\n",
            "       [35, 14],\n",
            "       [47, 14],\n",
            "       [15, 14],\n",
            "       [47, 39],\n",
            "       [16, 13],\n",
            "       [14, 13],\n",
            "       [47, 16],\n",
            "       [27, 13],\n",
            "       [25, 16],\n",
            "       [38, 14],\n",
            "       [31, 13],\n",
            "       [38, 14],\n",
            "       [14, 13],\n",
            "       [25, 24],\n",
            "       [25, 14],\n",
            "       [34, 14],\n",
            "       [28, 25],\n",
            "       [28, 14],\n",
            "       [25, 14],\n",
            "       [26, 25],\n",
            "       [23, 20],\n",
            "       [34,  7],\n",
            "       [18, 11],\n",
            "       [10,  3],\n",
            "       [31, 19],\n",
            "       [46, 42],\n",
            "       [20,  8],\n",
            "       [20,  8],\n",
            "       [20,  8],\n",
            "       [42, 39],\n",
            "       [15,  7],\n",
            "       [35, 14],\n",
            "       [15, 10],\n",
            "       [20,  8],\n",
            "       [35,  8],\n",
            "       [42,  8],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20,  8],\n",
            "       [20, 10],\n",
            "       [10,  8],\n",
            "       [42, 20],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [10,  8],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20,  8],\n",
            "       [28, 18],\n",
            "       [19, 11],\n",
            "       [11,  8],\n",
            "       [18, 11],\n",
            "       [18,  3],\n",
            "       [21, 18],\n",
            "       [20, 10],\n",
            "       [20,  8],\n",
            "       [46, 10],\n",
            "       [30, 20],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [ 5,  2],\n",
            "       [45, 43],\n",
            "       [43,  4],\n",
            "       [43, 11],\n",
            "       [45, 43],\n",
            "       [47, 25],\n",
            "       [43, 28],\n",
            "       [46, 35],\n",
            "       [29, 27],\n",
            "       [29, 27],\n",
            "       [29, 27],\n",
            "       [27,  0],\n",
            "       [29, 27],\n",
            "       [29,  0],\n",
            "       [29, 27],\n",
            "       [27,  0],\n",
            "       [29, 27],\n",
            "       [ 7,  6],\n",
            "       [ 6,  2],\n",
            "       [ 6,  2],\n",
            "       [ 7,  6],\n",
            "       [ 7,  6],\n",
            "       [ 7,  6],\n",
            "       [ 7,  6],\n",
            "       [ 7,  6],\n",
            "       [ 7,  6],\n",
            "       [24,  7],\n",
            "       [24, 15],\n",
            "       [ 7,  6],\n",
            "       [ 7,  6],\n",
            "       [42,  6],\n",
            "       [47,  6],\n",
            "       [ 7,  2],\n",
            "       [ 7,  6],\n",
            "       [11,  8],\n",
            "       [36,  8],\n",
            "       [21,  8],\n",
            "       [42,  8],\n",
            "       [42,  8],\n",
            "       [18,  3],\n",
            "       [21,  3],\n",
            "       [43,  3],\n",
            "       [ 3,  1],\n",
            "       [ 3,  1],\n",
            "       [20, 10],\n",
            "       [10,  4],\n",
            "       [20, 10],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 14],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [18, 10],\n",
            "       [17,  3],\n",
            "       [36, 18],\n",
            "       [20, 14],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 17],\n",
            "       [36, 18],\n",
            "       [20, 18],\n",
            "       [45, 36],\n",
            "       [14, 13],\n",
            "       [14, 13],\n",
            "       [13,  9],\n",
            "       [31, 13],\n",
            "       [31, 13],\n",
            "       [14, 13],\n",
            "       [15, 14],\n",
            "       [35, 14],\n",
            "       [35, 14],\n",
            "       [15, 14],\n",
            "       [15, 14],\n",
            "       [15, 14],\n",
            "       [15, 14],\n",
            "       [15, 14],\n",
            "       [15, 14],\n",
            "       [15, 14],\n",
            "       [15, 14],\n",
            "       [15, 14],\n",
            "       [15, 14],\n",
            "       [15,  6],\n",
            "       [15, 14],\n",
            "       [15, 14],\n",
            "       [14, 13],\n",
            "       [38, 14],\n",
            "       [29, 14],\n",
            "       [38, 25],\n",
            "       [34, 16],\n",
            "       [19, 14],\n",
            "       [19,  7],\n",
            "       [35, 15],\n",
            "       [35,  8],\n",
            "       [35,  0],\n",
            "       [ 4,  0],\n",
            "       [ 5,  4],\n",
            "       [29, 27],\n",
            "       [ 4,  0],\n",
            "       [30,  0],\n",
            "       [15, 14],\n",
            "       [26, 12],\n",
            "       [26,  0],\n",
            "       [26, 16],\n",
            "       [26, 12],\n",
            "       [27, 26],\n",
            "       [25, 24],\n",
            "       [25, 15],\n",
            "       [25, 21],\n",
            "       [25, 19],\n",
            "       [25, 21],\n",
            "       [31, 25],\n",
            "       [25, 19],\n",
            "       [25,  4],\n",
            "       [40, 25],\n",
            "       [40, 23],\n",
            "       [40, 19],\n",
            "       [40, 19],\n",
            "       [21, 16],\n",
            "       [40, 19],\n",
            "       [40, 19],\n",
            "       [40, 31],\n",
            "       [40, 37],\n",
            "       [40, 19],\n",
            "       [40, 10],\n",
            "       [35, 28],\n",
            "       [35, 14],\n",
            "       [35,  2],\n",
            "       [ 4,  2],\n",
            "       [35,  8],\n",
            "       [14,  0]]), indices=array([[0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1]], dtype=int32))\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}