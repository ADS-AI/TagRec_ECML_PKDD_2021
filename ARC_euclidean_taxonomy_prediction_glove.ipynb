{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"ARC_euclidean_taxonomy_prediction_glove.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"widgets":{"application/vnd.jupyter.widget-state+json":{"e2f12d7ba0914c6ca71c7c4c8a78ad14":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_805a5848e71a4b7eb994232ce2d88911","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5cb5e449d15649e9b4127333f87341a1","IPY_MODEL_96eb25c912704ff5837f77329f28f437"]}},"805a5848e71a4b7eb994232ce2d88911":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5cb5e449d15649e9b4127333f87341a1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d9f0e0d10ea6426985bf5228883d0381","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0664dba6dd7044de9808db97a8090f1e"}},"96eb25c912704ff5837f77329f28f437":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ac4c7429293c46b5b7347cdfe4f6ed8c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 1.89MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_20df23ff19544f4eb2e348254c179b51"}},"d9f0e0d10ea6426985bf5228883d0381":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0664dba6dd7044de9808db97a8090f1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ac4c7429293c46b5b7347cdfe4f6ed8c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"20df23ff19544f4eb2e348254c179b51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dbb9685d2eda44acac6e7284712a561d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e93a6e661d434ed4811c0766ef816be3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b8b8df1e951048f1b31996c979dab2c5","IPY_MODEL_7c2d0e1ecc1c44f2be5c2f9d39d2ea97"]}},"e93a6e661d434ed4811c0766ef816be3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b8b8df1e951048f1b31996c979dab2c5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_31ba238c9928494c8a86453b982635bf","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":433,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":433,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_331493bb4b864b39bdaa58b9c2c81e7a"}},"7c2d0e1ecc1c44f2be5c2f9d39d2ea97":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3b587ddc59cd410a84b5398a0c6c0eb9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 433/433 [03:13&lt;00:00, 2.24B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0469db31317e4e3d9828880680d5c492"}},"31ba238c9928494c8a86453b982635bf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"331493bb4b864b39bdaa58b9c2c81e7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3b587ddc59cd410a84b5398a0c6c0eb9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0469db31317e4e3d9828880680d5c492":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"87280831a61c4e779740c0964ce72282":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e8156eed32464b0b82b940d8da19d713","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d8dc8a8c216841bbaad99bbffa0ee3af","IPY_MODEL_a45b89420b6a4084b7d5ad1d2e3250a2"]}},"e8156eed32464b0b82b940d8da19d713":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d8dc8a8c216841bbaad99bbffa0ee3af":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_81100307f3a848cf9317206152004842","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":440473133,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":440473133,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4bc563ed43ad43f9b7039165d96df3f7"}},"a45b89420b6a4084b7d5ad1d2e3250a2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_acb04634796e42f8b4d6f736655f620e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 440M/440M [03:13&lt;00:00, 2.28MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a0cd0275ad5949c18ce282996dedf96d"}},"81100307f3a848cf9317206152004842":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4bc563ed43ad43f9b7039165d96df3f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"acb04634796e42f8b4d6f736655f620e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a0cd0275ad5949c18ce282996dedf96d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"sR9av2JU3kf6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625221716936,"user_tz":-330,"elapsed":4459,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}},"outputId":"46615d77-747e-413a-ab92-5db43a7fc739"},"source":["import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n","import torch\n","import logging\n","logging.basicConfig(level=logging.ERROR)\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":1,"outputs":[{"output_type":"stream","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla T4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"da-zaZJUGMFU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625222001663,"user_tz":-330,"elapsed":568,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}},"outputId":"e8cfbb04-3bc2-469d-a630-8b7e7a0376e9"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PlE6vskY9VmG","executionInfo":{"status":"ok","timestamp":1625222012570,"user_tz":-330,"elapsed":7244,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}}},"source":["!cp -r \"/content/drive/My Drive/research_lo_content_taxonomy_classification/model_euclidean_glove_QC/\" /content/"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"g-2VX5StL9JB","executionInfo":{"status":"ok","timestamp":1625222023426,"user_tz":-330,"elapsed":10863,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}}},"source":["!cp -r \"/content/drive/My Drive/research_lo_content_taxonomy_classification/model_euclidean_glove/\" /content/"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mG9ABE_QyDn5","executionInfo":{"status":"ok","timestamp":1625222087737,"user_tz":-330,"elapsed":49335,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}},"outputId":"8f2ea800-0f23-4327-ad22-9e2388fad9b8"},"source":["!pip install tensorflow==1.13.1"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Collecting tensorflow==1.13.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/29/6b4f1e02417c3a1ccc85380f093556ffd0b35dc354078074c5195c8447f2/tensorflow-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (92.6MB)\n","\u001b[K     |████████████████████████████████| 92.6MB 1.4MB/s \n","\u001b[?25hCollecting tensorboard<1.14.0,>=1.13.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n","\u001b[K     |████████████████████████████████| 3.2MB 40.0MB/s \n","\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.8.1)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.15.0)\n","Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.12.0)\n","Collecting keras-applications>=1.0.6\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n","\u001b[K     |████████████████████████████████| 51kB 7.3MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.19.5)\n","Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n","\u001b[K     |████████████████████████████████| 368kB 51.1MB/s \n","\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.2)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.36.2)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (3.12.4)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.4.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.34.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.3.4)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.1) (3.1.0)\n","Collecting mock>=2.0.0\n","  Downloading https://files.pythonhosted.org/packages/5c/03/b7e605db4a57c0f6fba744b11ef3ddf4ddebcada35022927a2b5fc623fdf/mock-4.0.3-py3-none-any.whl\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.13.1) (57.0.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (4.5.0)\n","Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.13.1) (1.5.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.7.4.3)\n","\u001b[31mERROR: kapre 0.3.5 has requirement tensorflow>=2.0.0, but you'll have tensorflow 1.13.1 which is incompatible.\u001b[0m\n","Installing collected packages: tensorboard, keras-applications, mock, tensorflow-estimator, tensorflow\n","  Found existing installation: tensorboard 2.5.0\n","    Uninstalling tensorboard-2.5.0:\n","      Successfully uninstalled tensorboard-2.5.0\n","  Found existing installation: tensorflow-estimator 2.5.0\n","    Uninstalling tensorflow-estimator-2.5.0:\n","      Successfully uninstalled tensorflow-estimator-2.5.0\n","  Found existing installation: tensorflow 2.5.0\n","    Uninstalling tensorflow-2.5.0:\n","      Successfully uninstalled tensorflow-2.5.0\n","Successfully installed keras-applications-1.0.8 mock-4.0.3 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"48baWPSlyS8y"},"source":["# Data Preparation"]},{"cell_type":"code","metadata":{"id":"BzKeqoCs3kgA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625222095914,"user_tz":-330,"elapsed":8183,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}},"outputId":"48bc7471-ae72-4786-a062-61ce67b60bdc"},"source":["!pip install transformers==2.8.0"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Collecting transformers==2.8.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n","\u001b[K     |████████████████████████████████| 573kB 22.4MB/s \n","\u001b[?25hCollecting tokenizers==0.5.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/e3/5e49e9a83fb605aaa34a1c1173e607302fecae529428c28696fb18f1c2c9/tokenizers-0.5.2-cp37-cp37m-manylinux1_x86_64.whl (5.6MB)\n","\u001b[K     |████████████████████████████████| 5.6MB 40.2MB/s \n","\u001b[?25hCollecting boto3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/8e/7a81544adb80582ab79b3c3572f9d69331fb0fefaccb3c94dc32082e8e3c/boto3-1.17.104-py2.py3-none-any.whl (131kB)\n","\u001b[K     |████████████████████████████████| 133kB 50.8MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (4.41.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (2.23.0)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 47.1MB/s \n","\u001b[?25hCollecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/aa/1437691b0c7c83086ebb79ce2da16e00bef024f24fec2a5161c35476f499/sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2MB)\n","\u001b[K     |████████████████████████████████| 1.2MB 50.0MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (3.0.12)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (1.19.5)\n","Collecting botocore<1.21.0,>=1.20.104\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/7f/d25fd47143499b2bb47f36d0272cb5e438a1e5ec69abb26c9cd74a7330ad/botocore-1.20.104-py2.py3-none-any.whl (7.7MB)\n","\u001b[K     |████████████████████████████████| 7.7MB 41.6MB/s \n","\u001b[?25hCollecting s3transfer<0.5.0,>=0.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/d0/693477c688348654ddc21dcdce0817653a294aa43f41771084c25e7ff9c7/s3transfer-0.4.2-py2.py3-none-any.whl (79kB)\n","\u001b[K     |████████████████████████████████| 81kB 10.8MB/s \n","\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n","  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (1.24.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (1.15.0)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.104->boto3->transformers==2.8.0) (2.8.1)\n","\u001b[31mERROR: botocore 1.20.104 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n","Installing collected packages: tokenizers, jmespath, botocore, s3transfer, boto3, sacremoses, sentencepiece, transformers\n","Successfully installed boto3-1.17.104 botocore-1.20.104 jmespath-0.10.0 s3transfer-0.4.2 sacremoses-0.0.45 sentencepiece-0.1.96 tokenizers-0.5.2 transformers-2.8.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HZFv4UU8sLTM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625222104339,"user_tz":-330,"elapsed":8430,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}},"outputId":"0871daff-6c3f-49f9-ddd8-7a094f114ace"},"source":["!pip install git+https://github.com/geoopt/geoopt.git\n","! pip install git+https://github.com/ferrine/hyrnn.git"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Collecting git+https://github.com/geoopt/geoopt.git\n","  Cloning https://github.com/geoopt/geoopt.git to /tmp/pip-req-build-dwh2vsqs\n","  Running command git clone -q https://github.com/geoopt/geoopt.git /tmp/pip-req-build-dwh2vsqs\n","Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from geoopt==0.4.0rc1) (1.9.0+cu102)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from geoopt==0.4.0rc1) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.9.0->geoopt==0.4.0rc1) (3.7.4.3)\n","Building wheels for collected packages: geoopt\n","  Building wheel for geoopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for geoopt: filename=geoopt-0.4.0rc1-cp37-none-any.whl size=85509 sha256=30576f0f5e4b6552566f20c788f7617328abd417282809fecc02984d2bb24dbf\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-j6xdfd_7/wheels/10/df/30/e0d857f034c142ca5f38af048b62aae3da773b272553e5dd21\n","Successfully built geoopt\n","Installing collected packages: geoopt\n","Successfully installed geoopt-0.4.0rc1\n","Collecting git+https://github.com/ferrine/hyrnn.git\n","  Cloning https://github.com/ferrine/hyrnn.git to /tmp/pip-req-build-4cgdvfbw\n","  Running command git clone -q https://github.com/ferrine/hyrnn.git /tmp/pip-req-build-4cgdvfbw\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from hyrnn==0.0.0) (1.9.0+cu102)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from hyrnn==0.0.0) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->hyrnn==0.0.0) (3.7.4.3)\n","Building wheels for collected packages: hyrnn\n","  Building wheel for hyrnn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for hyrnn: filename=hyrnn-0.0.0-cp37-none-any.whl size=13969 sha256=02f3dbd72991acd7c603c63f3b07d1df873b569cd49f44e9dc1c79fe4cd95f1f\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-i3gn6r5n/wheels/24/c3/64/cc0e9d25d466081dc154a2a8843157f54d845b916b4ba66418\n","Successfully built hyrnn\n","Installing collected packages: hyrnn\n","Successfully installed hyrnn-0.0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GsADhaO93kgD","colab":{"base_uri":"https://localhost:8080/","height":980},"executionInfo":{"status":"ok","timestamp":1625222104342,"user_tz":-330,"elapsed":20,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}},"outputId":"19c8cef1-65a0-47b1-8d7b-52cd407b0848"},"source":["import pandas as pd\n","train_data = pd.read_csv(\"train_QC_data.csv\")\n","val_data = pd.read_csv(\"val_QC_data.csv\")\n","test_data = pd.read_csv(\"test_QC_data.csv\")\n","\n","train_data\n"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>questionID</th>\n","      <th>originalQuestionID</th>\n","      <th>totalPossiblePoint</th>\n","      <th>AnswerKey</th>\n","      <th>isMultipleChoiceQuestion</th>\n","      <th>includesDiagram</th>\n","      <th>examName</th>\n","      <th>grade</th>\n","      <th>year</th>\n","      <th>QCLabel</th>\n","      <th>Question</th>\n","      <th>subject</th>\n","      <th>category</th>\n","      <th>fold</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>VASoL_2008_3_34</td>\n","      <td>34</td>\n","      <td>1</td>\n","      <td>C</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Virginia Standards of Learning - Science</td>\n","      <td>3</td>\n","      <td>2008</td>\n","      <td>matter_properties of objects_TEXT</td>\n","      <td>A student is asked to bring something that fee...</td>\n","      <td>NaN</td>\n","      <td>Train</td>\n","      <td>Easy</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>MCAS_2015_8_6</td>\n","      <td>6</td>\n","      <td>1</td>\n","      <td>B</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>MCAS</td>\n","      <td>8</td>\n","      <td>2015</td>\n","      <td>celestial_FEATURES_STELLAR</td>\n","      <td>Which of the following statements best describ...</td>\n","      <td>NaN</td>\n","      <td>Test</td>\n","      <td>Easy</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Mercury_SC_417677</td>\n","      <td>417677</td>\n","      <td>1</td>\n","      <td>B</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Mercury</td>\n","      <td>4</td>\n","      <td>2015</td>\n","      <td>energy_LIGHT_REFLECT</td>\n","      <td>A polished metal ball looks very shiny and bri...</td>\n","      <td>NaN</td>\n","      <td>Test</td>\n","      <td>Challenge</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Mercury_7230423</td>\n","      <td>7230423</td>\n","      <td>1</td>\n","      <td>A</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Mercury</td>\n","      <td>9</td>\n","      <td>2015</td>\n","      <td>LIFE_EXTINCTION_MASSEX</td>\n","      <td>Which was a main force driving extensive speci...</td>\n","      <td>NaN</td>\n","      <td>Test</td>\n","      <td>Easy</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>NYSEDREGENTS_2007_8_6</td>\n","      <td>6</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>NYSEDREGENTS</td>\n","      <td>8</td>\n","      <td>2007</td>\n","      <td>Life_functions_features and functions_CELLBIO_...</td>\n","      <td>Compared to the amount of hereditary informati...</td>\n","      <td>NaN</td>\n","      <td>Train</td>\n","      <td>Challenge</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5592</th>\n","      <td>Mercury_402502</td>\n","      <td>402502</td>\n","      <td>1</td>\n","      <td>D</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Mercury</td>\n","      <td>8</td>\n","      <td>2015</td>\n","      <td>matter_chemistry_periodic table</td>\n","      <td>According to the periodic table, argon is foun...</td>\n","      <td>NaN</td>\n","      <td>Test</td>\n","      <td>Challenge</td>\n","    </tr>\n","    <tr>\n","      <th>5593</th>\n","      <td>MCAS_2006_9_20</td>\n","      <td>20</td>\n","      <td>1</td>\n","      <td>B</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>MCAS</td>\n","      <td>9</td>\n","      <td>2006</td>\n","      <td>FOR_MOMENTUM</td>\n","      <td>Which of the following has the least momentum?...</td>\n","      <td>NaN</td>\n","      <td>Train</td>\n","      <td>Challenge</td>\n","    </tr>\n","    <tr>\n","      <th>5594</th>\n","      <td>NYSEDREGENTS_2013_8_35</td>\n","      <td>35</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>NYSEDREGENTS</td>\n","      <td>8</td>\n","      <td>2013</td>\n","      <td>Life_functions_features and functions_PLANT_PH...</td>\n","      <td>The amount of which greenhouse gas in the air ...</td>\n","      <td>NaN</td>\n","      <td>Test</td>\n","      <td>Easy</td>\n","    </tr>\n","    <tr>\n","      <th>5595</th>\n","      <td>Mercury_7082670</td>\n","      <td>7082670</td>\n","      <td>1</td>\n","      <td>C</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Mercury</td>\n","      <td>7</td>\n","      <td>2015</td>\n","      <td>energy_LIGHT_electromagnetic spectrum</td>\n","      <td>The visible light spectrum can be subdivided a...</td>\n","      <td>NaN</td>\n","      <td>Test</td>\n","      <td>Easy</td>\n","    </tr>\n","    <tr>\n","      <th>5596</th>\n","      <td>Mercury_7004970</td>\n","      <td>7004970</td>\n","      <td>1</td>\n","      <td>C</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Mercury</td>\n","      <td>8</td>\n","      <td>2015</td>\n","      <td>Life_reproduction_DNA inheritance_DOMRECESS</td>\n","      <td>A scientist crosses a red-flowered plant with ...</td>\n","      <td>NaN</td>\n","      <td>Train</td>\n","      <td>Easy</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5597 rows × 14 columns</p>\n","</div>"],"text/plain":["                  questionID originalQuestionID  ...  category       fold\n","0            VASoL_2008_3_34                 34  ...     Train       Easy\n","1              MCAS_2015_8_6                  6  ...      Test       Easy\n","2          Mercury_SC_417677             417677  ...      Test  Challenge\n","3            Mercury_7230423            7230423  ...      Test       Easy\n","4      NYSEDREGENTS_2007_8_6                  6  ...     Train  Challenge\n","...                      ...                ...  ...       ...        ...\n","5592          Mercury_402502             402502  ...      Test  Challenge\n","5593          MCAS_2006_9_20                 20  ...     Train  Challenge\n","5594  NYSEDREGENTS_2013_8_35                 35  ...      Test       Easy\n","5595         Mercury_7082670            7082670  ...      Test       Easy\n","5596         Mercury_7004970            7004970  ...     Train       Easy\n","\n","[5597 rows x 14 columns]"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"iQhO6qqt6lge","executionInfo":{"status":"ok","timestamp":1625222104344,"user_tz":-330,"elapsed":18,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}}},"source":["from google.colab import files"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"DD4IAgG1XQGp","executionInfo":{"status":"ok","timestamp":1625222104347,"user_tz":-330,"elapsed":20,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}}},"source":["import re\n","def clean_sentence(question):\n","  # print(question)\n","  question = re.sub('<[^>]*>', ' ',question)\n","  question = re.sub(' +', ' ', question)\n","  question = re.sub('\\xa0','',question)\n","  question = question.rstrip()\n","  question = re.sub('nan','',question)\n","  question = re.sub(u'\\u2004','',question)\n","  question = re.sub(u'\\u2009','',question)\n","\n","  # question = question.decode(\"utf-8\")\n","  # question = question.replace(u'\\u200\\d*','').encode(\"utf-8\")\n","  question = re.sub('&nbsp','',question)\n","  question = re.sub('&ndash','',question)\n","  question = re.sub('\\r','',question)\n","  question = re.sub('\\t','',question)\n","  question = re.sub('\\n',' ',question)\n","\n","  question = re.sub('MathType@.*','',question)\n","  question = re.sub('&thinsp','',question)\n","  question = re.sub('&times','',question)\n","  question = re.sub('\\u200b','',question)\n","  question = re.sub('&rarr;;;','',question)\n","\n","  return question"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"kNrGNk8f3kgh","executionInfo":{"status":"ok","timestamp":1625222104349,"user_tz":-330,"elapsed":21,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}}},"source":["# final_data_1 = final_data.loc[0:71003,:]\n","# final_data_1"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"FIrS5sxE3kgk","colab":{"base_uri":"https://localhost:8080/","height":324,"referenced_widgets":["e2f12d7ba0914c6ca71c7c4c8a78ad14","805a5848e71a4b7eb994232ce2d88911","5cb5e449d15649e9b4127333f87341a1","96eb25c912704ff5837f77329f28f437","d9f0e0d10ea6426985bf5228883d0381","0664dba6dd7044de9808db97a8090f1e","ac4c7429293c46b5b7347cdfe4f6ed8c","20df23ff19544f4eb2e348254c179b51"]},"executionInfo":{"status":"ok","timestamp":1625222106507,"user_tz":-330,"elapsed":2178,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}},"outputId":"b99c2bab-4ead-4f26-da7e-bb4dbf3deed7"},"source":["from transformers import BertTokenizer\n","\n","# Load the BERT tokenizer.\n","print('Loading BERT tokenizer...')\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"],"name":"stderr"},{"output_type":"stream","text":["Loading BERT tokenizer...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e2f12d7ba0914c6ca71c7c4c8a78ad14","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-mgc72PQYV1Y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625222106508,"user_tz":-330,"elapsed":32,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}},"outputId":"b174f297-a4db-4914-9a74-36f19b0d81a1"},"source":["train_data[\"QCLabel\"].value_counts()"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["celestial_cycles                                                106\n","matter_chemistry_periodic table                                  85\n","matter_chemistry_atomic                                          79\n","matter_CHANGES_CHEMICAL                                          72\n","science_INFERENCE_observation                                    69\n","                                                               ... \n","LIFE_environment and adaptation_ADAP                              1\n","Life_functions_features and functions_animal_nervous system       1\n","matter_properties of material_FLAMMABLE                           1\n","energy_ELEC_ELECTROMAGNETS_energy_devices                         1\n","energy_ELEC_COND                                                  1\n","Name: QCLabel, Length: 416, dtype: int64"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"j3lYOb2K3kgy","executionInfo":{"status":"ok","timestamp":1625222106509,"user_tz":-330,"elapsed":27,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}}},"source":["\n","# from sklearn.preprocessing import LabelEncoder\n","\n","# LE = LabelEncoder()\n","# final_data['label'] = LE.fit_transform(final_data['board_syllabus'])\n","# final_data.head()"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"wp64MkNB3kg1","executionInfo":{"status":"ok","timestamp":1625222106511,"user_tz":-330,"elapsed":28,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}}},"source":["# def get_labels(prediction):\n","#     predicted_label =  LE.inverse_transform([prediction])\n","#     return predicted_label[0]"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"uPgTmJPS3kg4","executionInfo":{"status":"ok","timestamp":1625222106511,"user_tz":-330,"elapsed":27,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}}},"source":["# get_labels(330)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"HrQ1BBx0vWUQ","executionInfo":{"status":"ok","timestamp":1625222106512,"user_tz":-330,"elapsed":27,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}}},"source":["# train_data = pd.concat([train_data,val_data])\n","# train_data"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"ijn1nIpByb3e","executionInfo":{"status":"ok","timestamp":1625222106513,"user_tz":-330,"elapsed":28,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}}},"source":["train_features = train_data[\"Question\"]\n","test_features = test_data[\"Question\"]\n","train_labels = train_data[\"QCLabel\"]\n","test_labels = test_data[\"QCLabel\"]\n","val_features = val_data[\"Question\"]\n","val_labels = val_data[\"QCLabel\"]"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"prM_km_83khD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625222106513,"user_tz":-330,"elapsed":26,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}},"outputId":"fb13ace7-c24d-4b2e-80f5-5dd9ba9b7df2"},"source":["train_labels.value_counts()"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["celestial_cycles                                                106\n","matter_chemistry_periodic table                                  85\n","matter_chemistry_atomic                                          79\n","matter_CHANGES_CHEMICAL                                          72\n","science_INFERENCE_observation                                    69\n","                                                               ... \n","LIFE_environment and adaptation_ADAP                              1\n","Life_functions_features and functions_animal_nervous system       1\n","matter_properties of material_FLAMMABLE                           1\n","energy_ELEC_ELECTROMAGNETS_energy_devices                         1\n","energy_ELEC_COND                                                  1\n","Name: QCLabel, Length: 416, dtype: int64"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"qfhPstXJ03oz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625222106514,"user_tz":-330,"elapsed":22,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}},"outputId":"62e2af6c-d947-4028-d2ff-570ff6c2f71a"},"source":["test_labels.value_counts()"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Life_reproduction_DNA inheritance_inheritance                   26\n","celestial_cycles                                                26\n","Life_functions_features and functions_PLANT_PHOTOSYNTH          22\n","matter_chemistry_atomic                                         21\n","science_INFERENCE_experiment design                             19\n","                                                                ..\n","Life_functions_features and functions_PLANT_TRANSPIR             1\n","energy_ELEC_COND                                                 1\n","EARTH_GEO_FORMATIONS_EARTH_INNER_generic plate                   1\n","matter_properties of material                                    1\n","Life_functions_features and functions_CELLBIO_ORG_ORGSYSTEMS     1\n","Name: QCLabel, Length: 352, dtype: int64"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"AkyM7gqv3khI","executionInfo":{"status":"ok","timestamp":1625222106515,"user_tz":-330,"elapsed":20,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}}},"source":["\n","question_answer = train_features.values\n","categories = train_labels.values"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"tFkS_H_83khL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625222106515,"user_tz":-330,"elapsed":19,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}},"outputId":"e36122c1-bf99-465c-ade7-f2bf2dbb7563"},"source":["question_answer"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['A student is asked to bring something that feels rough to class. Which would be BEST for him to bring? (A) Pillow (B) Marble (C) Sandpaper (D) Trading card',\n","       'Which of the following statements best describes the role of gravity in the formation of stars? (A) Gravity converts solid matter into gases and light energy. (B) Gravity causes gases and dust particles to condense into spheres. (C) Gravity cools gases and liquids until they become one solid mass. (D) Gravity pushes rocks and dust particles outward from a dense center.',\n","       'A polished metal ball looks very shiny and bright on a sunny day. What makes the ball look shiny? (A) The ball makes light. (B) The ball reflects light. (C) The ball absorbs light and then releases it. (D) The ball absorbs light and keeps it inside.',\n","       ...,\n","       'The amount of which greenhouse gas in the air will increase the most if large forests are cut down to be used for building materials without planting new trees in their place? (1) ozone (2) methane (3) water vapor (4) carbon dioxide',\n","       'The visible light spectrum can be subdivided according to (A) the types of waves. (B) the sizes of particles. (C) a range of colors. (D) a type of energy.',\n","       'A scientist crosses a red-flowered plant with a white-flowered plant, and all offspring have red flowers. What will most likely result if these red-flowered offspring are crossed with white-flowered plants? (A) All of the offspring will have red flowers. (B) All of the offspring will have white flowers. (C) The offspring will have either red or white flowers. (D) The offspring will have neither red nor white flowers.'],\n","      dtype=object)"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"ian7gSDE3khR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625222132496,"user_tz":-330,"elapsed":570,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}},"outputId":"bd1115b6-b745-4007-b01c-85d210342543"},"source":["categories"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['matter_properties of objects_TEXT', 'celestial_FEATURES_STELLAR',\n","       'energy_LIGHT_REFLECT', ...,\n","       'Life_functions_features and functions_PLANT_PHOTOSYNTH',\n","       'energy_LIGHT_electromagnetic spectrum',\n","       'Life_reproduction_DNA inheritance_DOMRECESS'], dtype=object)"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"fepGiggpqOQx","executionInfo":{"status":"ok","timestamp":1625222134397,"user_tz":-330,"elapsed":356,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}}},"source":["# val_features = test_features.values\n","# val_labels = test_labels.values"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"FN1zRXMOXwLK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625222142497,"user_tz":-330,"elapsed":4611,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}},"outputId":"20ddc8f5-985b-46c1-ec08-dfcda307825e"},"source":["\n","import numpy as np\n","!pip install inflection\n","\n","from bokeh.io import output_file, output_notebook, show\n","from bokeh.plotting import figure\n","from bokeh.transform import linear_cmap\n","from bokeh.util.hex import hexbin\n","from bokeh.models import HoverTool\n","from bokeh import colors\n","import inflection\n","\n","from nltk.stem import PorterStemmer \n","ps = PorterStemmer()\n","from gzip import open as gopen\n","from pandas.core.common import flatten\n","import gensim.models.poincare as poincare\n","def get_cleaned_taxonomy(taxonomy):\n","  cleaned_taxonomy = []\n","  for value in taxonomy:\n","      individual_tokens = []\n","      value = value.lower().split(\"_\")\n","      for val in value:\n","        for token in val.split(' '):\n","          if token.isalpha():\n","            individual_tokens.append(token)\n","      cleaned_taxonomy.append( list(tok for tok in individual_tokens) )\n","      # cleaned_taxonomy.append( value )\n","  return cleaned_taxonomy"],"execution_count":26,"outputs":[{"output_type":"stream","text":["Collecting inflection\n","  Downloading https://files.pythonhosted.org/packages/59/91/aa6bde563e0085a02a435aa99b49ef75b0a4b062635e606dab23ce18d720/inflection-0.5.1-py2.py3-none-any.whl\n","Installing collected packages: inflection\n","Successfully installed inflection-0.5.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wPAl0TNuX6mx","executionInfo":{"status":"ok","timestamp":1625222142499,"user_tz":-330,"elapsed":7,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}}},"source":["\n","# course_taxonomy\n","\n","poincare_emb_data = get_cleaned_taxonomy(categories)\n","poincare_val = get_cleaned_taxonomy(val_labels)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"aedZzkBsqEeK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625222142500,"user_tz":-330,"elapsed":7,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}},"outputId":"9b9c74a7-212c-42dc-fb3c-952a1e89af8b"},"source":["poincare_emb_data[2]"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['energy', 'light', 'reflect']"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"w_ocuHxzCy16","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625222145915,"user_tz":-330,"elapsed":338,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}},"outputId":"c82b0dde-26a2-40a8-9391-6c23a197eeb5"},"source":["import nltk\n","nltk.download('wordnet')\n","from nltk.stem import WordNetLemmatizer \n","wnl = WordNetLemmatizer()"],"execution_count":29,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sL2dQ-jAoIop","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625222415321,"user_tz":-330,"elapsed":2,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}},"outputId":"552bc558-fe4d-4a77-bf5a-4489ce2542a6"},"source":["import gensim.downloader as api\n","wv = api.load('glove-wiki-gigaword-300')"],"execution_count":30,"outputs":[{"output_type":"stream","text":["[=================================================-] 98.8% 371.6/376.1MB downloaded\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vcuR3P8qqluz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625222528210,"user_tz":-330,"elapsed":0,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}},"outputId":"e72c353b-2da9-472b-903d-c74313c311b3"},"source":["np.mean(np.vstack([wv['hi'],wv['hello']]),axis=0).shape"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(300,)"]},"metadata":{"tags":[]},"execution_count":0}]},{"cell_type":"code","metadata":{"id":"LdBbsrO9zp2p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625222528217,"user_tz":-330,"elapsed":0,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}},"outputId":"82e434d6-3146-49f0-beb7-dfa5be425c73"},"source":["taxonomy_vectors = []\n","for feature in poincare_emb_data:\n","  token_embeddings = []\n","  for token in feature:\n","    if token in wv:\n","      token_embeddings.append(wv[token])\n","  token_emb  = np.vstack(token_embeddings)\n","  taxonomy_vectors.append(np.mean(token_emb,axis=0))\n","taxonomy_vectors = np.vstack(taxonomy_vectors)\n","taxonomy_vectors.shape"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5597, 300)"]},"metadata":{"tags":[]},"execution_count":0}]},{"cell_type":"code","metadata":{"id":"oTlCYX9Q34JG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625222528303,"user_tz":-330,"elapsed":0,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}},"outputId":"8fbee97e-dd9c-44fd-d963-7b0086302049"},"source":["taxonomy_vectors_val = []\n","for feature in poincare_val:\n","  token_embeddings = []\n","  for token in feature:\n","      if token in wv:\n","        token_embeddings.append(wv[token])\n","  token_emb  = np.vstack(token_embeddings)\n","  taxonomy_vectors_val.append(np.mean(token_emb,axis=0))\n","taxonomy_vectors_val = np.vstack(taxonomy_vectors_val)\n","taxonomy_vectors_val.shape"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(778, 300)"]},"metadata":{"tags":[]},"execution_count":0}]},{"cell_type":"code","metadata":{"id":"Y_ZeuHc63khU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625222550780,"user_tz":-330,"elapsed":6129,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}},"outputId":"1068ce8d-e17d-4fa4-f1d9-a269d5057973"},"source":["input_ids = []\n","attention_masks = []\n","\n","for sent in question_answer:\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 128,           # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        truncation=True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', question_answer[0])\n","print('Token IDs:', input_ids[0])"],"execution_count":35,"outputs":[{"output_type":"stream","text":["Original:  A student is asked to bring something that feels rough to class. Which would be BEST for him to bring? (A) Pillow (B) Marble (C) Sandpaper (D) Trading card\n","Token IDs: tensor([  101,  1037,  3076,  2003,  2356,  2000,  3288,  2242,  2008,  5683,\n","         5931,  2000,  2465,  1012,  2029,  2052,  2022,  2190,  2005,  2032,\n","         2000,  3288,  1029,  1006,  1037,  1007, 10005,  1006,  1038,  1007,\n","         7720,  1006,  1039,  1007,  5472, 23298,  1006,  1040,  1007,  6202,\n","         4003,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2VjkhiN3pAfP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625222556614,"user_tz":-330,"elapsed":998,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}},"outputId":"9ea2af13-2e22-4928-a83e-ac94a7cbcd11"},"source":["input_ids_val = []\n","attention_masks_val = []\n","\n","for sent in val_features:\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 128,           # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        truncation=True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids_val.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks_val.append(encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors.\n","input_ids_val = torch.cat(input_ids_val, dim=0)\n","attention_masks_val = torch.cat(attention_masks_val, dim=0)\n","\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', question_answer[0])\n","print('Token IDs:', input_ids[0])"],"execution_count":36,"outputs":[{"output_type":"stream","text":["Original:  A student is asked to bring something that feels rough to class. Which would be BEST for him to bring? (A) Pillow (B) Marble (C) Sandpaper (D) Trading card\n","Token IDs: tensor([  101,  1037,  3076,  2003,  2356,  2000,  3288,  2242,  2008,  5683,\n","         5931,  2000,  2465,  1012,  2029,  2052,  2022,  2190,  2005,  2032,\n","         2000,  3288,  1029,  1006,  1037,  1007, 10005,  1006,  1038,  1007,\n","         7720,  1006,  1039,  1007,  5472, 23298,  1006,  1040,  1007,  6202,\n","         4003,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BNDW74Ny3khj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625222557183,"user_tz":-330,"elapsed":13,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}},"outputId":"96986bf4-5e5b-4039-954b-104fb5d78931"},"source":["num_classes = len(list(set(categories)))\n","num_classes"],"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["416"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"ZmaLk5Ab3khl","executionInfo":{"status":"ok","timestamp":1625222557789,"user_tz":-330,"elapsed":8,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}}},"source":["from torch.utils.data import TensorDataset, random_split\n","train_poincare_tensor = torch.tensor(taxonomy_vectors,dtype=torch.float)\n","val_poincare_tensor = torch.tensor(taxonomy_vectors_val,dtype=torch.float)\n","\n","val_dataset = TensorDataset(input_ids_val,attention_masks_val,val_poincare_tensor)\n","# Combine the training inputs into a TensorDataset.\n","train_dataset = TensorDataset(input_ids, attention_masks, train_poincare_tensor)"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"D_lTinod3kho","executionInfo":{"status":"ok","timestamp":1625222557790,"user_tz":-330,"elapsed":5,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}}},"source":["from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","batch_size = 32\n","train_dataloader = DataLoader(\n","            train_dataset,  # The training samples.\n","            sampler = RandomSampler(train_dataset), # Select batches randomly\n","            batch_size = batch_size # Trains with this batch size.\n","        )\n","\n","validation_dataloader = DataLoader(\n","            val_dataset, # The validation samples.\n","            sampler = SequentialSampler(val_dataset), \n","            batch_size = batch_size \n","        )"],"execution_count":39,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Vduf9fOMviK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625222558397,"user_tz":-330,"elapsed":9,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}},"outputId":"78fc8b7c-1779-400a-be1e-5868dcf1acfb"},"source":["# !pip install transformers==2.8.0\n","import transformers\n","print(transformers.__version__)"],"execution_count":40,"outputs":[{"output_type":"stream","text":["2.8.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PlrjSpSovto9","executionInfo":{"status":"ok","timestamp":1625222558938,"user_tz":-330,"elapsed":3,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}}},"source":["import torch"],"execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"id":"3H2wp8WlEi9u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625222559352,"user_tz":-330,"elapsed":4,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}},"outputId":"80183eb7-9867-4d01-ab18-fd92af65045a"},"source":["set(question_answer).intersection(set(test_features))"],"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/plain":["set()"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"ZN6jdKp0uhO3","executionInfo":{"status":"ok","timestamp":1625222560938,"user_tz":-330,"elapsed":4,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}}},"source":["\n","import sys\n","import json\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision import models\n","from sklearn.utils import shuffle\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import precision_recall_fscore_support\n","from matplotlib import pyplot as plt\n","from torch.nn.modules.loss import HingeEmbeddingLoss\n","from random import randint\n","\n","from tqdm import tqdm\n","import geoopt\n","import time\n","from sklearn.utils import shuffle\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import precision_recall_fscore_support\n","from matplotlib import pyplot as plt\n","from torch.nn.modules.loss import HingeEmbeddingLoss\n","from random import randint\n","import torch.nn.functional as F\n","\n","import time\n","import argparse\n","cos = nn.CosineSimilarity(dim=0, eps=1e-6)\n","# Neural Classifierwork\n","class MulticlassClassifier(nn.Module):\n","    def __init__(self,bert_model_path):\n","        super(MulticlassClassifier,self).__init__()\n","        self.bert = BertModel.from_pretrained(bert_model_path,output_hidden_states=False,output_attentions=False)\n","        self.dropout = nn.Dropout(0.1)\n","        self.fc1 = nn.Linear(768, 384)\n","        self.fc2 = nn.Linear(384, 300)\n","\n","    def forward(self,tokens,masks):\n","        _, pooled_output = self.bert(tokens, attention_mask=masks)\n","        x = self.fc1(pooled_output)\n","        x = self.fc2(x)\n","        return x\n","\n","class MyHingeLoss(torch.nn.Module):\n","    def __init__(self, margin):\n","        super(MyHingeLoss, self).__init__()\n","        self.margin = margin\n","    # def forward_val(self, output, target):\n","    #     cos = nn.CosineSimilarity(dim=0, eps=1e-6)\n","    #     loss = 0\n","    #     num_compare = 4\n","    #     count = 0\n","    #     for i in range(len(output)):\n","    #         v_image = output[i]\n","    #         t_label = target[i]\n","    #         for j in range(num_compare):\n","    #             if j != i:\n","    #                 count += 1\n","    #                 t_j = target[j]\n","    #                 loss += torch.relu( self.margin - cos(t_label, v_image) + cos(t_j, v_image) )\n","    #     return loss / count\n","    def forward(self, output, target):\n","        loss=0\n","        for i in range(len(output)):\n","            v_image = F.normalize(output[i],p=2,dim=0)\n","            t_label = F.normalize(target[i],p=2,dim=0)\n","            j = randint(0, len(output)-1)\n","            while j == i:\n","                j = randint(0, len(output)-1)\n","            t_j = F.normalize(target[j],p=2,dim=0)\n","            loss+= torch.relu( self.margin - cos(t_label, v_image) + cos(t_j, v_image) )\n","        return loss / len(output)\n","\n"],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"id":"yHYyjxMDIx2U","executionInfo":{"status":"ok","timestamp":1625222563307,"user_tz":-330,"elapsed":616,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}}},"source":["from transformers import BertModel, AdamW, BertConfig\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n"],"execution_count":44,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vOGVJtMozOta"},"source":["# Training section\n"]},{"cell_type":"code","metadata":{"id":"_2tmAMlw3khr","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["dbb9685d2eda44acac6e7284712a561d","e93a6e661d434ed4811c0766ef816be3","b8b8df1e951048f1b31996c979dab2c5","7c2d0e1ecc1c44f2be5c2f9d39d2ea97","31ba238c9928494c8a86453b982635bf","331493bb4b864b39bdaa58b9c2c81e7a","3b587ddc59cd410a84b5398a0c6c0eb9","0469db31317e4e3d9828880680d5c492","87280831a61c4e779740c0964ce72282","e8156eed32464b0b82b940d8da19d713","d8dc8a8c216841bbaad99bbffa0ee3af","a45b89420b6a4084b7d5ad1d2e3250a2","81100307f3a848cf9317206152004842","4bc563ed43ad43f9b7039165d96df3f7","acb04634796e42f8b4d6f736655f620e","a0cd0275ad5949c18ce282996dedf96d"]},"outputId":"3d8a00d8-3a7b-47f5-80ae-1718be21051c"},"source":["from transformers import BertModel, AdamW, BertConfig\n","\n","# Loads BertModel, the pretrained BERT model with a single \n","model = MulticlassClassifier('bert-base-uncased')\n","# model.load_state_dict(torch.load('model_euclidean_glove/model_weights'))\n","\n","# Tell pytorch to run this model on the GPU.\n","model.cuda()\n"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dbb9685d2eda44acac6e7284712a561d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"87280831a61c4e779740c0964ce72282","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["MulticlassClassifier(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (fc1): Linear(in_features=768, out_features=384, bias=True)\n","  (fc2): Linear(in_features=384, out_features=300, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"x4paz_8iTZ9o"},"source":["# mobius_params = []\n","# bert_params = []\n","\n","# def mobius_params():\n","#   for param in model.named_parameters():\n","#     if 'fc' in param[0]:\n","#       yield param[1]\n","# def bert_params():\n","#   for param in model.named_parameters():\n","#     if 'bert' in param[0]:\n","#       yield param[1]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"awQ2Y9Jb3kht"},"source":["optimizer_1 = torch.optim.AdamW(model.parameters(),\n","                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n","                )\n","# optimizer_2 = radam_.RiemannianAdam(mobius_params(), lr=0.01, stabilize=10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2Ys-M4-e3khv"},"source":["from transformers import get_linear_schedule_with_warmup\n","\n","\n","epochs = 30\n","\n","# Total number of training steps is [number of batches] x [number of epochs]. \n","total_steps = len(train_dataloader) * epochs\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QrYqErOD3khx","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d8e2106f-39df-499c-ef11-969b504e7980"},"source":["len(train_dataloader) "],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["175"]},"metadata":{"tags":[]},"execution_count":91}]},{"cell_type":"code","metadata":{"id":"EWVSE9LM3kh0","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5ee789b9-c559-469c-89bf-5852a9005b92"},"source":["1935 * 32"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["61920"]},"metadata":{"tags":[]},"execution_count":92}]},{"cell_type":"code","metadata":{"id":"rcvxVVi63kh3"},"source":["scheduler = get_linear_schedule_with_warmup(optimizer_1, \n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GUw3zm6g3kh5"},"source":["# import numpy as np\n","\n","# # Function to calculate the accuracy of our predictions vs labels\n","# def flat_accuracy(preds, labels):\n","#     pred_flat = np.argmax(preds, axis=1).flatten()\n","#     labels_flat = labels.flatten()\n","#     return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ta6zfUTa3kh7"},"source":["import time\n","import datetime\n","\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GFq9gd5kQSHb"},"source":["import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KsInxVoqbsFW"},"source":["class EarlyStopping:\n","    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n","    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n","        \"\"\"\n","        Args:\n","            patience (int): How long to wait after last time validation loss improved.\n","                            Default: 7\n","            verbose (bool): If True, prints a message for each validation loss improvement. \n","                            Default: False\n","            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n","                            Default: 0\n","            path (str): Path for the checkpoint to be saved to.\n","                            Default: 'checkpoint.pt'\n","            trace_func (function): trace print function.\n","                            Default: print            \n","        \"\"\"\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","        self.path = path\n","        self.trace_func = trace_func\n","    def __call__(self, val_loss, model):\n","\n","        score = -val_loss\n","\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model):\n","        '''Saves model when validation loss decrease.'''\n","        if self.verbose:\n","            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        torch.save(model.state_dict(), self.path)\n","        self.val_loss_min = val_loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Di68jXK5WaYr"},"source":["criterion = MyHingeLoss(0.1)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6LhAy2hZ3kh9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e17ae795-1baa-490e-a6f2-3a1045717c64"},"source":["import random\n","import numpy as np\n","import json\n","from sklearn.metrics import f1_score\n","# This training code is based on the `run_glue.py` script here:\n","# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n","\n","# Set the seed value all over the place to make this reproducible.\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# We'll store a number of quantities such as training and validation loss, \n","# validation accuracy, and timings.\n","training_stats = []\n","\n","# Measure the total training time for the whole run.\n","total_t0 = time.time()\n","early_stopping = EarlyStopping(patience=4, verbose=True)\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","    \n","\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","\n","    # Reset the total loss for this epoch.\n","    total_train_loss = 0\n","\n","\n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","\n","        # Progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)\n","            \n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","\n","        model.zero_grad() \n","        optimizer_1.zero_grad()       \n","\n","        logits = model(b_input_ids, \n","                             b_input_mask)\n","        \n","        loss = criterion.forward(logits,b_labels)\n","\n","  \n","        total_train_loss += loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # Update parameters and take a step using the computed gradient.\n","        # The optimizer dictates the \"update rule\"--how the parameters are\n","        # modified based on their gradients, the learning rate, etc.\n","        optimizer_1.step()\n","\n","        # Update the learning rate.\n","        scheduler.step()\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_train_loss = total_train_loss / len(train_dataloader)            \n","    \n","    # Measure how long this epoch took.\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(training_time))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set.\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    # Put the model in evaluation mode--the dropout layers behave differently\n","    # during evaluation.\n","    model.eval()\n","\n","    # Tracking variables \n","    total_eval_f1 = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        \n","\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        \n","        # Tell pytorch not to bother with constructing the compute graph during\n","        # the forward pass, since this is only needed for backprop (training).\n","        with torch.no_grad():        \n","\n","\n","          logits = model(b_input_ids, \n","                              b_input_mask)\n","          \n","        loss = criterion(logits,b_labels)\n","\n","            \n","        # Accumulate the validation loss.\n","        total_eval_loss += loss.item()\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy().round()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculate the accuracy for this batch of test sentences, and\n","        # accumulate it over all batches.\n","        # total_eval_f1 += f1_score(label_ids,logits, average='macro')\n","        \n","\n","    # Report the final accuracy for this validation run.\n","    # avg_val_accuracy = total_eval_f1 / len(validation_dataloader)\n","    # print(\"  f1score: {0:.2f}\".format(avg_val_accuracy))\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_val_loss = total_eval_loss / len(validation_dataloader)\n","    early_stopping(avg_val_loss, model)\n","    if early_stopping.early_stop:\n","      print(\"Early stopping\")\n","      break  \n","    # Measure how long the validation run took.\n","    validation_time = format_time(time.time() - t0)\n","    \n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","    output_dir = 'model_euclidean_glove_QC/'\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    print(\"Saving model to %s\" % output_dir)\n","    tokenizer.save_pretrained(output_dir)\n","    torch.save(model.state_dict(), os.path.join(output_dir, 'model_weights'))\n","\n","    !rm -rf \"/content/drive/My Drive/research_lo_content_taxonomy_classification/model_euclidean_glove_QC\"\n","    !mv model_euclidean_glove_QC \"/content/drive/My Drive/research_lo_content_taxonomy_classification/\"\n","    # Record all statistics from this epoch.\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Valid. Loss': avg_val_loss,\n","            'Training Time': training_time,\n","            'Validation Time': validation_time\n","        }\n","    )\n","\n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","======== Epoch 1 / 30 ========\n","Training...\n","  Batch    40  of    175.    Elapsed: 0:00:32.\n","  Batch    80  of    175.    Elapsed: 0:01:03.\n","  Batch   120  of    175.    Elapsed: 0:01:34.\n","  Batch   160  of    175.    Elapsed: 0:02:05.\n","\n","  Average training loss: 0.00\n","  Training epcoh took: 0:02:17\n","\n","Running Validation...\n","Validation loss decreased (inf --> 0.007344).  Saving model ...\n","  Validation Loss: 0.01\n","  Validation took: 0:00:08\n","Saving model to model_euclidean_glove_QC/\n","\n","======== Epoch 2 / 30 ========\n","Training...\n","  Batch    40  of    175.    Elapsed: 0:00:32.\n","  Batch    80  of    175.    Elapsed: 0:01:03.\n","  Batch   120  of    175.    Elapsed: 0:01:34.\n","  Batch   160  of    175.    Elapsed: 0:02:05.\n","\n","  Average training loss: 0.00\n","  Training epcoh took: 0:02:17\n","\n","Running Validation...\n","EarlyStopping counter: 1 out of 2\n","  Validation Loss: 0.01\n","  Validation took: 0:00:06\n","Saving model to model_euclidean_glove_QC/\n","\n","======== Epoch 3 / 30 ========\n","Training...\n","  Batch    40  of    175.    Elapsed: 0:00:32.\n","  Batch    80  of    175.    Elapsed: 0:01:03.\n","  Batch   120  of    175.    Elapsed: 0:01:34.\n","  Batch   160  of    175.    Elapsed: 0:02:05.\n","\n","  Average training loss: 0.00\n","  Training epcoh took: 0:02:17\n","\n","Running Validation...\n","EarlyStopping counter: 2 out of 2\n","Early stopping\n","\n","Training complete!\n","Total training took 0:07:18 (h:mm:ss)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"u_m_26bpXIaY"},"source":["# !rm -rf \"/content/drive/My Drive/research_lo_content_taxonomy_classification/model_euclidean_glove_QC\"\n","\n","# !mv model_euclidean_glove_QC \"/content/drive/My Drive/research_lo_content_taxonomy_classification/\"\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6RACcsko3kh_","colab":{"base_uri":"https://localhost:8080/","height":580},"outputId":"6d522b57-93af-4ce3-f897-1da4ca49c234"},"source":["import pandas as pd\n","\n","# Display floats with two decimal places.\n","pd.set_option('precision', 2)\n","\n","# Create a DataFrame from our training statistics.\n","df_stats = pd.DataFrame(data=training_stats)\n","\n","# Use the 'epoch' as the row index.\n","df_stats = df_stats.set_index('epoch')\n","\n","# A hack to force the column headers to wrap.\n","#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n","\n","# Display the table.\n","df_stats"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Training Loss</th>\n","      <th>Valid. Loss</th>\n","      <th>Training Time</th>\n","      <th>Validation Time</th>\n","    </tr>\n","    <tr>\n","      <th>epoch</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>4.65e-02</td>\n","      <td>2.34e-02</td>\n","      <td>0:02:16</td>\n","      <td>0:00:08</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.70e-02</td>\n","      <td>1.44e-02</td>\n","      <td>0:02:19</td>\n","      <td>0:00:08</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.29e-02</td>\n","      <td>1.44e-02</td>\n","      <td>0:02:18</td>\n","      <td>0:00:08</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.06e-02</td>\n","      <td>1.40e-02</td>\n","      <td>0:02:18</td>\n","      <td>0:00:08</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>9.00e-03</td>\n","      <td>1.23e-02</td>\n","      <td>0:02:18</td>\n","      <td>0:00:08</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>8.20e-03</td>\n","      <td>1.31e-02</td>\n","      <td>0:02:18</td>\n","      <td>0:00:06</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>6.71e-03</td>\n","      <td>1.06e-02</td>\n","      <td>0:02:18</td>\n","      <td>0:00:08</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>6.09e-03</td>\n","      <td>9.62e-03</td>\n","      <td>0:02:17</td>\n","      <td>0:00:08</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>6.15e-03</td>\n","      <td>9.43e-03</td>\n","      <td>0:02:17</td>\n","      <td>0:00:08</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>5.57e-03</td>\n","      <td>9.47e-03</td>\n","      <td>0:02:17</td>\n","      <td>0:00:06</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>5.59e-03</td>\n","      <td>7.96e-03</td>\n","      <td>0:02:17</td>\n","      <td>0:00:08</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>5.28e-03</td>\n","      <td>8.97e-03</td>\n","      <td>0:02:17</td>\n","      <td>0:00:06</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>4.73e-03</td>\n","      <td>8.33e-03</td>\n","      <td>0:02:17</td>\n","      <td>0:00:06</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>4.61e-03</td>\n","      <td>7.44e-03</td>\n","      <td>0:02:17</td>\n","      <td>0:00:08</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>4.39e-03</td>\n","      <td>1.02e-02</td>\n","      <td>0:02:17</td>\n","      <td>0:00:06</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>3.94e-03</td>\n","      <td>8.91e-03</td>\n","      <td>0:02:17</td>\n","      <td>0:00:06</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>3.86e-03</td>\n","      <td>8.79e-03</td>\n","      <td>0:02:17</td>\n","      <td>0:00:06</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Training Loss  Valid. Loss Training Time Validation Time\n","epoch                                                          \n","1           4.65e-02     2.34e-02       0:02:16         0:00:08\n","2           1.70e-02     1.44e-02       0:02:19         0:00:08\n","3           1.29e-02     1.44e-02       0:02:18         0:00:08\n","4           1.06e-02     1.40e-02       0:02:18         0:00:08\n","5           9.00e-03     1.23e-02       0:02:18         0:00:08\n","6           8.20e-03     1.31e-02       0:02:18         0:00:06\n","7           6.71e-03     1.06e-02       0:02:18         0:00:08\n","8           6.09e-03     9.62e-03       0:02:17         0:00:08\n","9           6.15e-03     9.43e-03       0:02:17         0:00:08\n","10          5.57e-03     9.47e-03       0:02:17         0:00:06\n","11          5.59e-03     7.96e-03       0:02:17         0:00:08\n","12          5.28e-03     8.97e-03       0:02:17         0:00:06\n","13          4.73e-03     8.33e-03       0:02:17         0:00:06\n","14          4.61e-03     7.44e-03       0:02:17         0:00:08\n","15          4.39e-03     1.02e-02       0:02:17         0:00:06\n","16          3.94e-03     8.91e-03       0:02:17         0:00:06\n","17          3.86e-03     8.79e-03       0:02:17         0:00:06"]},"metadata":{"tags":[]},"execution_count":56}]},{"cell_type":"code","metadata":{"id":"o5TicdiP3kiC","colab":{"base_uri":"https://localhost:8080/","height":427},"outputId":"83b9db22-a889-43ec-ef6c-d0a3baddcb52"},"source":["import matplotlib.pyplot as plt\n","% matplotlib inline\n","\n","import seaborn as sns\n","\n","# Use plot styling from seaborn.\n","sns.set(style='darkgrid')\n","\n","# Increase the plot size and font size.\n","sns.set(font_scale=1.5)\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","# Plot the learning curve.\n","plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n","plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n","\n","# Label the plot.\n","plt.title(\"Training & Validation Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.xticks([1, 2, 3, 4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20])\n","\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 864x432 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"DbiTDpVv3kiF","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2f98cd3c-898e-405d-9ee3-35cdd2a1f31d"},"source":["import os\n","\n","\n","output_dir = 'model_euclidean_glove_QC/'\n","\n","# Create output directory if needed\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)\n","\n","print(\"Saving model to %s\" % output_dir)\n","\n","\n","# model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n","# model_to_save.save_pretrained(output_dir)\n","tokenizer.save_pretrained(output_dir)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Saving model to model_euclidean_glove_QC/\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["('model_euclidean_glove_QC/vocab.txt',\n"," 'model_euclidean_glove_QC/special_tokens_map.json',\n"," 'model_euclidean_glove_QC/added_tokens.json')"]},"metadata":{"tags":[]},"execution_count":125}]},{"cell_type":"code","metadata":{"id":"1U2UQ29a3kiI"},"source":["# !pip install joblib\n","# import joblib\n","# joblib.dump(LE, \"label_encoder\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0F5PxZm9vAOI"},"source":["import json\n","torch.save(model.state_dict(), os.path.join(output_dir, 'model_weights'))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vlb0IpVJO1XQ"},"source":["# with open(os.path.join(output_dir, 'model_config.json'), 'w') as f:\n","#     json.dump(model.config, f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dpGY8vSDI6u4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"055991a2-9e98-4405-c013-18f05b5bb180"},"source":["!zip -r model_euclidean_glove_QC.zip model_euclidean_glove_QC\n","# files.download('model_euclidean_1.zip')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["updating: model_euclidean_glove_QC/ (stored 0%)\n","updating: model_euclidean_glove_QC/tokenizer_config.json (stored 0%)\n","updating: model_euclidean_glove_QC/vocab.txt (deflated 53%)\n","updating: model_euclidean_glove_QC/model_weights (deflated 7%)\n","updating: model_euclidean_glove_QC/special_tokens_map.json (deflated 40%)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HvFDCDIxKDOf"},"source":["# !zip -r label_encoder_categorized_reduced.zip label_encoder\n","# files.download('label_encoder_categorized_reduced.zip')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ft-vovoH0IY5"},"source":["# Inference"]},{"cell_type":"code","metadata":{"id":"JKdRT1UUz4vC"},"source":["#Execute only for Lo zero shot testing. Skip this and following cell if you want to infer on ARC dataset\n","import pandas as pd\n","lo_data = pd.read_csv(\"what_you_learnt_lo_labelled.csv\", delimiter=\"|\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y2kDnBDF0I3e"},"source":["test_features = lo_data[\"learning_objectives\"].values\n","labels = lo_data[\"taxonomy\"].values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4178_yLFMWmx","executionInfo":{"status":"ok","timestamp":1625222649350,"user_tz":-330,"elapsed":580,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}}},"source":["test_features = test_features.values\n","labels = test_labels.values"],"execution_count":46,"outputs":[]},{"cell_type":"code","metadata":{"id":"8ohj1x7frQJ1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625222651933,"user_tz":-330,"elapsed":589,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}},"outputId":"8964c1d6-4340-420d-ab43-0b143177455b"},"source":["len(list(set(labels)))"],"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/plain":["352"]},"metadata":{"tags":[]},"execution_count":47}]},{"cell_type":"code","metadata":{"id":"WyXY8hryCwJM","executionInfo":{"status":"ok","timestamp":1625222653511,"user_tz":-330,"elapsed":391,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}}},"source":["def get_cleaned_taxonomy_lo(taxonomy):\n","  cleaned_taxonomy = []\n","  for value in taxonomy:\n","      individual_tokens = []\n","      value = value.lower().split(\">>\")\n","      for val in value:\n","        for token in val.split(' '):\n","          if token.isalpha():\n","            individual_tokens.append(token)\n","      cleaned_taxonomy.append( list(tok for tok in individual_tokens) )\n","      # cleaned_taxonomy.append( value )\n","  return cleaned_taxonomy"],"execution_count":48,"outputs":[]},{"cell_type":"code","metadata":{"id":"EvElzLjECzdn"},"source":["#execute only for LO skip for ARC\n","test_labels = list(set(labels))\n","poincare_emb_data = get_cleaned_taxonomy_lo(test_labels)\n","poincare_emb_data[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LyCDmupa3FJQ","executionInfo":{"status":"ok","timestamp":1625223929035,"user_tz":-330,"elapsed":412,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}}},"source":["# rerun from here when inferring for different values of top k\n","import pandas as pd\n","targets = pd.read_csv(\"targets_ARC.csv\")\n","targets = targets[\"targets\"].values"],"execution_count":122,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kjinn0gXkNuP","executionInfo":{"status":"ok","timestamp":1625223929659,"user_tz":-330,"elapsed":5,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}}},"source":["\n","# course_taxonomy\n","test_labels = targets\n","poincare_emb_data = get_cleaned_taxonomy(test_labels)"],"execution_count":123,"outputs":[]},{"cell_type":"code","metadata":{"id":"dorQwznCeMpR","executionInfo":{"status":"ok","timestamp":1625223936837,"user_tz":-330,"elapsed":3,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}}},"source":["# import sent2vec\n","# s2v_model = sent2vec.Sent2vecModel()\n","# s2v_model.load_model('torontobooks_unigrams.bin')"],"execution_count":124,"outputs":[]},{"cell_type":"code","metadata":{"id":"6wl0RJ3SSW4i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625223937381,"user_tz":-330,"elapsed":8,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}},"outputId":"7e43eba9-7153-4075-9fa0-0a352e3e1d0d"},"source":["taxonomy_vectors = []\n","for feature in poincare_emb_data:\n","  token_embeddings = []\n","  for token in feature:\n","    if token in wv:\n","      token_embeddings.append(wv[token])\n","  token_emb  = np.vstack(token_embeddings)\n","  taxonomy_vectors.append(np.mean(token_emb,axis=0))\n","taxonomy_vectors = np.vstack(taxonomy_vectors)\n","taxonomy_vectors.shape"],"execution_count":125,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(352, 300)"]},"metadata":{"tags":[]},"execution_count":125}]},{"cell_type":"code","metadata":{"id":"Nso39n1N_po_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625223937382,"user_tz":-330,"elapsed":7,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}},"outputId":"5ff4cb02-285d-4bce-f413-06ac578fd735"},"source":["model = MulticlassClassifier('bert-base-uncased')\n","model.load_state_dict(torch.load('model_euclidean_glove_QC/model_weights'))\n","model.cuda()"],"execution_count":126,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MulticlassClassifier(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (fc1): Linear(in_features=768, out_features=384, bias=True)\n","  (fc2): Linear(in_features=384, out_features=300, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":126}]},{"cell_type":"code","metadata":{"id":"Qe4qYkV2C4fX","executionInfo":{"status":"ok","timestamp":1625223952070,"user_tz":-330,"elapsed":485,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}}},"source":["test_input_ids = []\n","test_attention_masks = []\n","for sent in test_features:\n","\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 128,           # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        truncation=True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    test_input_ids.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    test_attention_masks.append(encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors.\n","test_input_ids = torch.cat(test_input_ids, dim=0)\n","test_attention_masks = torch.cat(test_attention_masks, dim=0)\n","# labels = torch.tensor(labels)\n","\n","# Set the batch size.  \n","batch_size = 32  \n","test_poincare_tensor = torch.tensor(taxonomy_vectors,dtype=torch.float)\n","\n","# Create the DataLoader.\n","# prediction_data = TensorDataset(test_input_ids, test_attention_masks, test_poincare_tensor)\n","# prediction_sampler = SequentialSampler(prediction_data)\n","# prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"],"execution_count":127,"outputs":[]},{"cell_type":"code","metadata":{"id":"SNdlve8AJcCO","executionInfo":{"status":"ok","timestamp":1625223952071,"user_tz":-330,"elapsed":14,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}}},"source":["from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","test_poincare_tensor = torch.tensor(taxonomy_vectors,dtype=torch.float)\n"],"execution_count":128,"outputs":[]},{"cell_type":"code","metadata":{"id":"osWBBDJcZ7tZ","executionInfo":{"status":"ok","timestamp":1625223952071,"user_tz":-330,"elapsed":13,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}}},"source":[""],"execution_count":128,"outputs":[]},{"cell_type":"code","metadata":{"id":"I6aMBHkAQZjT","executionInfo":{"status":"ok","timestamp":1625223952072,"user_tz":-330,"elapsed":12,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}}},"source":["cos = torch.nn.CosineSimilarity(dim=0, eps=1e-6)\n","def dist_without_grad( u, v):\n","  sqdist = torch.sum((u - v) ** 2, dim=-1)\n","  squnorm = torch.sum(u ** 2, dim=-1)\n","  sqvnorm = torch.sum(v ** 2, dim=-1)\n","  x = 1 + 2 * sqdist / ((1 - squnorm) * (1 - sqvnorm)) + 1e-7\n","  z = torch.sqrt(x ** 2 - 1)\n","  return torch.log(x + z)"],"execution_count":129,"outputs":[]},{"cell_type":"code","metadata":{"id":"oe0otXOPg7z0","executionInfo":{"status":"ok","timestamp":1625223952072,"user_tz":-330,"elapsed":11,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}}},"source":["test_labels = np.array(test_labels)"],"execution_count":130,"outputs":[]},{"cell_type":"code","metadata":{"id":"GyV33c3G1o4M","executionInfo":{"status":"ok","timestamp":1625223952073,"user_tz":-330,"elapsed":11,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}}},"source":["targets = np.array(targets)"],"execution_count":131,"outputs":[]},{"cell_type":"code","metadata":{"id":"mPCktQT9DVT4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625223976577,"user_tz":-330,"elapsed":23094,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}},"outputId":"a685ab62-a35d-4a5e-999e-ac85fcbd8eff"},"source":["# Prediction on test set\n","\n","print('Predicting labels for {:,} test sentences...'.format(len(test_input_ids)))\n","\n","# Put model in evaluation mode\n","model.eval()\n","cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n","\n","input_ids = test_input_ids.to('cuda')\n","attention_masks = test_attention_masks.to('cuda')\n","test_poincare_tensor = test_poincare_tensor.to('cuda')\n","# Tracking variables \n","predictions , true_labels = [], []\n","for input_id,attention_mask in zip(input_ids, attention_masks):\n","  with torch.no_grad():\n","    outputs = model(input_id.reshape(1,-1),attention_mask.reshape(1,-1))\n","    \n","  distances = cos(outputs,test_poincare_tensor)\n","  distances,indices = torch.topk(distances,15,largest=True)\n","  predictions.append(targets[indices.cpu().numpy()])\n","print(len(predictions))\n","  \n","print('    DONE.')\n","# predictions"],"execution_count":132,"outputs":[{"output_type":"stream","text":["Predicting labels for 1,400 test sentences...\n","1400\n","    DONE.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FPYYwiKFSTp6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625223976581,"user_tz":-330,"elapsed":39,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}},"outputId":"89f3222c-f0d6-43f7-9ed1-af0463859acc"},"source":["np.where(test_labels==\"physics>>physics : part - ii\")"],"execution_count":133,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([], dtype=int64),)"]},"metadata":{"tags":[]},"execution_count":133}]},{"cell_type":"code","metadata":{"id":"KF42ENe1RnGn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625223976582,"user_tz":-330,"elapsed":32,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}},"outputId":"40dbf3db-ea6b-4152-90a9-b3e2fccd6bc1"},"source":["predictions[0]"],"execution_count":134,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['science_GRAPH', 'science_MODELS', 'science_INFERENCE',\n","       'science_INFERENCE_FORMLAWS', 'science_INFERENCE_SAMPLESIZE',\n","       'science_INFERENCE_WHATTESTING', 'science_INFERENCE_HYP',\n","       'science_INFERENCE_QUESTIONING', 'science_INFERENCE_observation',\n","       'science_INFERENCE_BIAS', 'science_INFERENCE_REPORT',\n","       'science_INFERENCE_experiment design',\n","       'science_INFERENCE_INFERENCE ', 'science_INFERENCE_INFERENCE',\n","       'OTHER_ENGINEERING'], dtype=object)"]},"metadata":{"tags":[]},"execution_count":134}]},{"cell_type":"code","metadata":{"id":"O5wj2gXYFkrQ","executionInfo":{"status":"ok","timestamp":1625223976583,"user_tz":-330,"elapsed":28,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}}},"source":["labels=test_data['QCLabel'].values"],"execution_count":135,"outputs":[]},{"cell_type":"code","metadata":{"id":"uvUdu4uH14Ca","executionInfo":{"status":"ok","timestamp":1625223976584,"user_tz":-330,"elapsed":29,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}}},"source":["targets = pd.read_csv(\"targets_ARC.csv\")\n","\n","labels = targets[\"targets\"].values"],"execution_count":136,"outputs":[]},{"cell_type":"code","metadata":{"id":"nOt8hvs-CZfn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625223976585,"user_tz":-330,"elapsed":29,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}},"outputId":"f14c7553-8605-407f-ae1f-bf6f10243330"},"source":["from sklearn .preprocessing import LabelEncoder\n","LE= LabelEncoder()\n","labels = LE.fit_transform(labels)\n","labels"],"execution_count":137,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([107, 168,  77, 183, 281, 254, 142, 249,  81, 103, 312, 299, 171,\n","       337, 179, 208, 285, 155, 335, 342, 137, 243, 188,  69, 217, 273,\n","        16, 344,  88, 316, 132,  85, 118,  20, 244, 125, 348, 332, 164,\n","       280,  33, 256, 251, 100, 216, 278, 279, 287,   3, 204,  71, 269,\n","       334, 196,  72, 158,   7, 172, 173, 325, 297,  11, 295, 195, 180,\n","        89, 308,  48, 274,  43, 264, 139, 104, 230,  95, 241, 154, 231,\n","        37,  87, 229, 145,  75, 190, 286, 234, 101,  51, 199,  68, 283,\n","        29, 112, 326, 184, 296, 162, 189, 343, 303,  82, 201, 122,  73,\n","       108, 141,   6,  14, 257,  97, 330, 111,  39, 175, 213, 300,  67,\n","       311, 255, 152, 338, 349,  46, 130, 347, 177, 176, 320, 246, 220,\n","         1, 110, 121, 271, 277, 282,  53, 310, 322, 319, 307, 170,  98,\n","       167, 236, 309, 346, 131,  25, 209, 315,  49, 293,  52, 259, 106,\n","       181, 268, 267, 197, 126,  38,  34, 317,  83, 219, 266, 265, 245,\n","        94, 305, 324, 124, 105,  22,   2, 214, 146, 260,  80, 138, 238,\n","       331, 123, 233, 345, 192, 228, 115, 207, 288, 341, 144, 247, 242,\n","       148, 151,  64, 327, 136,  10,  78, 150, 329, 163,  21, 153, 147,\n","       321, 198,  63, 248,   9,  91, 222, 211,  79,  26, 302,  90, 340,\n","       140,  18,  96, 294, 127,  30,  66, 284,  13,  36, 262, 159,  62,\n","        60,  19, 350, 252,  28,   5, 232, 298, 275, 304, 215, 119,  99,\n","       133, 117, 351,  15,  44, 221, 250, 272,  86,   8, 339, 191,  12,\n","       227, 240,  92, 193, 174,  24,  41, 235, 289, 314, 333, 291, 182,\n","       313, 186,  57,  70,  59, 113, 160, 161, 128,  76, 178, 149, 135,\n","       116, 224,   4, 166, 102, 276,  27,  23, 318,  56,  84,  50, 187,\n","       200, 237, 143,  35, 239, 203, 223, 206, 114,  47, 323,  45, 185,\n","       134,  17,  65, 328, 253, 205, 292, 263,  40, 109, 258, 225,  93,\n","       157, 301, 212, 120,  74, 336,  55, 306, 270, 165, 290, 202,   0,\n","       194, 210, 226,  58, 261,  54,  61, 218,  31,  32,  42, 169, 156,\n","       129])"]},"metadata":{"tags":[]},"execution_count":137}]},{"cell_type":"code","metadata":{"id":"adb4gTNgGKUP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625223976585,"user_tz":-330,"elapsed":24,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}},"outputId":"d093bd2d-cb79-4472-a91e-ee99aca76e7f"},"source":["labels"],"execution_count":138,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([107, 168,  77, 183, 281, 254, 142, 249,  81, 103, 312, 299, 171,\n","       337, 179, 208, 285, 155, 335, 342, 137, 243, 188,  69, 217, 273,\n","        16, 344,  88, 316, 132,  85, 118,  20, 244, 125, 348, 332, 164,\n","       280,  33, 256, 251, 100, 216, 278, 279, 287,   3, 204,  71, 269,\n","       334, 196,  72, 158,   7, 172, 173, 325, 297,  11, 295, 195, 180,\n","        89, 308,  48, 274,  43, 264, 139, 104, 230,  95, 241, 154, 231,\n","        37,  87, 229, 145,  75, 190, 286, 234, 101,  51, 199,  68, 283,\n","        29, 112, 326, 184, 296, 162, 189, 343, 303,  82, 201, 122,  73,\n","       108, 141,   6,  14, 257,  97, 330, 111,  39, 175, 213, 300,  67,\n","       311, 255, 152, 338, 349,  46, 130, 347, 177, 176, 320, 246, 220,\n","         1, 110, 121, 271, 277, 282,  53, 310, 322, 319, 307, 170,  98,\n","       167, 236, 309, 346, 131,  25, 209, 315,  49, 293,  52, 259, 106,\n","       181, 268, 267, 197, 126,  38,  34, 317,  83, 219, 266, 265, 245,\n","        94, 305, 324, 124, 105,  22,   2, 214, 146, 260,  80, 138, 238,\n","       331, 123, 233, 345, 192, 228, 115, 207, 288, 341, 144, 247, 242,\n","       148, 151,  64, 327, 136,  10,  78, 150, 329, 163,  21, 153, 147,\n","       321, 198,  63, 248,   9,  91, 222, 211,  79,  26, 302,  90, 340,\n","       140,  18,  96, 294, 127,  30,  66, 284,  13,  36, 262, 159,  62,\n","        60,  19, 350, 252,  28,   5, 232, 298, 275, 304, 215, 119,  99,\n","       133, 117, 351,  15,  44, 221, 250, 272,  86,   8, 339, 191,  12,\n","       227, 240,  92, 193, 174,  24,  41, 235, 289, 314, 333, 291, 182,\n","       313, 186,  57,  70,  59, 113, 160, 161, 128,  76, 178, 149, 135,\n","       116, 224,   4, 166, 102, 276,  27,  23, 318,  56,  84,  50, 187,\n","       200, 237, 143,  35, 239, 203, 223, 206, 114,  47, 323,  45, 185,\n","       134,  17,  65, 328, 253, 205, 292, 263,  40, 109, 258, 225,  93,\n","       157, 301, 212, 120,  74, 336,  55, 306, 270, 165, 290, 202,   0,\n","       194, 210, 226,  58, 261,  54,  61, 218,  31,  32,  42, 169, 156,\n","       129])"]},"metadata":{"tags":[]},"execution_count":138}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RZIY_54gHm7M","executionInfo":{"status":"ok","timestamp":1625223976586,"user_tz":-330,"elapsed":20,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}},"outputId":"1c920400-6509-4c8a-f21d-3d319d72c36c"},"source":["np.where(labels==325)"],"execution_count":139,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([59]),)"]},"metadata":{"tags":[]},"execution_count":139}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O96135r8GhD6","executionInfo":{"status":"ok","timestamp":1625223188358,"user_tz":-330,"elapsed":13,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}},"outputId":"126c0853-a395-46ee-ee39-e74ce573ebb4"},"source":["LE.transform([\"matter_properties of material_REFLECT\"])"],"execution_count":87,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([325])"]},"metadata":{"tags":[]},"execution_count":87}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lTZJoePzIQ1e","executionInfo":{"status":"ok","timestamp":1625223192614,"user_tz":-330,"elapsed":447,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}},"outputId":"039a1e41-4568-4ab8-bb19-d2de0178e064"},"source":["#unseen label proof\n","\n","np.where(test_data[\"QCLabel\"].values==\"matter_properties of material_REFLECT\")"],"execution_count":88,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([ 498,  644, 1102]),)"]},"metadata":{"tags":[]},"execution_count":88}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pq_ukFUBHW6q","executionInfo":{"status":"ok","timestamp":1625223194762,"user_tz":-330,"elapsed":376,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}},"outputId":"443c86af-110e-4515-eb71-84e347190417"},"source":["#unseen label proof\n","\n","LE.inverse_transform([325])"],"execution_count":89,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['matter_properties of material_REFLECT'], dtype=object)"]},"metadata":{"tags":[]},"execution_count":89}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t1bcG5-w5pud","executionInfo":{"status":"ok","timestamp":1625223195326,"user_tz":-330,"elapsed":10,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}},"outputId":"dc39edac-f09f-4f7c-de6d-5aaf5217e556"},"source":["LE.inverse_transform([297])"],"execution_count":90,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['matter_STATES_SOLID'], dtype=object)"]},"metadata":{"tags":[]},"execution_count":90}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GwH2zIAW8QR_","executionInfo":{"status":"ok","timestamp":1625223197096,"user_tz":-330,"elapsed":10,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}},"outputId":"19e3ddb0-18dd-4741-aea0-44e84b66003b"},"source":["LE.inverse_transform([318])"],"execution_count":91,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['matter_properties of material_DENSITY'], dtype=object)"]},"metadata":{"tags":[]},"execution_count":91}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JcL8BmXQO3be","executionInfo":{"status":"ok","timestamp":1625223197468,"user_tz":-330,"elapsed":5,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}},"outputId":"d1d0070e-f54c-4771-fc5c-472a29784eb6"},"source":["LE.inverse_transform([244])"],"execution_count":92,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['energy_LIGHT_COLINCOL'], dtype=object)"]},"metadata":{"tags":[]},"execution_count":92}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TyFx41ItO62C","executionInfo":{"status":"ok","timestamp":1625223200848,"user_tz":-330,"elapsed":419,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}},"outputId":"36b56bff-f245-401d-9c23-f358d3f0b4dc"},"source":["LE.inverse_transform([247])"],"execution_count":93,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['energy_LIGHT_REFRACT'], dtype=object)"]},"metadata":{"tags":[]},"execution_count":93}]},{"cell_type":"markdown","metadata":{"id":"CbohQzAhlYRN"},"source":[""]},{"cell_type":"code","metadata":{"id":"azkCfK-bCoXd","executionInfo":{"status":"ok","timestamp":1625223987406,"user_tz":-330,"elapsed":422,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}}},"source":["final_predictions = []\n","for prediction in predictions:\n","  final_predictions.append(LE.transform(prediction))\n"],"execution_count":140,"outputs":[]},{"cell_type":"code","metadata":{"id":"OQrlczKxMwzZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625223209523,"user_tz":-330,"elapsed":14,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}},"outputId":"2cbe84f6-cef4-408b-cd21-ebf8a44fc1bf"},"source":["final_predictions[-1]"],"execution_count":95,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 6,  8,  2, 26,  7])"]},"metadata":{"tags":[]},"execution_count":95}]},{"cell_type":"code","metadata":{"id":"2Sv7x6Ij66D6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625223210098,"user_tz":-330,"elapsed":10,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}},"outputId":"edd31dcc-aa91-4dd0-e5e2-8afb7ee3c974"},"source":["final_predictions[0]"],"execution_count":96,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([335, 351, 338, 348, 344])"]},"metadata":{"tags":[]},"execution_count":96}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"buXWtwdNHSYF","outputId":"c8847667-0852-4da7-ba4d-dfd56939e6d6"},"source":["#unseen label proof\n","final_predictions[1102]\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([297, 318, 332, 330, 319, 316, 327, 320, 329, 326])"]},"metadata":{"tags":[]},"execution_count":75}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dm6Zd6Q05cOO","outputId":"679edede-a327-422d-b4c2-38dadf4344f4"},"source":["final_predictions[498]\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([294, 297, 285, 295, 281, 287, 275, 296, 282, 283])"]},"metadata":{"tags":[]},"execution_count":76}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"exJ_nGI95fPl","outputId":"dd86f455-e4ce-499f-dcb8-32cebea34a93"},"source":["final_predictions[644]\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([247, 244, 245, 243, 246, 286, 249, 248, 231, 241])"]},"metadata":{"tags":[]},"execution_count":77}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"h2Yo8TNBxScC","outputId":"a0501844-0113-48f2-f823-0cf6c1b4b679"},"source":["test_data.loc[1102,\"Question\"]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'A boy can see his face when he looks into a calm pond. Which physical property of the pond makes this happen? (A) flexibility (B) reflectiveness (C) temperature (D) volume'"]},"metadata":{"tags":[]},"execution_count":81}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"xjieMNsa5i-V","outputId":"99965173-3866-4e6c-b3df-7bebcc187b9c"},"source":["test_data.loc[644,\"Question\"]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Which object best reflects light? (A) gray door (B) white floor (C) black sweater (D) brown carpet'"]},"metadata":{"tags":[]},"execution_count":80}]},{"cell_type":"code","metadata":{"id":"4NtFoF0n2tmx","executionInfo":{"status":"ok","timestamp":1625223994296,"user_tz":-330,"elapsed":625,"user":{"displayName":"anonymous anonymous","photoUrl":"","userId":"06251276198200574004"}}},"source":["test_labels = LE.transform(test_data[\"QCLabel\"].values)"],"execution_count":141,"outputs":[]},{"cell_type":"code","metadata":{"id":"Is-KTAENfB6C","colab":{"base_uri":"https://localhost:8080/"},"outputId":"06f83c11-f940-45b8-d51b-257b0272645e"},"source":["import tensorflow as tf\n","y_true = np.array(test_labels)\n","y_true = tf.identity(y_true)\n","y_pred = np.array(final_predictions)\n","y_pred = tf.identity(y_pred)\n","print(y_pred.shape,y_true.shape)\n","k = 20\n","recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, k=20)\n","precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, k=20)\n","\n","tmp_rank = tf.nn.top_k(y_pred, 20)\n","stream_vars = [i for i in tf.local_variables()]\n","\n","with tf.Session() as sess:\n","    sess.run(tf.local_variables_initializer())\n","    # print(\"precision\",sess.run(update_precision))\n","    # print(\"precision\",s|ess.run(precision))\n","\n","    print(\"update_recall: \",sess.run(update_recall ))\n","    print(\"recall\",sess.run(recall))\n","\n","    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n","    print(\"TMP_RANK: \",sess.run(tmp_rank))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(1400, 20) (1400,)\n","update_recall:  0.86\n","recall 0.86\n","STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1204.0, 196.0, 0.0, 0.0]\n","TMP_RANK:  TopKV2(values=array([[351, 350, 349, ..., 198,  17,   8],\n","       [285, 284, 283, ...,  39,  31,  27],\n","       [332, 331, 330, ..., 260, 241, 239],\n","       ...,\n","       [333, 317, 312, ..., 155, 146,  91],\n","       [139, 138, 137, ...,  96,  95,  86],\n","       [ 29,  26,  25, ...,   6,   2,   1]]), indices=array([[ 1,  8, 11, ..., 14, 17, 19],\n","       [ 9, 11,  5, ..., 19,  7, 16],\n","       [19, 16, 17, ..., 15, 12, 14],\n","       ...,\n","       [14, 17, 10, ..., 18, 13, 19],\n","       [16,  7,  2, ...,  9, 10,  8],\n","       [12,  3, 11, ...,  1,  2,  9]], dtype=int32))\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kI1jhndp6cEW","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a1a71fba-02d6-4ece-fa9b-f53f1fbe6626"},"source":["import tensorflow as tf\n","y_true = np.array(test_labels)\n","y_true = tf.identity(y_true)\n","y_pred = np.array(final_predictions)\n","y_pred = tf.identity(y_pred)\n","print(y_pred.shape,y_true.shape)\n","k = 8\n","recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 15)\n","precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 15)\n","\n","tmp_rank = tf.nn.top_k(y_pred, 15)\n","stream_vars = [i for i in tf.local_variables()]\n","\n","with tf.Session() as sess:\n","    sess.run(tf.local_variables_initializer())\n","    print(\"precision\",sess.run(update_precision))\n","    # print(\"precision\",sess.run(precision))\n","\n","    print(\"update_recall: \",sess.run(update_recall ))\n","    print(\"recall\",sess.run(recall))\n","\n","    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n","    print(\"TMP_RANK: \",sess.run(tmp_rank))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(1400, 15) (1400,)\n","precision 0.05480952380952381\n","update_recall:  0.8221428571428572\n","recall 0.8221428571428572\n","STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1151.0, 249.0, 1151.0, 19849.0]\n","TMP_RANK:  TopKV2(values=array([[351, 350, 349, ..., 336, 335, 198],\n","       [285, 284, 283, ...,  45,  44,  31],\n","       [300, 297, 296, ..., 279, 241, 239],\n","       ...,\n","       [333, 312, 298, ..., 187, 156, 146],\n","       [138, 137, 136, ...,  96,  95,  86],\n","       [ 29,  26,  25, ...,   6,   2,   1]]), indices=array([[ 1,  8, 11, ...,  5,  0, 14],\n","       [ 9, 11,  5, ...,  1,  2,  7],\n","       [10,  0, 11, ...,  9, 12, 14],\n","       ...,\n","       [14, 10, 12, ...,  8,  9, 13],\n","       [ 7,  2,  1, ...,  9,  8, 10],\n","       [12,  3, 11, ...,  1,  2,  9]], dtype=int32))\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EaA9z5n3mZz0","colab":{"base_uri":"https://localhost:8080/"},"outputId":"cf328652-24b7-44c8-fa71-a73805cd06ab"},"source":["import tensorflow as tf\n","y_true = np.array(test_labels)\n","y_true = tf.identity(y_true)\n","y_pred = np.array(final_predictions)\n","y_pred = tf.identity(y_pred)\n","print(y_pred.shape,y_true.shape)\n","k = 8\n","recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 10)\n","precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 10)\n","\n","tmp_rank = tf.nn.top_k(y_pred, 10)\n","stream_vars = [i for i in tf.local_variables()]\n","\n","with tf.Session() as sess:\n","    sess.run(tf.local_variables_initializer())\n","    print(\"precision\",sess.run(update_precision))\n","    # print(\"precision\",sess.run(precision))\n","\n","    print(\"update_recall: \",sess.run(update_recall ))\n","    print(\"recall\",sess.run(recall))\n","\n","    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n","    print(\"TMP_RANK: \",sess.run(y_pred))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(1400, 10) (1400,)\n","precision 0.07292857142857143\n","update_recall:  0.7292857142857143\n","recall 0.7292857142857143\n","STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1021.0, 379.0, 1021.0, 12979.0]\n","TMP_RANK:  [[335 351 344 ... 342 350 337]\n"," [ 47  45  44 ...  31  76 285]\n"," [297 294 285 ... 280 284 279]\n"," ...\n"," [194 188 192 ... 195 187 156]\n"," [122 136 137 ... 138  96  95]\n"," [  6   8   2 ...  23  17   1]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lkKaMSEJnJUX","colab":{"base_uri":"https://localhost:8080/"},"outputId":"afa62578-7904-4da7-87ab-58de73f42344"},"source":["import tensorflow as tf\n","y_true = np.array(test_labels)\n","y_true = tf.identity(y_true)\n","y_pred = np.array(final_predictions)\n","y_pred = tf.identity(y_pred)\n","print(y_pred.shape,y_true.shape)\n","k = 8\n","recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 5)\n","precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 5)\n","\n","tmp_rank = tf.nn.top_k(y_pred, 5)\n","stream_vars = [i for i in tf.local_variables()]\n","\n","with tf.Session() as sess:\n","    sess.run(tf.local_variables_initializer())\n","    print(\"precision\",sess.run(update_precision))\n","    # print(\"precision\",sess.run(precision))\n","\n","    print(\"update_recall: \",sess.run(update_recall ))\n","    print(\"recall\",sess.run(recall))\n","\n","    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n","    print(\"TMP_RANK: \",sess.run(tmp_rank))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(1400, 5) (1400,)\n","precision 0.11157142857142857\n","update_recall:  0.5578571428571428\n","recall 0.5578571428571428\n","STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 781.0, 619.0, 781.0, 6219.0]\n","TMP_RANK:  TopKV2(values=array([[351, 344, 338, 336, 335],\n","       [ 48,  47,  46,  45,  44],\n","       [297, 295, 294, 285, 281],\n","       ...,\n","       [194, 192, 191, 189, 188],\n","       [137, 136, 125, 124, 122],\n","       [ 26,   8,   7,   6,   2]]), indices=array([[1, 2, 4, 3, 0],\n","       [4, 0, 3, 1, 2],\n","       [0, 3, 1, 2, 4],\n","       ...,\n","       [0, 2, 4, 3, 1],\n","       [1, 2, 4, 3, 0],\n","       [3, 0, 4, 1, 2]], dtype=int32))\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oPqYvRNIrRg1","colab":{"base_uri":"https://localhost:8080/"},"outputId":"95067021-9e00-48f6-acec-3e3d624024f5"},"source":["import tensorflow as tf\n","y_true = np.array(test_labels)\n","y_true = tf.identity(y_true)\n","y_pred = np.array(final_predictions)\n","y_pred = tf.identity(y_pred)\n","print(y_pred.shape,y_true.shape)\n","k = 8\n","recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 1)\n","precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 1)\n","\n","tmp_rank = tf.nn.top_k(y_pred, 1)\n","stream_vars = [i for i in tf.local_variables()]\n","\n","with tf.Session() as sess:\n","    sess.run(tf.local_variables_initializer())\n","    print(\"precision\",sess.run(update_precision))\n","    # print(\"precision\",sess.run(precision))\n","\n","    print(\"update_recall: \",sess.run(update_recall ))\n","    print(\"recall\",sess.run(recall))\n","\n","    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n","    print(\"TMP_RANK: \",sess.run(tmp_rank))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(4784, 1) (4784,)\n","precision 0.3867056856187291\n","update_recall:  0.3867056856187291\n","recall 0.3867056856187291\n","STREAM_VARS:  [1850.0, 2934.0, 1850.0, 2934.0]\n","TMP_RANK:  TopKV2(values=array([[ 73],\n","       [222],\n","       [116],\n","       ...,\n","       [ 49],\n","       [ 15],\n","       [152]]), indices=array([[0],\n","       [0],\n","       [0],\n","       ...,\n","       [0],\n","       [0],\n","       [0]], dtype=int32))\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8nc37NBPPkv4"},"source":["def get_cleaned_taxonomy_lo(taxonomy):\n","  cleaned_taxonomy = []\n","  for value in taxonomy:\n","      value = ' '.join(value.lower().split(\">>\"))\n","      # taxonomy_words = [inflection.singularize(val)  for token in value for val in token.split(\" \") if val.isalpha()]\n","      cleaned_taxonomy.append( value )\n","  return cleaned_taxonomy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"uj6s6uerPkv4","outputId":"c179c3e1-64b9-4f0e-960b-07b3b2ddc6a2"},"source":["test_labels = list(set(labels))\n","test_set_labels = get_cleaned_taxonomy_lo(test_labels)\n","test_set_labels[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'science cell structure and functions'"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"CUzf5IbMDfHp"},"source":["#### LO classification o/p"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YnSjuzMDDhwe","outputId":"150f4b9c-5504-4ab8-d04b-10322c8a00c5"},"source":["import tensorflow as tf\n","y_true = np.array(labels)\n","y_true = tf.identity(y_true)\n","y_pred = np.array(final_predictions)\n","y_pred = tf.identity(y_pred)\n","print(y_pred.shape,y_true.shape)\n","k = 8\n","recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 1)\n","precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 1)\n","\n","tmp_rank = tf.nn.top_k(y_pred, 1)\n","stream_vars = [i for i in tf.local_variables()]\n","\n","with tf.Session() as sess:\n","    sess.run(tf.local_variables_initializer())\n","    print(\"precision\",sess.run(update_precision))\n","    # print(\"precision\",sess.run(precision))\n","\n","    print(\"update_recall: \",sess.run(update_recall ))\n","    print(\"recall\",sess.run(recall))\n","\n","    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n","    print(\"TMP_RANK: \",sess.run(tmp_rank))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(417, 1) (417,)\n","precision 0.6211031175059952\n","update_recall:  0.6211031175059952\n","recall 0.6211031175059952\n","STREAM_VARS:  [259.0, 158.0, 259.0, 158.0]\n","TMP_RANK:  TopKV2(values=array([[ 5],\n","       [ 5],\n","       [ 5],\n","       [ 5],\n","       [ 7],\n","       [ 5],\n","       [ 5],\n","       [ 0],\n","       [ 5],\n","       [ 5],\n","       [ 7],\n","       [ 5],\n","       [ 0],\n","       [ 5],\n","       [27],\n","       [ 4],\n","       [ 5],\n","       [ 0],\n","       [21],\n","       [27],\n","       [27],\n","       [27],\n","       [27],\n","       [27],\n","       [29],\n","       [27],\n","       [ 5],\n","       [27],\n","       [ 6],\n","       [27],\n","       [27],\n","       [27],\n","       [27],\n","       [27],\n","       [ 6],\n","       [ 1],\n","       [ 1],\n","       [ 1],\n","       [ 2],\n","       [ 6],\n","       [ 6],\n","       [43],\n","       [34],\n","       [41],\n","       [41],\n","       [34],\n","       [31],\n","       [20],\n","       [20],\n","       [20],\n","       [22],\n","       [45],\n","       [22],\n","       [45],\n","       [45],\n","       [45],\n","       [11],\n","       [ 9],\n","       [ 9],\n","       [26],\n","       [ 9],\n","       [ 9],\n","       [ 9],\n","       [ 9],\n","       [18],\n","       [18],\n","       [18],\n","       [18],\n","       [18],\n","       [18],\n","       [18],\n","       [18],\n","       [17],\n","       [18],\n","       [18],\n","       [18],\n","       [18],\n","       [18],\n","       [17],\n","       [17],\n","       [46],\n","       [17],\n","       [17],\n","       [17],\n","       [23],\n","       [23],\n","       [23],\n","       [23],\n","       [23],\n","       [23],\n","       [25],\n","       [23],\n","       [23],\n","       [23],\n","       [23],\n","       [25],\n","       [23],\n","       [23],\n","       [23],\n","       [23],\n","       [23],\n","       [19],\n","       [19],\n","       [26],\n","       [26],\n","       [26],\n","       [26],\n","       [12],\n","       [26],\n","       [12],\n","       [26],\n","       [26],\n","       [26],\n","       [26],\n","       [26],\n","       [26],\n","       [26],\n","       [26],\n","       [26],\n","       [26],\n","       [26],\n","       [26],\n","       [47],\n","       [42],\n","       [ 8],\n","       [33],\n","       [35],\n","       [35],\n","       [42],\n","       [42],\n","       [21],\n","       [21],\n","       [14],\n","       [47],\n","       [21],\n","       [21],\n","       [21],\n","       [28],\n","       [28],\n","       [28],\n","       [28],\n","       [39],\n","       [39],\n","       [21],\n","       [21],\n","       [21],\n","       [21],\n","       [21],\n","       [21],\n","       [21],\n","       [27],\n","       [27],\n","       [ 1],\n","       [ 5],\n","       [ 1],\n","       [ 1],\n","       [ 1],\n","       [ 1],\n","       [ 1],\n","       [ 1],\n","       [ 1],\n","       [ 1],\n","       [41],\n","       [ 1],\n","       [41],\n","       [ 1],\n","       [ 1],\n","       [41],\n","       [ 1],\n","       [ 3],\n","       [ 3],\n","       [ 3],\n","       [ 3],\n","       [45],\n","       [ 3],\n","       [ 3],\n","       [ 3],\n","       [ 3],\n","       [ 3],\n","       [18],\n","       [45],\n","       [45],\n","       [45],\n","       [45],\n","       [45],\n","       [45],\n","       [45],\n","       [45],\n","       [ 9],\n","       [11],\n","       [17],\n","       [11],\n","       [11],\n","       [17],\n","       [17],\n","       [31],\n","       [31],\n","       [31],\n","       [31],\n","       [31],\n","       [13],\n","       [16],\n","       [15],\n","       [13],\n","       [13],\n","       [ 5],\n","       [16],\n","       [13],\n","       [16],\n","       [16],\n","       [16],\n","       [16],\n","       [16],\n","       [16],\n","       [16],\n","       [16],\n","       [47],\n","       [47],\n","       [47],\n","       [47],\n","       [47],\n","       [47],\n","       [38],\n","       [38],\n","       [38],\n","       [38],\n","       [38],\n","       [31],\n","       [ 1],\n","       [38],\n","       [38],\n","       [38],\n","       [38],\n","       [38],\n","       [38],\n","       [46],\n","       [46],\n","       [30],\n","       [30],\n","       [46],\n","       [46],\n","       [46],\n","       [46],\n","       [46],\n","       [47],\n","       [ 7],\n","       [35],\n","       [32],\n","       [42],\n","       [32],\n","       [42],\n","       [20],\n","       [20],\n","       [20],\n","       [20],\n","       [10],\n","       [10],\n","       [42],\n","       [10],\n","       [10],\n","       [20],\n","       [38],\n","       [20],\n","       [20],\n","       [10],\n","       [10],\n","       [10],\n","       [10],\n","       [10],\n","       [20],\n","       [10],\n","       [10],\n","       [21],\n","       [10],\n","       [10],\n","       [30],\n","       [ 8],\n","       [30],\n","       [30],\n","       [30],\n","       [30],\n","       [30],\n","       [33],\n","       [30],\n","       [30],\n","       [32],\n","       [32],\n","       [32],\n","       [43],\n","       [43],\n","       [43],\n","       [43],\n","       [43],\n","       [43],\n","       [43],\n","       [27],\n","       [27],\n","       [26],\n","       [27],\n","       [27],\n","       [27],\n","       [27],\n","       [27],\n","       [27],\n","       [ 6],\n","       [39],\n","       [ 6],\n","       [ 6],\n","       [ 6],\n","       [ 6],\n","       [ 7],\n","       [ 7],\n","       [ 7],\n","       [ 7],\n","       [ 7],\n","       [ 7],\n","       [23],\n","       [ 6],\n","       [39],\n","       [32],\n","       [ 7],\n","       [ 8],\n","       [ 8],\n","       [ 8],\n","       [42],\n","       [ 8],\n","       [ 3],\n","       [ 3],\n","       [ 3],\n","       [ 3],\n","       [ 3],\n","       [ 3],\n","       [ 3],\n","       [ 3],\n","       [18],\n","       [18],\n","       [18],\n","       [36],\n","       [36],\n","       [36],\n","       [36],\n","       [18],\n","       [36],\n","       [36],\n","       [36],\n","       [36],\n","       [18],\n","       [18],\n","       [18],\n","       [14],\n","       [14],\n","       [16],\n","       [31],\n","       [14],\n","       [14],\n","       [14],\n","       [14],\n","       [14],\n","       [15],\n","       [15],\n","       [15],\n","       [15],\n","       [15],\n","       [15],\n","       [15],\n","       [15],\n","       [15],\n","       [15],\n","       [15],\n","       [15],\n","       [15],\n","       [38],\n","       [38],\n","       [38],\n","       [38],\n","       [38],\n","       [38],\n","       [38],\n","       [38],\n","       [38],\n","       [26],\n","       [26],\n","       [26],\n","       [26],\n","       [26],\n","       [26],\n","       [26],\n","       [26],\n","       [26],\n","       [26],\n","       [26],\n","       [37],\n","       [23],\n","       [23],\n","       [23],\n","       [23],\n","       [23],\n","       [23],\n","       [23],\n","       [23],\n","       [40],\n","       [40],\n","       [31],\n","       [40],\n","       [40],\n","       [40],\n","       [40],\n","       [16],\n","       [40],\n","       [40],\n","       [40],\n","       [35],\n","       [35],\n","       [35],\n","       [35],\n","       [35],\n","       [35]]), indices=array([[0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0]], dtype=int32))\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mXaBO4GEDhy_","outputId":"f4433f61-bf81-478f-c8a9-03424fba84f2"},"source":["import tensorflow as tf\n","y_true = np.array(labels)\n","y_true = tf.identity(y_true)\n","y_pred = np.array(final_predictions)\n","y_pred = tf.identity(y_pred)\n","print(y_pred.shape,y_true.shape)\n","k = 8\n","recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 2)\n","precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 2)\n","\n","tmp_rank = tf.nn.top_k(y_pred, 2)\n","stream_vars = [i for i in tf.local_variables()]\n","\n","with tf.Session() as sess:\n","    sess.run(tf.local_variables_initializer())\n","    print(\"precision\",sess.run(update_precision))\n","    # print(\"precision\",sess.run(precision))\n","\n","    print(\"update_recall: \",sess.run(update_recall ))\n","    print(\"recall\",sess.run(recall))\n","\n","    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n","    print(\"TMP_RANK: \",sess.run(tmp_rank))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(417, 2) (417,)\n","precision 0.4196642685851319\n","update_recall:  0.8393285371702638\n","recall 0.8393285371702638\n","STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 350.0, 67.0, 350.0, 484.0]\n","TMP_RANK:  TopKV2(values=array([[ 5,  1],\n","       [ 5,  1],\n","       [27,  5],\n","       [ 5,  1],\n","       [ 7,  5],\n","       [ 7,  5],\n","       [ 5,  1],\n","       [ 5,  0],\n","       [ 5,  1],\n","       [ 7,  5],\n","       [ 7,  5],\n","       [27,  5],\n","       [45,  0],\n","       [29,  5],\n","       [29, 27],\n","       [26,  4],\n","       [21,  5],\n","       [27,  0],\n","       [27, 21],\n","       [27,  0],\n","       [29, 27],\n","       [29, 27],\n","       [29, 27],\n","       [29, 27],\n","       [29, 27],\n","       [29, 27],\n","       [27,  5],\n","       [29, 27],\n","       [29,  6],\n","       [29, 27],\n","       [29, 27],\n","       [27, 26],\n","       [29, 27],\n","       [29, 27],\n","       [39,  6],\n","       [27,  1],\n","       [27,  1],\n","       [ 2,  1],\n","       [ 2,  0],\n","       [39,  6],\n","       [ 6,  2],\n","       [43,  2],\n","       [41, 34],\n","       [41, 34],\n","       [41, 34],\n","       [41, 34],\n","       [31, 13],\n","       [22, 20],\n","       [30, 20],\n","       [30, 20],\n","       [36, 22],\n","       [45, 22],\n","       [45, 22],\n","       [45, 22],\n","       [45, 22],\n","       [45,  8],\n","       [18, 11],\n","       [14,  9],\n","       [33,  9],\n","       [26,  9],\n","       [45,  9],\n","       [ 9,  1],\n","       [18,  9],\n","       [44,  9],\n","       [46, 18],\n","       [18, 17],\n","       [36, 18],\n","       [46, 18],\n","       [36, 18],\n","       [46, 18],\n","       [46, 18],\n","       [46, 18],\n","       [18, 17],\n","       [36, 18],\n","       [18, 17],\n","       [36, 18],\n","       [46, 18],\n","       [46, 18],\n","       [17, 11],\n","       [17, 11],\n","       [46, 19],\n","       [18, 17],\n","       [17, 11],\n","       [17, 11],\n","       [24, 23],\n","       [24, 23],\n","       [24, 23],\n","       [24, 23],\n","       [24, 23],\n","       [24, 23],\n","       [25, 19],\n","       [24, 23],\n","       [24, 23],\n","       [24, 23],\n","       [24, 23],\n","       [25, 23],\n","       [24, 23],\n","       [24, 23],\n","       [24, 23],\n","       [24, 23],\n","       [24, 23],\n","       [23, 19],\n","       [23, 19],\n","       [26,  4],\n","       [26, 12],\n","       [26, 12],\n","       [26, 12],\n","       [26, 12],\n","       [26, 12],\n","       [26, 12],\n","       [26,  4],\n","       [26,  4],\n","       [26,  4],\n","       [26,  4],\n","       [26,  4],\n","       [26,  4],\n","       [26,  4],\n","       [26,  4],\n","       [26,  4],\n","       [26,  4],\n","       [26,  4],\n","       [26,  4],\n","       [47, 39],\n","       [42, 33],\n","       [33,  8],\n","       [33, 22],\n","       [35, 33],\n","       [43, 35],\n","       [42, 35],\n","       [42,  6],\n","       [43, 21],\n","       [28, 21],\n","       [28, 14],\n","       [47, 39],\n","       [21,  1],\n","       [28, 21],\n","       [28, 21],\n","       [28, 21],\n","       [28, 21],\n","       [33, 28],\n","       [28, 21],\n","       [39,  7],\n","       [47, 39],\n","       [21,  1],\n","       [21,  1],\n","       [28, 21],\n","       [28, 21],\n","       [43, 21],\n","       [28, 21],\n","       [28, 21],\n","       [27,  1],\n","       [27,  1],\n","       [21,  1],\n","       [ 5,  1],\n","       [34,  1],\n","       [41,  1],\n","       [41,  1],\n","       [34,  1],\n","       [41,  1],\n","       [41,  1],\n","       [27,  1],\n","       [21,  1],\n","       [41,  1],\n","       [41,  1],\n","       [41,  1],\n","       [41,  1],\n","       [41,  1],\n","       [41,  1],\n","       [41,  1],\n","       [44,  3],\n","       [44,  3],\n","       [44,  3],\n","       [45,  3],\n","       [45, 18],\n","       [44,  3],\n","       [44,  3],\n","       [44,  3],\n","       [45,  3],\n","       [44,  3],\n","       [18, 11],\n","       [45,  3],\n","       [45, 11],\n","       [45,  3],\n","       [45, 22],\n","       [45,  3],\n","       [45,  3],\n","       [45,  3],\n","       [45,  3],\n","       [45,  9],\n","       [17, 11],\n","       [17, 11],\n","       [17, 11],\n","       [45, 11],\n","       [17, 11],\n","       [17, 11],\n","       [31, 13],\n","       [31, 13],\n","       [31, 16],\n","       [31, 13],\n","       [31, 13],\n","       [14, 13],\n","       [16, 13],\n","       [15, 14],\n","       [14, 13],\n","       [31, 13],\n","       [14,  5],\n","       [16, 13],\n","       [14, 13],\n","       [16, 13],\n","       [16, 13],\n","       [16, 13],\n","       [16, 14],\n","       [16, 13],\n","       [16, 13],\n","       [16, 14],\n","       [16, 13],\n","       [47, 14],\n","       [47, 39],\n","       [47, 39],\n","       [47, 39],\n","       [47, 39],\n","       [47, 39],\n","       [38, 31],\n","       [38, 23],\n","       [38, 31],\n","       [38, 31],\n","       [38, 23],\n","       [38, 31],\n","       [25,  1],\n","       [38, 25],\n","       [38, 31],\n","       [38, 31],\n","       [38, 31],\n","       [38, 23],\n","       [38, 23],\n","       [46, 30],\n","       [46, 30],\n","       [46, 30],\n","       [46, 30],\n","       [46, 30],\n","       [46, 30],\n","       [46, 30],\n","       [46, 30],\n","       [46, 30],\n","       [47, 39],\n","       [35,  7],\n","       [35, 32],\n","       [33, 32],\n","       [42, 20],\n","       [42, 32],\n","       [42, 32],\n","       [20, 10],\n","       [20, 10],\n","       [20, 10],\n","       [20, 10],\n","       [20, 10],\n","       [20, 10],\n","       [42, 20],\n","       [20, 10],\n","       [20, 10],\n","       [20, 10],\n","       [38,  8],\n","       [20, 17],\n","       [20, 10],\n","       [20, 10],\n","       [20, 10],\n","       [20, 10],\n","       [20, 10],\n","       [42, 10],\n","       [20, 10],\n","       [42, 10],\n","       [20, 10],\n","       [21, 10],\n","       [20, 10],\n","       [20, 10],\n","       [33, 30],\n","       [11,  8],\n","       [33, 30],\n","       [30, 11],\n","       [46, 30],\n","       [46, 30],\n","       [33, 30],\n","       [33, 30],\n","       [46, 30],\n","       [33, 30],\n","       [42, 32],\n","       [32, 30],\n","       [32, 30],\n","       [43, 27],\n","       [43,  6],\n","       [43,  6],\n","       [43, 27],\n","       [43,  6],\n","       [43, 27],\n","       [43, 27],\n","       [29, 27],\n","       [29, 27],\n","       [26,  4],\n","       [29, 27],\n","       [29, 27],\n","       [29, 27],\n","       [29, 27],\n","       [29, 27],\n","       [27,  6],\n","       [39,  6],\n","       [39,  6],\n","       [39,  6],\n","       [39,  6],\n","       [39,  6],\n","       [39,  6],\n","       [ 7,  6],\n","       [ 7,  6],\n","       [15,  7],\n","       [ 7,  6],\n","       [15,  7],\n","       [ 7,  6],\n","       [24, 23],\n","       [39,  6],\n","       [39,  6],\n","       [35, 32],\n","       [ 7,  6],\n","       [32,  8],\n","       [11,  8],\n","       [42,  8],\n","       [42,  8],\n","       [42,  8],\n","       [45,  3],\n","       [44,  3],\n","       [44,  3],\n","       [44,  3],\n","       [44,  3],\n","       [45,  3],\n","       [44,  3],\n","       [45,  3],\n","       [36, 18],\n","       [36, 18],\n","       [36, 18],\n","       [36, 18],\n","       [36, 18],\n","       [36, 18],\n","       [36, 18],\n","       [36, 18],\n","       [36, 18],\n","       [36, 18],\n","       [36, 18],\n","       [36, 18],\n","       [46, 18],\n","       [36, 18],\n","       [36, 18],\n","       [14, 13],\n","       [14, 13],\n","       [16, 14],\n","       [31, 13],\n","       [14, 13],\n","       [14, 13],\n","       [16, 14],\n","       [16, 14],\n","       [16, 14],\n","       [15, 14],\n","       [15, 14],\n","       [15, 14],\n","       [15, 14],\n","       [15, 14],\n","       [15, 14],\n","       [15, 14],\n","       [15, 14],\n","       [15, 14],\n","       [15, 14],\n","       [15, 14],\n","       [15, 14],\n","       [15, 14],\n","       [38, 31],\n","       [38, 31],\n","       [38, 31],\n","       [38, 31],\n","       [38, 31],\n","       [38, 31],\n","       [38, 31],\n","       [38, 31],\n","       [38, 31],\n","       [26,  4],\n","       [26,  4],\n","       [26,  4],\n","       [26,  4],\n","       [37, 26],\n","       [37, 26],\n","       [26,  4],\n","       [26,  4],\n","       [26,  4],\n","       [37, 26],\n","       [26,  4],\n","       [37, 26],\n","       [24, 23],\n","       [24, 23],\n","       [24, 23],\n","       [24, 23],\n","       [24, 23],\n","       [24, 23],\n","       [24, 23],\n","       [24, 23],\n","       [40, 23],\n","       [40, 23],\n","       [31, 25],\n","       [40, 19],\n","       [40, 31],\n","       [40, 23],\n","       [41, 40],\n","       [40, 16],\n","       [40, 16],\n","       [40, 16],\n","       [40, 39],\n","       [35, 32],\n","       [42, 35],\n","       [35, 32],\n","       [35,  7],\n","       [42, 35],\n","       [42, 35]]), indices=array([[0, 1],\n","       [0, 1],\n","       [1, 0],\n","       [0, 1],\n","       [0, 1],\n","       [1, 0],\n","       [0, 1],\n","       [1, 0],\n","       [0, 1],\n","       [1, 0],\n","       [0, 1],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [0, 1],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [0, 1],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [0, 1],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [0, 1],\n","       [1, 0],\n","       [0, 1],\n","       [0, 1],\n","       [1, 0],\n","       [0, 1],\n","       [0, 1],\n","       [1, 0],\n","       [0, 1],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [0, 1],\n","       [1, 0],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [0, 1],\n","       [1, 0],\n","       [0, 1],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [0, 1],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [0, 1],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [1, 0],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [1, 0],\n","       [1, 0],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [1, 0],\n","       [0, 1],\n","       [1, 0],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [1, 0],\n","       [0, 1],\n","       [0, 1],\n","       [1, 0],\n","       [0, 1],\n","       [0, 1],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [0, 1],\n","       [0, 1],\n","       [1, 0],\n","       [1, 0],\n","       [0, 1],\n","       [0, 1],\n","       [1, 0],\n","       [0, 1],\n","       [0, 1],\n","       [1, 0],\n","       [0, 1],\n","       [0, 1],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [0, 1],\n","       [0, 1],\n","       [1, 0],\n","       [0, 1],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [0, 1],\n","       [1, 0],\n","       [0, 1],\n","       [1, 0],\n","       [1, 0],\n","       [0, 1],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [0, 1],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [1, 0],\n","       [1, 0],\n","       [0, 1],\n","       [1, 0],\n","       [1, 0],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [1, 0],\n","       [0, 1],\n","       [0, 1],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [0, 1],\n","       [1, 0],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [1, 0],\n","       [1, 0],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [1, 0],\n","       [1, 0],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [1, 0],\n","       [0, 1],\n","       [1, 0],\n","       [0, 1],\n","       [1, 0],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [1, 0],\n","       [1, 0],\n","       [0, 1],\n","       [1, 0],\n","       [1, 0],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [0, 1],\n","       [1, 0],\n","       [1, 0],\n","       [0, 1],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [0, 1],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [0, 1],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [1, 0],\n","       [1, 0],\n","       [0, 1],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [0, 1],\n","       [1, 0],\n","       [0, 1],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [0, 1],\n","       [0, 1],\n","       [1, 0],\n","       [0, 1],\n","       [1, 0],\n","       [0, 1],\n","       [0, 1],\n","       [1, 0],\n","       [0, 1],\n","       [1, 0],\n","       [0, 1],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [0, 1],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [1, 0],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [1, 0],\n","       [1, 0],\n","       [1, 0],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [1, 0],\n","       [1, 0],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [1, 0],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [1, 0],\n","       [1, 0],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [1, 0],\n","       [0, 1],\n","       [0, 1],\n","       [1, 0],\n","       [1, 0]], dtype=int32))\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lVAO6-ddDh1z","outputId":"ec68de60-095b-426e-a81d-9e217c565664"},"source":["import tensorflow as tf\n","y_true = np.array(labels)\n","y_true = tf.identity(y_true)\n","y_pred = np.array(final_predictions)\n","y_pred = tf.identity(y_pred)\n","print(y_pred.shape,y_true.shape)\n","k = 8\n","recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 3)\n","precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 3)\n","\n","tmp_rank = tf.nn.top_k(y_pred,3)\n","stream_vars = [i for i in tf.local_variables()]\n","\n","with tf.Session() as sess:\n","    sess.run(tf.local_variables_initializer())\n","    print(\"precision\",sess.run(update_precision))\n","    # print(\"precision\",sess.run(precision))\n","\n","    print(\"update_recall: \",sess.run(update_recall ))\n","    print(\"recall\",sess.run(recall))\n","\n","    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n","    print(\"TMP_RANK: \",sess.run(tmp_rank))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(417, 3) (417,)\n","precision 0.31254996003197444\n","update_recall:  0.9376498800959233\n","recall 0.9376498800959233\n","STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 391.0, 26.0, 391.0, 860.0]\n","TMP_RANK:  TopKV2(values=array([[17,  5,  1],\n","       [17,  5,  1],\n","       [27,  5,  1],\n","       ...,\n","       [35, 32,  7],\n","       [42, 35, 32],\n","       [42, 35, 20]]), indices=array([[2, 0, 1],\n","       [2, 0, 1],\n","       [1, 0, 2],\n","       ...,\n","       [0, 2, 1],\n","       [1, 0, 2],\n","       [1, 0, 2]], dtype=int32))\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rLX7Wx9CDh4r","outputId":"2b5f70e0-187e-4a18-c319-eec05561dca5"},"source":["import tensorflow as tf\n","y_true = np.array(labels)\n","y_true = tf.identity(y_true)\n","y_pred = np.array(final_predictions)\n","y_pred = tf.identity(y_pred)\n","print(y_pred.shape,y_true.shape)\n","k = 8\n","recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 4)\n","precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 4)\n","\n","tmp_rank = tf.nn.top_k(y_pred, 4)\n","stream_vars = [i for i in tf.local_variables()]\n","\n","with tf.Session() as sess:\n","    sess.run(tf.local_variables_initializer())\n","    print(\"precision\",sess.run(update_precision))\n","    # print(\"precision\",sess.run(precision))\n","\n","    print(\"update_recall: \",sess.run(update_recall ))\n","    print(\"recall\",sess.run(recall))\n","\n","    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n","    print(\"TMP_RANK: \",sess.run(tmp_rank))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(417, 4) (417,)\n","precision 0.24040767386091128\n","update_recall:  0.9616306954436451\n","recall 0.9616306954436451\n","STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 401.0, 16.0, 401.0, 1267.0]\n","TMP_RANK:  TopKV2(values=array([[29, 17,  5,  1],\n","       [29, 17,  5,  1],\n","       [27,  5,  2,  1],\n","       ...,\n","       [35, 32,  7,  6],\n","       [42, 35, 32,  6],\n","       [42, 35, 32, 20]]), indices=array([[3, 2, 0, 1],\n","       [3, 2, 0, 1],\n","       [1, 0, 3, 2],\n","       ...,\n","       [0, 2, 1, 3],\n","       [1, 0, 2, 3],\n","       [1, 0, 3, 2]], dtype=int32))\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eV492QBBDh7l","outputId":"cde23bc3-7c72-4ff4-c4b9-c313477631d0"},"source":["import tensorflow as tf\n","y_true = np.array(labels)\n","y_true = tf.identity(y_true)\n","y_pred = np.array(final_predictions)\n","y_pred = tf.identity(y_pred)\n","print(y_pred.shape,y_true.shape)\n","k = 8\n","recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 5)\n","precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 5)\n","\n","tmp_rank = tf.nn.top_k(y_pred, 5)\n","stream_vars = [i for i in tf.local_variables()]\n","\n","with tf.Session() as sess:\n","    sess.run(tf.local_variables_initializer())\n","    print(\"precision\",sess.run(update_precision))\n","    # print(\"precision\",sess.run(precision))\n","\n","    print(\"update_recall: \",sess.run(update_recall ))\n","    print(\"recall\",sess.run(recall))\n","\n","    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n","    print(\"TMP_RANK: \",sess.run(tmp_rank))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(417, 5) (417,)\n","precision 0.19424460431654678\n","update_recall:  0.9712230215827338\n","recall 0.9712230215827338\n","STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 405.0, 12.0, 405.0, 1680.0]\n","TMP_RANK:  TopKV2(values=array([[29, 27, 17,  5,  1],\n","       [29, 27, 17,  5,  1],\n","       [29, 27,  5,  2,  1],\n","       ...,\n","       [35, 33, 32,  7,  6],\n","       [42, 35, 32,  7,  6],\n","       [42, 35, 32, 20, 12]]), indices=array([[3, 4, 2, 0, 1],\n","       [3, 4, 2, 0, 1],\n","       [4, 1, 0, 3, 2],\n","       ...,\n","       [0, 4, 2, 1, 3],\n","       [1, 0, 2, 4, 3],\n","       [1, 0, 3, 2, 4]], dtype=int32))\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oGbi4DEZkwhh","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ce443a41-50aa-4372-d392-a11bb6f36380"},"source":["y_true = np.array(labels)\n","final_predictions = np.array(final_predictions).squeeze()\n","final_predictions.shape\n","len(final_predictions[final_predictions==y_true])/len(labels)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.44544314381270905"]},"metadata":{"tags":[]},"execution_count":148}]},{"cell_type":"code","metadata":{"id":"IN1UA_4uBu_S"},"source":["categories"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TdD0JiYgEX4k"},"source":["!cp /content/model_euclidean_glove_QC.zip \"/content/drive/My Drive/research_lo_content_taxonomy_classification\""],"execution_count":null,"outputs":[]}]}