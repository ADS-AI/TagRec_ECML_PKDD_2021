{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "euclidean_taxonomy_prediction_dual_BERT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f7c1f99e9646429e9917b5407139fca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_add3e217b8164a1b9ad4f8a765561c9c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_83a7159241734018b5b4ca6161164abf",
              "IPY_MODEL_74130373d17b426fae5b0c6704d46c1f"
            ]
          }
        },
        "add3e217b8164a1b9ad4f8a765561c9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "83a7159241734018b5b4ca6161164abf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_71a5161606e5495fb86ef8b59ff2bcbc",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6e97ba95fdf04aeb9b6450377dc1bf7b"
          }
        },
        "74130373d17b426fae5b0c6704d46c1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e206ad602a0e4f0cb54d370b47e54ab6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 1.49MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5fe895417e934bb19ae66eefcad683f9"
          }
        },
        "71a5161606e5495fb86ef8b59ff2bcbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6e97ba95fdf04aeb9b6450377dc1bf7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e206ad602a0e4f0cb54d370b47e54ab6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5fe895417e934bb19ae66eefcad683f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c137e653d2d94a259dd7ae82bd76b293": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1f9ea2dc166f4b2f862d176875ce8383",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0f4700f2641d454998e444bb9aa2ec72",
              "IPY_MODEL_46eb0a81e9eb4a5a9ce739b89663422a"
            ]
          }
        },
        "1f9ea2dc166f4b2f862d176875ce8383": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0f4700f2641d454998e444bb9aa2ec72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8256dc8c6ca24ccfbacd97b87fc23176",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d549b2648aec40628a2166508403116b"
          }
        },
        "46eb0a81e9eb4a5a9ce739b89663422a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_372787f49c494c40a7357bea7d9023b2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 2.25kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_21362ce6683140fd8812691239b969b0"
          }
        },
        "8256dc8c6ca24ccfbacd97b87fc23176": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d549b2648aec40628a2166508403116b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "372787f49c494c40a7357bea7d9023b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "21362ce6683140fd8812691239b969b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e5043b1147df43e488479fac9d4774e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_92a40e6e73d14d4e862198668163897b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1f47c690023d4a73a6a60b50a14a1045",
              "IPY_MODEL_0e0759c21a1c4c4886caad27dead45bd"
            ]
          }
        },
        "92a40e6e73d14d4e862198668163897b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1f47c690023d4a73a6a60b50a14a1045": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2cbb9c07941f45fd9ef4b17bb1ba0a93",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d7fba0bc30ae42d2ac161eeca3a3a7fa"
          }
        },
        "0e0759c21a1c4c4886caad27dead45bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_62a1e99102d04c9a917d51d3e6b46ae2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:06&lt;00:00, 64.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f39cee4ea1d6470b8291aa064528a220"
          }
        },
        "2cbb9c07941f45fd9ef4b17bb1ba0a93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d7fba0bc30ae42d2ac161eeca3a3a7fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "62a1e99102d04c9a917d51d3e6b46ae2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f39cee4ea1d6470b8291aa064528a220": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sR9av2JU3kf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "662d897e-df29-43af-ea65-1753873e937b"
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "import torch\n",
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da-zaZJUGMFU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14ef5395-b83f-4b78-e5be-494f6c4159e4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzKeqoCs3kgA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04fc2458-2c22-4b8d-bd45-0ab655009a02"
      },
      "source": [
        "!pip install transformers==2.8.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==2.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\r\u001b[K     |▋                               | 10kB 19.7MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20kB 19.9MB/s eta 0:00:01\r\u001b[K     |█▊                              | 30kB 11.8MB/s eta 0:00:01\r\u001b[K     |██▎                             | 40kB 9.7MB/s eta 0:00:01\r\u001b[K     |███                             | 51kB 5.3MB/s eta 0:00:01\r\u001b[K     |███▌                            | 61kB 5.8MB/s eta 0:00:01\r\u001b[K     |████                            | 71kB 6.2MB/s eta 0:00:01\r\u001b[K     |████▋                           | 81kB 6.5MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 92kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 102kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 112kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 122kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 133kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 143kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 153kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 163kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 174kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 184kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 194kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 204kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 215kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 225kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 235kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 245kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 256kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 266kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 276kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 286kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 296kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 307kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 317kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 327kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 337kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 348kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 358kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 368kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 378kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 389kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 399kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 409kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 419kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 430kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 440kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 450kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 460kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 471kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 481kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 491kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 501kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 512kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 522kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 532kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 542kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 552kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 563kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 573kB 6.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (2.23.0)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/9c/544396572c05841b7a2482c88be5dd54dcd18ba97abeb1e8d34daf921a54/boto3-1.16.30-py2.py3-none-any.whl (129kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 18.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (4.41.1)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 15.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (1.18.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 52.2MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 47.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (0.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (1.24.3)\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.4MB/s \n",
            "\u001b[?25hCollecting botocore<1.20.0,>=1.19.30\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/a3/1ee497faf994d180df5d14d456eef1ef46ca1ffce617816faa4ff8164608/botocore-1.19.30-py2.py3-none-any.whl (7.0MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0MB 45.9MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (0.17.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.30->boto3->transformers==2.8.0) (2.8.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=7271133a81de1a52b36c14b63434a045f573009e9a91febd9d2151a97db9e6a6\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "\u001b[31mERROR: botocore 1.19.30 has requirement urllib3<1.27,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3, tokenizers, sacremoses, sentencepiece, transformers\n",
            "Successfully installed boto3-1.16.30 botocore-1.19.30 jmespath-0.10.0 s3transfer-0.3.3 sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.5.2 transformers-2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gf-OXnTs-ZhS"
      },
      "source": [
        "!cp -r \"/content/drive/My Drive/research_lo_content_taxonomy_classification/model_euclidean_dual_bert_1/\" /content/\n",
        "!cp -r \"/content/drive/My Drive/research_lo_content_taxonomy_classification/model_euclidean_dual_bert_2/\" /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZFv4UU8sLTM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fe51fa1-80bd-4c68-dc2f-11f43ca479df"
      },
      "source": [
        "!pip install git+https://github.com/geoopt/geoopt.git\n",
        "! pip install git+https://github.com/ferrine/hyrnn.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/geoopt/geoopt.git\n",
            "  Cloning https://github.com/geoopt/geoopt.git to /tmp/pip-req-build-qs542flp\n",
            "  Running command git clone -q https://github.com/geoopt/geoopt.git /tmp/pip-req-build-qs542flp\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from geoopt==0.3.1) (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from geoopt==0.3.1) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.4.0->geoopt==0.3.1) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.4.0->geoopt==0.3.1) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.4.0->geoopt==0.3.1) (3.7.4.3)\n",
            "Building wheels for collected packages: geoopt\n",
            "  Building wheel for geoopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for geoopt: filename=geoopt-0.3.1-cp36-none-any.whl size=73075 sha256=11f9f4f5606bebde2de27b135d626f3b614c5a8aca88218a3800f86c79a0474e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ombijidf/wheels/10/df/30/e0d857f034c142ca5f38af048b62aae3da773b272553e5dd21\n",
            "Successfully built geoopt\n",
            "Installing collected packages: geoopt\n",
            "Successfully installed geoopt-0.3.1\n",
            "Collecting git+https://github.com/ferrine/hyrnn.git\n",
            "  Cloning https://github.com/ferrine/hyrnn.git to /tmp/pip-req-build-g_g8hmh6\n",
            "  Running command git clone -q https://github.com/ferrine/hyrnn.git /tmp/pip-req-build-g_g8hmh6\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from hyrnn==0.0.0) (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from hyrnn==0.0.0) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->hyrnn==0.0.0) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->hyrnn==0.0.0) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->hyrnn==0.0.0) (3.7.4.3)\n",
            "Building wheels for collected packages: hyrnn\n",
            "  Building wheel for hyrnn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hyrnn: filename=hyrnn-0.0.0-cp36-none-any.whl size=13955 sha256=67f2a88e2fe22cc6c144b42bb73f37d2be8215ce035826e31bb302c021e712b9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-b2_xgf89/wheels/24/c3/64/cc0e9d25d466081dc154a2a8843157f54d845b916b4ba66418\n",
            "Successfully built hyrnn\n",
            "Installing collected packages: hyrnn\n",
            "Successfully installed hyrnn-0.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsADhaO93kgD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 959
        },
        "outputId": "265cdfc3-98ea-4601-9e42-2ae1a8c7db1f"
      },
      "source": [
        "import pandas as pd\n",
        "train_data = pd.read_csv(\"train_taxonomy_prediction.csv\")\n",
        "val_data = pd.read_csv(\"validation_taxonomy_prediction.csv\")\n",
        "test_data = pd.read_csv(\"test_taxonomy_prediction.csv\")\n",
        "\n",
        "train_data\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>questionID</th>\n",
              "      <th>originalQuestionID</th>\n",
              "      <th>totalPossiblePoint</th>\n",
              "      <th>AnswerKey</th>\n",
              "      <th>isMultipleChoiceQuestion</th>\n",
              "      <th>includesDiagram</th>\n",
              "      <th>examName</th>\n",
              "      <th>grade</th>\n",
              "      <th>year</th>\n",
              "      <th>QCLabel</th>\n",
              "      <th>Question</th>\n",
              "      <th>subject</th>\n",
              "      <th>category</th>\n",
              "      <th>fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>VASoL_2008_3_34</td>\n",
              "      <td>34</td>\n",
              "      <td>1</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Virginia Standards of Learning - Science</td>\n",
              "      <td>3</td>\n",
              "      <td>2008</td>\n",
              "      <td>matter_properties of objects_TEXT</td>\n",
              "      <td>A student is asked to bring something that fee...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Train</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MCAS_2015_8_6</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>B</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>MCAS</td>\n",
              "      <td>8</td>\n",
              "      <td>2015</td>\n",
              "      <td>celestial_FEATURES_STELLAR</td>\n",
              "      <td>Which of the following statements best describ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Mercury_SC_417677</td>\n",
              "      <td>417677</td>\n",
              "      <td>1</td>\n",
              "      <td>B</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>4</td>\n",
              "      <td>2015</td>\n",
              "      <td>energy_LIGHT_REFLECT</td>\n",
              "      <td>A polished metal ball looks very shiny and bri...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mercury_7230423</td>\n",
              "      <td>7230423</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>9</td>\n",
              "      <td>2015</td>\n",
              "      <td>LIFE_EXTINCTION_MASSEX</td>\n",
              "      <td>Which was a main force driving extensive speci...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NYSEDREGENTS_2007_8_6</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NYSEDREGENTS</td>\n",
              "      <td>8</td>\n",
              "      <td>2007</td>\n",
              "      <td>Life_functions_features and functions_CELLBIO_...</td>\n",
              "      <td>Compared to the amount of hereditary informati...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Train</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5592</th>\n",
              "      <td>Mercury_402502</td>\n",
              "      <td>402502</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>8</td>\n",
              "      <td>2015</td>\n",
              "      <td>matter_chemistry_periodic table</td>\n",
              "      <td>According to the periodic table, argon is foun...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5593</th>\n",
              "      <td>MCAS_2006_9_20</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>B</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>MCAS</td>\n",
              "      <td>9</td>\n",
              "      <td>2006</td>\n",
              "      <td>FOR_MOMENTUM</td>\n",
              "      <td>Which of the following has the least momentum?...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Train</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5594</th>\n",
              "      <td>NYSEDREGENTS_2013_8_35</td>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NYSEDREGENTS</td>\n",
              "      <td>8</td>\n",
              "      <td>2013</td>\n",
              "      <td>Life_functions_features and functions_PLANT_PH...</td>\n",
              "      <td>The amount of which greenhouse gas in the air ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5595</th>\n",
              "      <td>Mercury_7082670</td>\n",
              "      <td>7082670</td>\n",
              "      <td>1</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>7</td>\n",
              "      <td>2015</td>\n",
              "      <td>energy_LIGHT_electromagnetic spectrum</td>\n",
              "      <td>The visible light spectrum can be subdivided a...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5596</th>\n",
              "      <td>Mercury_7004970</td>\n",
              "      <td>7004970</td>\n",
              "      <td>1</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>8</td>\n",
              "      <td>2015</td>\n",
              "      <td>Life_reproduction_DNA inheritance_DOMRECESS</td>\n",
              "      <td>A scientist crosses a red-flowered plant with ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Train</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5597 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  questionID originalQuestionID  ...  category       fold\n",
              "0            VASoL_2008_3_34                 34  ...     Train       Easy\n",
              "1              MCAS_2015_8_6                  6  ...      Test       Easy\n",
              "2          Mercury_SC_417677             417677  ...      Test  Challenge\n",
              "3            Mercury_7230423            7230423  ...      Test       Easy\n",
              "4      NYSEDREGENTS_2007_8_6                  6  ...     Train  Challenge\n",
              "...                      ...                ...  ...       ...        ...\n",
              "5592          Mercury_402502             402502  ...      Test  Challenge\n",
              "5593          MCAS_2006_9_20                 20  ...     Train  Challenge\n",
              "5594  NYSEDREGENTS_2013_8_35                 35  ...      Test       Easy\n",
              "5595         Mercury_7082670            7082670  ...      Test       Easy\n",
              "5596         Mercury_7004970            7004970  ...     Train       Easy\n",
              "\n",
              "[5597 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Z43kiCZHQ9WI",
        "outputId": "ad96005e-564c-49e9-dd18-cb756142e1d5"
      },
      "source": [
        "test_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>questionID</th>\n",
              "      <th>originalQuestionID</th>\n",
              "      <th>totalPossiblePoint</th>\n",
              "      <th>AnswerKey</th>\n",
              "      <th>isMultipleChoiceQuestion</th>\n",
              "      <th>includesDiagram</th>\n",
              "      <th>examName</th>\n",
              "      <th>grade</th>\n",
              "      <th>year</th>\n",
              "      <th>QCLabel</th>\n",
              "      <th>Question</th>\n",
              "      <th>subject</th>\n",
              "      <th>category</th>\n",
              "      <th>fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mercury_409529</td>\n",
              "      <td>409529</td>\n",
              "      <td>1</td>\n",
              "      <td>B</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>7</td>\n",
              "      <td>2015</td>\n",
              "      <td>science_INFERENCE_experiment design</td>\n",
              "      <td>Robert is a fisherman who wants to find a way ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Dev</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mercury_7090790</td>\n",
              "      <td>7090790</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>7</td>\n",
              "      <td>2015</td>\n",
              "      <td>matter_Change of state_EVAPoration</td>\n",
              "      <td>Which of these factors causes water to evapora...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TIMSS_2007_8_pg7</td>\n",
              "      <td>pg7</td>\n",
              "      <td>1</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>TIMSS</td>\n",
              "      <td>8</td>\n",
              "      <td>2007</td>\n",
              "      <td>matter_chemistry_atomic</td>\n",
              "      <td>Which statement is true about the particles of...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Train</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mercury_7014455</td>\n",
              "      <td>7014455</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>8</td>\n",
              "      <td>2015</td>\n",
              "      <td>energy_LIGHT_GENERICPROP</td>\n",
              "      <td>Which generates waves that are capable of trav...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Dev</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NAEP_2000_8_S21+4</td>\n",
              "      <td>S21+4</td>\n",
              "      <td>1</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NAEP</td>\n",
              "      <td>8</td>\n",
              "      <td>2000</td>\n",
              "      <td>forces and friction</td>\n",
              "      <td>To keep a heavy box sliding across a carpeted ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1395</th>\n",
              "      <td>Mercury_SC_401827</td>\n",
              "      <td>401827</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>5</td>\n",
              "      <td>2015</td>\n",
              "      <td>matter_properties of material_ELECCOND</td>\n",
              "      <td>Metals that easily transfer electricity are ca...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1396</th>\n",
              "      <td>MDSA_2010_5_35</td>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Maryland School Assessment - Science</td>\n",
              "      <td>5</td>\n",
              "      <td>2010</td>\n",
              "      <td>EARTH_human impacts_WHAT_air pollution</td>\n",
              "      <td>Many states require vehicles to be examined an...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Train</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1397</th>\n",
              "      <td>Mercury_7024483</td>\n",
              "      <td>7024483</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>8</td>\n",
              "      <td>2015</td>\n",
              "      <td>Life_reproduction_DNA inheritance_inheritance</td>\n",
              "      <td>Which of these is not an inherited trait in hu...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Train</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1398</th>\n",
              "      <td>NYSEDREGENTS_2008_4_17</td>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NYSEDREGENTS</td>\n",
              "      <td>4</td>\n",
              "      <td>2008</td>\n",
              "      <td>Life_functions_FUNCT_animalESS</td>\n",
              "      <td>In order to survive, all animals need (A) heat...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1399</th>\n",
              "      <td>MCAS_2001_8_13</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>MCAS</td>\n",
              "      <td>8</td>\n",
              "      <td>2001</td>\n",
              "      <td>EARTH_INNER_PLATE_CONTDRIFT</td>\n",
              "      <td>Scientists claim that the continents of South ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Train</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1400 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  questionID originalQuestionID  ...  category       fold\n",
              "0             Mercury_409529             409529  ...       Dev  Challenge\n",
              "1            Mercury_7090790            7090790  ...      Test  Challenge\n",
              "2           TIMSS_2007_8_pg7                pg7  ...     Train  Challenge\n",
              "3            Mercury_7014455            7014455  ...       Dev       Easy\n",
              "4          NAEP_2000_8_S21+4              S21+4  ...      Test  Challenge\n",
              "...                      ...                ...  ...       ...        ...\n",
              "1395       Mercury_SC_401827             401827  ...      Test       Easy\n",
              "1396          MDSA_2010_5_35                 35  ...     Train  Challenge\n",
              "1397         Mercury_7024483            7024483  ...     Train  Challenge\n",
              "1398  NYSEDREGENTS_2008_4_17                 17  ...      Test       Easy\n",
              "1399          MCAS_2001_8_13                 13  ...     Train  Challenge\n",
              "\n",
              "[1400 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 993
        },
        "id": "X_mbeDv5Q-lH",
        "outputId": "a162fdbe-164d-47c2-f056-09695dc0e48e"
      },
      "source": [
        "val_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>questionID</th>\n",
              "      <th>originalQuestionID</th>\n",
              "      <th>totalPossiblePoint</th>\n",
              "      <th>AnswerKey</th>\n",
              "      <th>isMultipleChoiceQuestion</th>\n",
              "      <th>includesDiagram</th>\n",
              "      <th>examName</th>\n",
              "      <th>grade</th>\n",
              "      <th>year</th>\n",
              "      <th>QCLabel</th>\n",
              "      <th>Question</th>\n",
              "      <th>subject</th>\n",
              "      <th>category</th>\n",
              "      <th>fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MCAS_2006_9_30-v1</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>MCAS</td>\n",
              "      <td>9</td>\n",
              "      <td>2006</td>\n",
              "      <td>matter_CHANGES_PHYSICAL</td>\n",
              "      <td>Which of the following changes occurs as a sol...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Train</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mercury_SC_401144</td>\n",
              "      <td>401144</td>\n",
              "      <td>1</td>\n",
              "      <td>B</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>5</td>\n",
              "      <td>2015</td>\n",
              "      <td>EARTH_WEATHER_CLOUDS</td>\n",
              "      <td>When water vapor rises and cools, the liquid w...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Train</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NCEOGA_2013_8_46</td>\n",
              "      <td>46</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>North Carolina READY End-of-Grade Assessment</td>\n",
              "      <td>8</td>\n",
              "      <td>2013</td>\n",
              "      <td>EARTH_GEO_FORMATIONS</td>\n",
              "      <td>Which best describes the characteristics of a ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Dev</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mercury_417146</td>\n",
              "      <td>417146</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>8</td>\n",
              "      <td>2015</td>\n",
              "      <td>Life_interdependence_ecological features</td>\n",
              "      <td>Most of the oxygen in the atmosphere is made b...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Dev</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Mercury_7283833</td>\n",
              "      <td>7283833</td>\n",
              "      <td>1</td>\n",
              "      <td>B</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>8</td>\n",
              "      <td>2015</td>\n",
              "      <td>LIFE_HEALTH_DIESEASE_PANDEMICEPIDEMIC</td>\n",
              "      <td>Which aspect of modern Life_could most likely ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>773</th>\n",
              "      <td>Mercury_7128853</td>\n",
              "      <td>7128853</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>8</td>\n",
              "      <td>2015</td>\n",
              "      <td>energy_SOUND_AMPLITUDE</td>\n",
              "      <td>As the loudness of a sound wave increases, whi...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>774</th>\n",
              "      <td>Mercury_7245858</td>\n",
              "      <td>7245858</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>7</td>\n",
              "      <td>2015</td>\n",
              "      <td>celestial_SPACEEX_HUMAN</td>\n",
              "      <td>In the initial stages of manned space explorat...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Train</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>775</th>\n",
              "      <td>Mercury_417462</td>\n",
              "      <td>417462</td>\n",
              "      <td>1</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>7</td>\n",
              "      <td>2015</td>\n",
              "      <td>Life_functions_features and functions_PLANT_RE...</td>\n",
              "      <td>During a walk in the woods, Mandy finds a plan...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>776</th>\n",
              "      <td>Mercury_7044065</td>\n",
              "      <td>7044065</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>8</td>\n",
              "      <td>2015</td>\n",
              "      <td>EARTH_human impacts_WHAT_air pollution</td>\n",
              "      <td>What is the MAJOR cause of acid rain? (A) smel...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>777</th>\n",
              "      <td>Mercury_7094238</td>\n",
              "      <td>7094238</td>\n",
              "      <td>1</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>7</td>\n",
              "      <td>2015</td>\n",
              "      <td>OTHER</td>\n",
              "      <td>Which invention would a culture living above t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Train</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>778 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            questionID originalQuestionID  ...  category       fold\n",
              "0    MCAS_2006_9_30-v1                 30  ...     Train  Challenge\n",
              "1    Mercury_SC_401144             401144  ...     Train       Easy\n",
              "2     NCEOGA_2013_8_46                 46  ...       Dev       Easy\n",
              "3       Mercury_417146             417146  ...       Dev  Challenge\n",
              "4      Mercury_7283833            7283833  ...      Test  Challenge\n",
              "..                 ...                ...  ...       ...        ...\n",
              "773    Mercury_7128853            7128853  ...      Test       Easy\n",
              "774    Mercury_7245858            7245858  ...     Train       Easy\n",
              "775     Mercury_417462             417462  ...      Test       Easy\n",
              "776    Mercury_7044065            7044065  ...      Test       Easy\n",
              "777    Mercury_7094238            7094238  ...     Train  Challenge\n",
              "\n",
              "[778 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQhO6qqt6lge"
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DD4IAgG1XQGp"
      },
      "source": [
        "import re\n",
        "def clean_sentence(question):\n",
        "  # print(question)\n",
        "  question = re.sub('<[^>]*>', ' ',question)\n",
        "  question = re.sub(' +', ' ', question)\n",
        "  question = re.sub('\\xa0','',question)\n",
        "  question = question.rstrip()\n",
        "  question = re.sub('nan','',question)\n",
        "  question = re.sub(u'\\u2004','',question)\n",
        "  question = re.sub(u'\\u2009','',question)\n",
        "\n",
        "  # question = question.decode(\"utf-8\")\n",
        "  # question = question.replace(u'\\u200\\d*','').encode(\"utf-8\")\n",
        "  question = re.sub('&nbsp','',question)\n",
        "  question = re.sub('&ndash','',question)\n",
        "  question = re.sub('\\r','',question)\n",
        "  question = re.sub('\\t','',question)\n",
        "  question = re.sub('\\n',' ',question)\n",
        "\n",
        "  question = re.sub('MathType@.*','',question)\n",
        "  question = re.sub('&thinsp','',question)\n",
        "  question = re.sub('&times','',question)\n",
        "  question = re.sub('\\u200b','',question)\n",
        "  question = re.sub('&rarr;;;','',question)\n",
        "\n",
        "  return question"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNrGNk8f3kgh"
      },
      "source": [
        "# final_data_1 = final_data.loc[0:71003,:]\n",
        "# final_data_1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkJyRhquRKz7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43735f7b-5985-4d5c-d49a-2b08a527b8f2"
      },
      "source": [
        "import transformers\n",
        "print(transformers.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIrS5sxE3kgk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "f7c1f99e9646429e9917b5407139fca5",
            "add3e217b8164a1b9ad4f8a765561c9c",
            "83a7159241734018b5b4ca6161164abf",
            "74130373d17b426fae5b0c6704d46c1f",
            "71a5161606e5495fb86ef8b59ff2bcbc",
            "6e97ba95fdf04aeb9b6450377dc1bf7b",
            "e206ad602a0e4f0cb54d370b47e54ab6",
            "5fe895417e934bb19ae66eefcad683f9"
          ]
        },
        "outputId": "2f7d2b5b-f9db-4de0-fcb8-a4279ece063e"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f7c1f99e9646429e9917b5407139fca5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mgc72PQYV1Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8421115-bde7-49e4-c564-705ea2d96d56"
      },
      "source": [
        "train_data[\"QCLabel\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "celestial_cycles                                                 106\n",
              "matter_chemistry_periodic table                                   85\n",
              "matter_chemistry_atomic                                           79\n",
              "matter_CHANGES_CHEMICAL                                           72\n",
              "science_INFERENCE_observation                                     69\n",
              "                                                                ... \n",
              "science_INFERENCE_INFERENCE                                        1\n",
              "energy_ELEC_COND                                                   1\n",
              "Life_functions_features and functions_CELLBIO_STRUCT_GOLGI         1\n",
              "matter_measurement_UNIT_TEMP                                       1\n",
              "LIFE_environment and adaptation_animal adaptations_BEHAV_HUNT      1\n",
              "Name: QCLabel, Length: 416, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owuvwWJORK8W",
        "outputId": "29edd95b-f2e7-4b68-8fb9-25b1a5753b6f"
      },
      "source": [
        "test_data[\"QCLabel\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Life_reproduction_DNA inheritance_inheritance                    26\n",
              "celestial_cycles                                                 26\n",
              "Life_functions_features and functions_PLANT_PHOTOSYNTH           22\n",
              "matter_chemistry_atomic                                          21\n",
              "science_INFERENCE_experiment design                              19\n",
              "                                                                 ..\n",
              "force_work                                                        1\n",
              "celestial_APPARENTMOTION Celestial_cycles                         1\n",
              "energy_WAVES_FREQWL                                               1\n",
              "Life_reproduction                                                 1\n",
              "LIFE_environment and adaptation_animal adaptations_STRUCT_FAT     1\n",
              "Name: QCLabel, Length: 352, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3lYOb2K3kgy"
      },
      "source": [
        "\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# LE = LabelEncoder()\n",
        "# final_data['label'] = LE.fit_transform(final_data['board_syllabus'])\n",
        "# final_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wp64MkNB3kg1"
      },
      "source": [
        "# def get_labels(prediction):\n",
        "#     predicted_label =  LE.inverse_transform([prediction])\n",
        "#     return predicted_label[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPgTmJPS3kg4"
      },
      "source": [
        "# get_labels(330)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrQ1BBx0vWUQ"
      },
      "source": [
        "# train_data = pd.concat([train_data,val_data])\n",
        "# train_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijn1nIpByb3e"
      },
      "source": [
        "train_features = train_data[\"Question\"]\n",
        "test_features = test_data[\"Question\"]\n",
        "train_labels = train_data[\"QCLabel\"]\n",
        "test_labels = test_data[\"QCLabel\"]\n",
        "val_features = val_data[\"Question\"]\n",
        "val_labels = val_data[\"QCLabel\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prM_km_83khD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c16a07e6-5a47-405f-fa79-8c13c3724472"
      },
      "source": [
        "train_labels.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "celestial_cycles                                                 106\n",
              "matter_chemistry_periodic table                                   85\n",
              "matter_chemistry_atomic                                           79\n",
              "matter_CHANGES_CHEMICAL                                           72\n",
              "science_INFERENCE_observation                                     69\n",
              "                                                                ... \n",
              "science_INFERENCE_INFERENCE                                        1\n",
              "energy_ELEC_COND                                                   1\n",
              "Life_functions_features and functions_CELLBIO_STRUCT_GOLGI         1\n",
              "matter_measurement_UNIT_TEMP                                       1\n",
              "LIFE_environment and adaptation_animal adaptations_BEHAV_HUNT      1\n",
              "Name: QCLabel, Length: 416, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfhPstXJ03oz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f9aec3f-7126-4047-8ccd-c218ed5c869e"
      },
      "source": [
        "test_labels.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Life_reproduction_DNA inheritance_inheritance                    26\n",
              "celestial_cycles                                                 26\n",
              "Life_functions_features and functions_PLANT_PHOTOSYNTH           22\n",
              "matter_chemistry_atomic                                          21\n",
              "science_INFERENCE_experiment design                              19\n",
              "                                                                 ..\n",
              "force_work                                                        1\n",
              "celestial_APPARENTMOTION Celestial_cycles                         1\n",
              "energy_WAVES_FREQWL                                               1\n",
              "Life_reproduction                                                 1\n",
              "LIFE_environment and adaptation_animal adaptations_STRUCT_FAT     1\n",
              "Name: QCLabel, Length: 352, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkyM7gqv3khI"
      },
      "source": [
        "\n",
        "question_answer = train_features.values\n",
        "categories = train_labels.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFkS_H_83khL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f097d102-9dd5-4494-8000-6a7ac3dd2839"
      },
      "source": [
        "question_answer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['A student is asked to bring something that feels rough to class. Which would be BEST for him to bring? (A) Pillow (B) Marble (C) Sandpaper (D) Trading card',\n",
              "       'Which of the following statements best describes the role of gravity in the formation of stars? (A) Gravity converts solid matter into gases and light energy. (B) Gravity causes gases and dust particles to condense into spheres. (C) Gravity cools gases and liquids until they become one solid mass. (D) Gravity pushes rocks and dust particles outward from a dense center.',\n",
              "       'A polished metal ball looks very shiny and bright on a sunny day. What makes the ball look shiny? (A) The ball makes light. (B) The ball reflects light. (C) The ball absorbs light and then releases it. (D) The ball absorbs light and keeps it inside.',\n",
              "       ...,\n",
              "       'The amount of which greenhouse gas in the air will increase the most if large forests are cut down to be used for building materials without planting new trees in their place? (1) ozone (2) methane (3) water vapor (4) carbon dioxide',\n",
              "       'The visible light spectrum can be subdivided according to (A) the types of waves. (B) the sizes of particles. (C) a range of colors. (D) a type of energy.',\n",
              "       'A scientist crosses a red-flowered plant with a white-flowered plant, and all offspring have red flowers. What will most likely result if these red-flowered offspring are crossed with white-flowered plants? (A) All of the offspring will have red flowers. (B) All of the offspring will have white flowers. (C) The offspring will have either red or white flowers. (D) The offspring will have neither red nor white flowers.'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ian7gSDE3khR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12374fdb-feb4-4b5b-b4a2-af755642cdef"
      },
      "source": [
        "categories"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['matter_properties of objects_TEXT', 'celestial_FEATURES_STELLAR',\n",
              "       'energy_LIGHT_REFLECT', ...,\n",
              "       'Life_functions_features and functions_PLANT_PHOTOSYNTH',\n",
              "       'energy_LIGHT_electromagnetic spectrum',\n",
              "       'Life_reproduction_DNA inheritance_DOMRECESS'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fepGiggpqOQx"
      },
      "source": [
        "# val_features = test_features.values\n",
        "# val_labels = test_labels.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1L2y3KLjV5OB"
      },
      "source": [
        "# list(set(label_emb_data))[0]\n",
        "# # list(set(train_data['board_syllabus'].values))[0]\n",
        "# label_emb_data[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FN1zRXMOXwLK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00e27f95-510f-465c-af75-26f73109b423"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "!pip install inflection\n",
        "\n",
        "from bokeh.io import output_file, output_notebook, show\n",
        "from bokeh.plotting import figure\n",
        "from bokeh.transform import linear_cmap\n",
        "from bokeh.util.hex import hexbin\n",
        "from bokeh.models import HoverTool\n",
        "from bokeh import colors\n",
        "import inflection\n",
        "\n",
        "from nltk.stem import PorterStemmer \n",
        "ps = PorterStemmer()\n",
        "from gzip import open as gopen\n",
        "from pandas.core.common import flatten\n",
        "import gensim.models.poincare as poincare\n",
        "def get_cleaned_taxonomy(taxonomy):\n",
        "  cleaned_taxonomy = []\n",
        "  for value in taxonomy:\n",
        "      value = ' '.join(value.split(\">>\"))\n",
        "      # taxonomy_words = [inflection.singularize(val)  for token in value for val in token.split(\" \") if val.isalpha()]\n",
        "      cleaned_taxonomy.append( value )\n",
        "  return cleaned_taxonomy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting inflection\n",
            "  Downloading https://files.pythonhosted.org/packages/59/91/aa6bde563e0085a02a435aa99b49ef75b0a4b062635e606dab23ce18d720/inflection-0.5.1-py2.py3-none-any.whl\n",
            "Installing collected packages: inflection\n",
            "Successfully installed inflection-0.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPAl0TNuX6mx"
      },
      "source": [
        "\n",
        "# course_taxonomy\n",
        "\n",
        "label_emb_data = get_cleaned_taxonomy(categories)\n",
        "label_val = get_cleaned_taxonomy(val_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdFQoVFqWQ2m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a3d52e61-89c5-439e-e5ab-72657bbf4f38"
      },
      "source": [
        "label_emb_data[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'matter properties of objects text'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aedZzkBsqEeK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0cebce8f-80bb-4118-e36b-c2450928f12a"
      },
      "source": [
        "label_emb_data[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'energy light reflect'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_ocuHxzCy16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ce63ddb-4c3e-4411-cef8-1890e6105add"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "wnl = WordNetLemmatizer()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRnsivQMMo8j"
      },
      "source": [
        "%cd ..\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLviI8T-pKSl"
      },
      "source": [
        "!git clone https://github.com/epfml/sent2vec\n",
        "%cd sent2vec\n",
        "!ls\n",
        "!git checkout f827d014a473aa22b2fef28d9e29211d50808d48\n",
        "!make\n",
        "!pip install cython\n",
        "%cd src\n",
        "!python setup.py build_ext\n",
        "!pip install .\n",
        "%cd ../../"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wm6AyX4KNKCm"
      },
      "source": [
        "!wget --load-cookies /tmp/cookies.txt \"https://drive.google.com/u/0/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://drive.google.com/u/0/uc?export=download&confirm=r8GA&id=0B6VhzidiLvjSOWdGM0tOX1lUNEk' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=0B6VhzidiLvjSOWdGM0tOX1lUNEk\" -O torontobooks_unigrams.bin && rm -rf /tmp/cookies.txt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjDKIFSENir_"
      },
      "source": [
        "import sent2vec\n",
        "model = sent2vec.Sent2vecModel()\n",
        "model.load_model('torontobooks_unigrams.bin')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FU-K6GP_1jM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f7c149b-b606-4d91-b50c-56129cdbdbc0"
      },
      "source": [
        "len(list(set(label_emb_data)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "416"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czfB-yOBSjGJ"
      },
      "source": [
        "label_input_ids = []\n",
        "label_attention_masks = []\n",
        "for sent in label_emb_data:\n",
        "\n",
        "    label_encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    label_input_ids.append(label_encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    label_attention_masks.append(label_encoded_dict['attention_mask'])\n",
        "label_input_ids = torch.cat(label_input_ids, dim=0)\n",
        "label_attention_masks = torch.cat(label_attention_masks, dim=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "om1dts4_-UnS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "704f36bc-1978-4eaf-ef06-e6ec0ceed1d7"
      },
      "source": [
        "taxonomy_vectors = []\n",
        "for label_input_id,label_att_mask in zip(label_input_ids,label_attention_masks):\n",
        "    label_input_id = label_input_id.to(device)\n",
        "    label_att_mask = label_att_mask.to(device)\n",
        "    with torch.no_grad():\n",
        "      outputs = model_label(label_input_id.reshape(1,-1),label_att_mask.reshape(1,-1))\n",
        "    taxonomy_vectors.append(outputs.cpu().numpy())\n",
        "taxonomy_vectors = np.vstack(taxonomy_vectors)\n",
        "taxonomy_vectors.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(312, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WT7tK3YTSswa"
      },
      "source": [
        "label_input_ids_val = []\n",
        "label_attention_masks_val = []\n",
        "for sent in label_val:\n",
        "\n",
        "    label_encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    label_input_ids_val.append(label_encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    label_attention_masks_val.append(label_encoded_dict['attention_mask'])\n",
        "label_input_ids_val = torch.cat(label_input_ids_val, dim=0)\n",
        "label_attention_masks_val = torch.cat(label_attention_masks_val, dim=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdBbsrO9zp2p"
      },
      "source": [
        "# taxonomy_vectors = []\n",
        "# for label_input_id,label_att_mask in zip(label_input_ids,label_attention_masks):\n",
        "#     label_input_id = label_input_id.to(device)\n",
        "#     label_att_mask = label_att_mask.to(device)\n",
        "#     with torch.no_grad():\n",
        "#       outputs = model_label(label_input_id.reshape(1,-1),label_att_mask.reshape(1,-1))\n",
        "#     taxonomy_vectors.append(outputs[1].cpu().numpy())\n",
        "# taxonomy_vectors = np.vstack(taxonomy_vectors)\n",
        "# taxonomy_vectors.shape\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTlCYX9Q34JG"
      },
      "source": [
        "# taxonomy_vectors_val = []\n",
        "# for feature in poincare_val:\n",
        "#   taxonomy_vectors_val.append(model.embed_sentences([feature]))\n",
        "# taxonomy_vectors_val = np.vstack(taxonomy_vectors_val)\n",
        "# taxonomy_vectors_val.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-DEKAOHv-VD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "da4f84e6-ecc0-4cb9-e9e9-6e82e0ab3539"
      },
      "source": [
        "test_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>questionID</th>\n",
              "      <th>originalQuestionID</th>\n",
              "      <th>totalPossiblePoint</th>\n",
              "      <th>AnswerKey</th>\n",
              "      <th>isMultipleChoiceQuestion</th>\n",
              "      <th>includesDiagram</th>\n",
              "      <th>examName</th>\n",
              "      <th>grade</th>\n",
              "      <th>year</th>\n",
              "      <th>QCLabel</th>\n",
              "      <th>Question</th>\n",
              "      <th>subject</th>\n",
              "      <th>category</th>\n",
              "      <th>fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mercury_409529</td>\n",
              "      <td>409529</td>\n",
              "      <td>1</td>\n",
              "      <td>B</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>7</td>\n",
              "      <td>2015</td>\n",
              "      <td>science_INFERENCE_experiment design</td>\n",
              "      <td>Robert is a fisherman who wants to find a way ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Dev</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mercury_7090790</td>\n",
              "      <td>7090790</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>7</td>\n",
              "      <td>2015</td>\n",
              "      <td>matter_Change of state_EVAPoration</td>\n",
              "      <td>Which of these factors causes water to evapora...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TIMSS_2007_8_pg7</td>\n",
              "      <td>pg7</td>\n",
              "      <td>1</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>TIMSS</td>\n",
              "      <td>8</td>\n",
              "      <td>2007</td>\n",
              "      <td>matter_chemistry_atomic</td>\n",
              "      <td>Which statement is true about the particles of...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Train</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mercury_7014455</td>\n",
              "      <td>7014455</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>8</td>\n",
              "      <td>2015</td>\n",
              "      <td>energy_LIGHT_GENERICPROP</td>\n",
              "      <td>Which generates waves that are capable of trav...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Dev</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NAEP_2000_8_S21+4</td>\n",
              "      <td>S21+4</td>\n",
              "      <td>1</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NAEP</td>\n",
              "      <td>8</td>\n",
              "      <td>2000</td>\n",
              "      <td>forces and friction</td>\n",
              "      <td>To keep a heavy box sliding across a carpeted ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1395</th>\n",
              "      <td>Mercury_SC_401827</td>\n",
              "      <td>401827</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>5</td>\n",
              "      <td>2015</td>\n",
              "      <td>matter_properties of material_ELECCOND</td>\n",
              "      <td>Metals that easily transfer electricity are ca...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1396</th>\n",
              "      <td>MDSA_2010_5_35</td>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Maryland School Assessment - Science</td>\n",
              "      <td>5</td>\n",
              "      <td>2010</td>\n",
              "      <td>EARTH_human impacts_WHAT_air pollution</td>\n",
              "      <td>Many states require vehicles to be examined an...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Train</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1397</th>\n",
              "      <td>Mercury_7024483</td>\n",
              "      <td>7024483</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>8</td>\n",
              "      <td>2015</td>\n",
              "      <td>Life_reproduction_DNA inheritance_inheritance</td>\n",
              "      <td>Which of these is not an inherited trait in hu...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Train</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1398</th>\n",
              "      <td>NYSEDREGENTS_2008_4_17</td>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NYSEDREGENTS</td>\n",
              "      <td>4</td>\n",
              "      <td>2008</td>\n",
              "      <td>Life_functions_FUNCT_animalESS</td>\n",
              "      <td>In order to survive, all animals need (A) heat...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1399</th>\n",
              "      <td>MCAS_2001_8_13</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>MCAS</td>\n",
              "      <td>8</td>\n",
              "      <td>2001</td>\n",
              "      <td>EARTH_INNER_PLATE_CONTDRIFT</td>\n",
              "      <td>Scientists claim that the continents of South ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Train</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1400 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  questionID originalQuestionID  ...  category       fold\n",
              "0             Mercury_409529             409529  ...       Dev  Challenge\n",
              "1            Mercury_7090790            7090790  ...      Test  Challenge\n",
              "2           TIMSS_2007_8_pg7                pg7  ...     Train  Challenge\n",
              "3            Mercury_7014455            7014455  ...       Dev       Easy\n",
              "4          NAEP_2000_8_S21+4              S21+4  ...      Test  Challenge\n",
              "...                      ...                ...  ...       ...        ...\n",
              "1395       Mercury_SC_401827             401827  ...      Test       Easy\n",
              "1396          MDSA_2010_5_35                 35  ...     Train  Challenge\n",
              "1397         Mercury_7024483            7024483  ...     Train  Challenge\n",
              "1398  NYSEDREGENTS_2008_4_17                 17  ...      Test       Easy\n",
              "1399          MCAS_2001_8_13                 13  ...     Train  Challenge\n",
              "\n",
              "[1400 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p834oM1Pzzu8"
      },
      "source": [
        "# np.array(poincare_embedding).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_ZeuHc63khU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed51d14d-ba88-4837-b976-de249a37a90d"
      },
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in question_answer:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', question_answer[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  A student is asked to bring something that feels rough to class. Which would be BEST for him to bring? (A) Pillow (B) Marble (C) Sandpaper (D) Trading card\n",
            "Token IDs: tensor([  101,  1037,  3076,  2003,  2356,  2000,  3288,  2242,  2008,  5683,\n",
            "         5931,  2000,  2465,  1012,  2029,  2052,  2022,  2190,  2005,  2032,\n",
            "         2000,  3288,  1029,  1006,  1037,  1007, 10005,  1006,  1038,  1007,\n",
            "         7720,  1006,  1039,  1007,  5472, 23298,  1006,  1040,  1007,  6202,\n",
            "         4003,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VjkhiN3pAfP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "452e1c16-33d7-4ba0-b176-a58b8e43fc15"
      },
      "source": [
        "input_ids_val = []\n",
        "attention_masks_val = []\n",
        "\n",
        "for sent in val_features:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids_val.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks_val.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids_val = torch.cat(input_ids_val, dim=0)\n",
        "attention_masks_val = torch.cat(attention_masks_val, dim=0)\n",
        "\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', question_answer[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  A student is asked to bring something that feels rough to class. Which would be BEST for him to bring? (A) Pillow (B) Marble (C) Sandpaper (D) Trading card\n",
            "Token IDs: tensor([  101,  1037,  3076,  2003,  2356,  2000,  3288,  2242,  2008,  5683,\n",
            "         5931,  2000,  2465,  1012,  2029,  2052,  2022,  2190,  2005,  2032,\n",
            "         2000,  3288,  1029,  1006,  1037,  1007, 10005,  1006,  1038,  1007,\n",
            "         7720,  1006,  1039,  1007,  5472, 23298,  1006,  1040,  1007,  6202,\n",
            "         4003,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNDW74Ny3khj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c2a7025-1e1e-45fb-808e-badf42b01634"
      },
      "source": [
        "num_classes = len(list(set(categories)))\n",
        "num_classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "416"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmaLk5Ab3khl"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "# train_poincare_tensor = torch.tensor(taxonomy_vectors,dtype=torch.float)\n",
        "# val_poincare_tensor = torch.tensor(taxonomy_vectors_val,dtype=torch.float)\n",
        "\n",
        "val_dataset = TensorDataset(input_ids_val,attention_masks_val,label_input_ids_val,label_attention_masks_val)\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "train_dataset = TensorDataset(input_ids, attention_masks, label_input_ids,label_attention_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_lTinod3kho"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "batch_size = 32\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), \n",
        "            batch_size = batch_size \n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Vduf9fOMviK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24d5092a-bf5d-40c1-edd3-c9745439797a"
      },
      "source": [
        "# !pip install transformers==2.8.0\n",
        "import transformers\n",
        "print(transformers.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H2wp8WlEi9u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17cc68bc-2684-4b70-9c34-bfae80ab3b6c"
      },
      "source": [
        "set(question_answer).intersection(set(test_features))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "set()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZN6jdKp0uhO3"
      },
      "source": [
        "\n",
        "import sys\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from matplotlib import pyplot as plt\n",
        "from torch.nn.modules.loss import HingeEmbeddingLoss\n",
        "from random import randint\n",
        "\n",
        "from tqdm import tqdm\n",
        "import geoopt\n",
        "import time\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from matplotlib import pyplot as plt\n",
        "from torch.nn.modules.loss import HingeEmbeddingLoss\n",
        "from random import randint\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import time\n",
        "import argparse\n",
        "cos = nn.CosineSimilarity(dim=0, eps=1e-6)\n",
        "# Neural Classifierwork\n",
        "class MulticlassClassifier(nn.Module):\n",
        "    def __init__(self,bert_model_path):\n",
        "        super(MulticlassClassifier,self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(bert_model_path,output_hidden_states=False,output_attentions=False)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc1 = nn.Linear(768, 384)\n",
        "        self.fc2 = nn.Linear(384, 768)\n",
        "\n",
        "    def forward(self,tokens,masks):\n",
        "        _, pooled_output = self.bert(tokens, attention_mask=masks)\n",
        "        x = self.fc1(pooled_output)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "class MyHingeLoss(torch.nn.Module):\n",
        "    def __init__(self, margin):\n",
        "        super(MyHingeLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "    # def forward_val(self, output, target):\n",
        "    #     cos = nn.CosineSimilarity(dim=0, eps=1e-6)\n",
        "    #     loss = 0\n",
        "    #     num_compare = 4\n",
        "    #     count = 0\n",
        "    #     for i in range(len(output)):\n",
        "    #         v_image = output[i]\n",
        "    #         t_label = target[i]\n",
        "    #         for j in range(num_compare):\n",
        "    #             if j != i:\n",
        "    #                 count += 1\n",
        "    #                 t_j = target[j]\n",
        "    #                 loss += torch.relu( self.margin - cos(t_label, v_image) + cos(t_j, v_image) )\n",
        "    #     return loss / count\n",
        "\n",
        "    def forward(self, output, target):\n",
        "        loss=0\n",
        "        for i in range(len(output)):\n",
        "            v_image = output[i]\n",
        "            t_label = target[i]\n",
        "            j = randint(0, len(output)-1)\n",
        "            while j == i:\n",
        "                j = randint(0, len(output)-1)\n",
        "            t_j = target[j]\n",
        "            loss+= torch.relu( self.margin - cos(t_label, v_image) + cos(t_j, v_image) )\n",
        "        return loss / len(output)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHYyjxMDIx2U"
      },
      "source": [
        "from transformers import BertModel, AdamW, BertConfig\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2tmAMlw3khr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c137e653d2d94a259dd7ae82bd76b293",
            "1f9ea2dc166f4b2f862d176875ce8383",
            "0f4700f2641d454998e444bb9aa2ec72",
            "46eb0a81e9eb4a5a9ce739b89663422a",
            "8256dc8c6ca24ccfbacd97b87fc23176",
            "d549b2648aec40628a2166508403116b",
            "372787f49c494c40a7357bea7d9023b2",
            "21362ce6683140fd8812691239b969b0",
            "e5043b1147df43e488479fac9d4774e4",
            "92a40e6e73d14d4e862198668163897b",
            "1f47c690023d4a73a6a60b50a14a1045",
            "0e0759c21a1c4c4886caad27dead45bd",
            "2cbb9c07941f45fd9ef4b17bb1ba0a93",
            "d7fba0bc30ae42d2ac161eeca3a3a7fa",
            "62a1e99102d04c9a917d51d3e6b46ae2",
            "f39cee4ea1d6470b8291aa064528a220"
          ]
        },
        "outputId": "963e2a57-1d8e-43ba-e749-1f19986fbf3e"
      },
      "source": [
        "from transformers import BertModel, AdamW, BertConfig\n",
        "\n",
        "# Loads BertModel, the pretrained BERT model with a single \n",
        "model = MulticlassClassifier('bert-base-uncased')\n",
        "# model.load_state_dict(torch.load('model_euclidean_dual_bert_1/model_weights'))\n",
        "model_label = MulticlassClassifier('bert-base-uncased')\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "# model_label.load_state_dict(torch.load('model_euclidean_dual_bert_2/model_weights'))\n",
        "\n",
        "model.cuda()\n",
        "model_label.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c137e653d2d94a259dd7ae82bd76b293",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5043b1147df43e488479fac9d4774e4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MulticlassClassifier(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (fc1): Linear(in_features=768, out_features=384, bias=True)\n",
              "  (fc2): Linear(in_features=384, out_features=768, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4paz_8iTZ9o"
      },
      "source": [
        "# mobius_params = []\n",
        "# bert_params = []\n",
        "\n",
        "# def mobius_params():\n",
        "#   for param in model.named_parameters():\n",
        "#     if 'fc' in param[0]:\n",
        "#       yield param[1]\n",
        "# def bert_params():\n",
        "#   for param in model.named_parameters():\n",
        "#     if 'bert' in param[0]:\n",
        "#       yield param[1]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awQ2Y9Jb3kht"
      },
      "source": [
        "optimizer_1 = torch.optim.AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n",
        "optimizer_2 = torch.optim.AdamW(model_label.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ys-M4-e3khv"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "\n",
        "epochs = 30\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrYqErOD3khx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58e83b00-0a12-451b-de6d-efdd83f314c9"
      },
      "source": [
        "len(train_dataloader) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "175"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWVSE9LM3kh0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53d45074-d88f-41bc-add3-13bf70f19e9d"
      },
      "source": [
        "1935 * 32"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61920"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcvxVVi63kh3"
      },
      "source": [
        "scheduler = get_linear_schedule_with_warmup(optimizer_1, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUw3zm6g3kh5"
      },
      "source": [
        "# import numpy as np\n",
        "\n",
        "# # Function to calculate the accuracy of our predictions vs labels\n",
        "# def flat_accuracy(preds, labels):\n",
        "#     pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "#     labels_flat = labels.flatten()\n",
        "#     return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ta6zfUTa3kh7"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFq9gd5kQSHb"
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsInxVoqbsFW"
      },
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "            path (str): Path for the checkpoint to be saved to.\n",
        "                            Default: 'checkpoint.pt'\n",
        "            trace_func (function): trace print function.\n",
        "                            Default: print            \n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Di68jXK5WaYr"
      },
      "source": [
        "criterion = MyHingeLoss(0.1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LhAy2hZ3kh9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "outputId": "724d4892-7a23-4554-8687-f0d9e2c44b1f"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import json\n",
        "from sklearn.metrics import f1_score\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "early_stopping = EarlyStopping(patience=6, verbose=True)\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_label_input_ids = batch[2].to(device)\n",
        "        b_label_att_masks = batch[3].to(device)\n",
        "\n",
        "\n",
        "        model.zero_grad() \n",
        "        model_label.zero_grad()\n",
        "        optimizer_1.zero_grad()       \n",
        "\n",
        "        logits = model(b_input_ids, \n",
        "                             b_input_mask)\n",
        "        label_repr = model_label(b_label_input_ids,b_label_att_masks)\n",
        "        \n",
        "        loss = criterion.forward(logits,label_repr)\n",
        "\n",
        "  \n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer_1.step()\n",
        "        optimizer_2.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_f1 = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_label_input_id = batch[2].to(device)\n",
        "        b_label_att_mask = batch[3].to(device)\n",
        "\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "\n",
        "          logits = model(b_input_ids, \n",
        "                              b_input_mask)\n",
        "          label_repr = model_label(b_label_input_id,b_label_att_mask)\n",
        "        loss = criterion(logits,label_repr)\n",
        "\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "        # Move logits and labels to CPU\n",
        "        # logits = logits.detach().cpu().numpy().round()\n",
        "        # label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        # total_eval_f1 += f1_score(label_ids,logits, average='macro')\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    # avg_val_accuracy = total_eval_f1 / len(validation_dataloader)\n",
        "    # print(\"  f1score: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    early_stopping(avg_val_loss, model)\n",
        "    if early_stopping.early_stop:\n",
        "      print(\"Early stopping\")\n",
        "      break  \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "    output_dir = 'model_euclidean_dual_bert_1/'\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "        os.makedirs(\"model_euclidean_dual_bert_2\")\n",
        "\n",
        "    print(\"Saving model to %s\" % output_dir)\n",
        "    tokenizer.save_pretrained(output_dir)\n",
        "    torch.save(model.state_dict(), os.path.join(output_dir, 'model_weights'))\n",
        "    torch.save(model_label.state_dict(), os.path.join('model_euclidean_dual_bert_2', 'model_weights'))\n",
        "\n",
        "\n",
        "    !rm -rf \"/content/drive/My Drive/research_lo_content_taxonomy_classification/model_euclidean_dual_bert_1\"\n",
        "    !mv model_euclidean_dual_bert_1 \"/content/drive/My Drive/research_lo_content_taxonomy_classification/\"\n",
        "\n",
        "    !rm -rf \"/content/drive/My Drive/research_lo_content_taxonomy_classification/model_euclidean_dual_bert_2\"\n",
        "    !mv model_euclidean_dual_bert_2 \"/content/drive/My Drive/research_lo_content_taxonomy_classification/\"\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 30 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-d144709490fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m         logits = model(b_input_ids, \n\u001b[1;32m     65\u001b[0m                              b_input_mask)\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mlabel_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_label_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb_label_att_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_repr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-46-fd0042c82138>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tokens, masks)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_extended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m         )\n\u001b[1;32m    792\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             layer_outputs = layer_module(\n\u001b[0;32m--> 407\u001b[0;31m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m             )\n\u001b[1;32m    409\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     ):\n\u001b[0;32m--> 368\u001b[0;31m         \u001b[0mself_attention_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add self attentions if we output attention weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    312\u001b[0m     ):\n\u001b[1;32m    313\u001b[0m         self_outputs = self.self(\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m         )\n\u001b[1;32m    316\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;31m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_head_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 7.43 GiB total capacity; 6.73 GiB already allocated; 4.94 MiB free; 6.79 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RACcsko3kh_"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5TicdiP3kiC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "24d0ca95-969a-4c7e-a6b8-6b160a60ad13"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbiTDpVv3kiF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de568d2a-675f-483d-9b1c-8c071080a3ac"
      },
      "source": [
        "import os\n",
        "\n",
        "\n",
        "output_dir = 'model_euclidean_dual_bert_1_QC/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "\n",
        "# model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "# model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to model_euclidean_cos/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('model_euclidean_cos/vocab.txt',\n",
              " 'model_euclidean_cos/special_tokens_map.json',\n",
              " 'model_euclidean_cos/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1U2UQ29a3kiI"
      },
      "source": [
        "# !pip install joblib\n",
        "# import joblib\n",
        "# joblib.dump(LE, \"label_encoder\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0F5PxZm9vAOI"
      },
      "source": [
        "import json\n",
        "torch.save(model.state_dict(), os.path.join(output_dir, 'model_weights'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vlb0IpVJO1XQ"
      },
      "source": [
        "# with open(os.path.join(output_dir, 'model_config.json'), 'w') as f:\n",
        "#     json.dump(model.config, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpGY8vSDI6u4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e56362f-2dd0-4eec-e60c-9f1e48ac81f5"
      },
      "source": [
        "!zip -r model_euclidean_cos.zip model_euclidean_cos\n",
        "# files.download('model_euclidean_1.zip')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: model_euclidean_cos/ (stored 0%)\n",
            "  adding: model_euclidean_cos/model_weights (deflated 7%)\n",
            "  adding: model_euclidean_cos/vocab.txt (deflated 53%)\n",
            "  adding: model_euclidean_cos/special_tokens_map.json (deflated 40%)\n",
            "  adding: model_euclidean_cos/tokenizer_config.json (stored 0%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvFDCDIxKDOf"
      },
      "source": [
        "# !zip -r label_encoder_categorized_reduced.zip label_encoder\n",
        "# files.download('label_encoder_categorized_reduced.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4178_yLFMWmx"
      },
      "source": [
        "test_features = test_features.values\n",
        "labels = test_labels.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZpmBJuIC2nM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7065d7d-d35b-412e-b3ed-83de3c55bcbe"
      },
      "source": [
        "test_features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([' (a) Describe a simple experiment (or activity) to show that the polarity of emf induced in a coil is always such that it tends to produce a current which opposes the change of magnetic flux that produces it. (b) The current flowing through an inductor of self inductance L is continuously increasing. Plot a graph showing the variation of (i) Magnetic flux versus the current (ii) Induced emf versus dI/dt (iii) Magnetic potential energy stored versus the current. /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-qformat:yes; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin-top:0in; mso-para-margin-right:0in; mso-para-margin-bottom:10.0pt; mso-para-margin-left:0in; line-height:115%; mso-pagination:widow-orphan; font-size:11.0pt; font-family:\"Calibri\",\"sans-serif\"; mso-ascii-font-family:Calibri; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Calibri; mso-hansi-theme-font:minor-latin; mso-bidi-font-family:\"Times New Roman\"; mso-bidi-theme-font:minor-bidi;} v:* {behavior:url(#default#VML);} o:* {behavior:url(#default#VML);} w:* {behavior:url(#default#VML);} .shape {behavior:url(#default#VML);} (a) Lenz law: According to Lenz&#39;s law, the polarity of the induced emf is such that it opposes a change in magnetic flux responsible for its production. Activity: When the north pole of a bar magnet is pushed towards the coil, the amount of magnetic flux linked with the coil increases. Current is induced in the coil in such a direction that it opposes the increase in magnetic flux. This is possible only when the current induced in the coil is in anti-clockwise direction, with respect to an observer. The magnetic moment associated with this induced emf has north polarity, towards the north pole of the approaching bar magnet. Similarly, when the north pole of the bar magnet is moved away from the coil, the magnetic flux linked with the coil decreases. To counter this decrease in magnetic flux, current is induced in the coil in clockwise direction so that its south pole faces the receding north pole of the bar magnet. This would result in an attractive force which opposes the motion of the magnet and the corresponding decrease in magnetic flux. (b)',\n",
              "       ' What is the average weather in a place over many years called? Climate',\n",
              "       ' Which of the following is correct for the characteristics considered at the higher level of classification? dependent on the characteristic of the lower level',\n",
              "       ...,\n",
              "       ' Program formatting has more effect when a consistent style is followed.',\n",
              "       'Cryoscopic constant is related to depression in freezing point .',\n",
              "       ' The elements present in same period have same number of shells.'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRZ54gFokNh9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eecb15c3-d54c-4dd0-917e-55a921bc2e9c"
      },
      "source": [
        "labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['physics>>physics : part - ii',\n",
              "       'social science>>geography : the earth our habitat>>india : climate, vegetation and wildlife',\n",
              "       'science>>diversity in living organisms', ...,\n",
              "       'computer science[c++]>>programming methodology',\n",
              "       'chemistry>>chemistry : part i>>solutions',\n",
              "       'science>>periodic classification of elements'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ohj1x7frQJ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0d8bb3a-988c-4731-ca57-79d6dc691bb6"
      },
      "source": [
        "len(list(set(labels)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "312"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kjinn0gXkNuP"
      },
      "source": [
        "\n",
        "# course_taxonomy\n",
        "test_labels = list(set(labels))\n",
        "# poincare_emb_data = get_cleaned_taxonomy(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dorQwznCeMpR"
      },
      "source": [
        "import sent2vec\n",
        "s2v_model = sent2vec.Sent2vecModel()\n",
        "s2v_model.load_model('torontobooks_unigrams.bin')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wl0RJ3SSW4i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f40918cf-999d-435c-b700-dbd4015dfb18"
      },
      "source": [
        "taxonomy_vectors = []\n",
        "for feature in poincare_emb_data:\n",
        "  taxonomy_vectors.append(s2v_model.embed_sentences([feature]))\n",
        "taxonomy_vectors = np.vstack(taxonomy_vectors)\n",
        "taxonomy_vectors.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(312, 700)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nso39n1N_po_"
      },
      "source": [
        "# model = MulticlassClassifier('bert-base-uncased')\n",
        "# # model.load_state_dict(torch.load('model_euclidean_cos/model_weights'))\n",
        "# model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qe4qYkV2C4fX"
      },
      "source": [
        "test_input_ids = []\n",
        "test_attention_masks = []\n",
        "for sent in test_features:\n",
        "\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    test_input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    test_attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "test_input_ids = torch.cat(test_input_ids, dim=0)\n",
        "test_attention_masks = torch.cat(test_attention_masks, dim=0)\n",
        "# labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "test_poincare_tensor = torch.tensor(taxonomy_vectors,dtype=torch.float)\n",
        "\n",
        "# Create the DataLoader.\n",
        "# prediction_data = TensorDataset(test_input_ids, test_attention_masks, test_poincare_tensor)\n",
        "# prediction_sampler = SequentialSampler(prediction_data)\n",
        "# prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNdlve8AJcCO"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "test_poincare_tensor = torch.tensor(taxonomy_vectors,dtype=torch.float)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6aMBHkAQZjT"
      },
      "source": [
        "cos = torch.nn.CosineSimilarity(dim=0, eps=1e-6)\n",
        "def dist_without_grad( u, v):\n",
        "  sqdist = torch.sum((u - v) ** 2, dim=-1)\n",
        "  squnorm = torch.sum(u ** 2, dim=-1)\n",
        "  sqvnorm = torch.sum(v ** 2, dim=-1)\n",
        "  x = 1 + 2 * sqdist / ((1 - squnorm) * (1 - sqvnorm)) + 1e-7\n",
        "  z = torch.sqrt(x ** 2 - 1)\n",
        "  return torch.log(x + z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Og_IY6eRelt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "510d32d7-184c-4521-fefb-0e77ad3e1756"
      },
      "source": [
        "_,indices=torch.sort(distances,descending=True)\n",
        "indices\n",
        "mean = torch.mean(embeddings[indices[:50]],dim=0)\n",
        "mean.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([80])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idBN7kS5ebZ1"
      },
      "source": [
        "len(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oe0otXOPg7z0"
      },
      "source": [
        "test_labels = np.array(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHToj9kUTNmm"
      },
      "source": [
        "label_set = np.array(list(set(categories)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfbTB6VHhKci",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ed43b7a-f8f1-4872-8027-4dab3204ec4d"
      },
      "source": [
        "torch.topk(dist_without_grad(model2(test_input_ids[0].to('cuda').reshape(1,-1),test_attention_masks[0].to('cuda').reshape(1,-1)),test_poincare_tensor),3,largest=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.topk(values=tensor([3.1841, 3.1841, 3.1841], device='cuda:0', grad_fn=<TopkBackward>), indices=tensor([839, 682,  15], device='cuda:0'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quvVZFe0TUcO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2cd2e973-559c-412f-e312-180ae7079593"
      },
      "source": [
        "label_set[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'science>>motion and time'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8sPJhJJk_gQ"
      },
      "source": [
        "def precision(actual, predicted, k):\n",
        "    act_set = set(actual)\n",
        "    pred_set = set(predicted[:k])\n",
        "    result = len(act_set & pred_set) / float(k)\n",
        "    return result\n",
        "\n",
        "def recall(actual, predicted, k):\n",
        "    act_set = set(actual)\n",
        "    pred_set = set(predicted[:k])\n",
        "    result = len(act_set & pred_set) / float(len(act_set))\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGXOdjvptHqe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bb1b8959-a8b3-4f19-bce3-500f3fc3e386"
      },
      "source": [
        "test_data['board_syllabus'][20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'computer science[c++]>>c++ revision tour'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UsQfb6tsBmB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24508cf1-85b9-4a67-a35f-33515b3a2341"
      },
      "source": [
        "predictions=[]\n",
        "def dist_without_grad( u, v):\n",
        "  sqdist = torch.sum((u - v) ** 2, dim=-1)\n",
        "  squnorm = torch.sum(u ** 2, dim=-1)\n",
        "  sqvnorm = torch.sum(v ** 2, dim=-1)\n",
        "  x = 1 + 2 * sqdist / ((1 - squnorm) * (1 - sqvnorm)) + 1e-7\n",
        "  z = torch.sqrt(x ** 2 - 1)\n",
        "  return torch.log(x + z)\n",
        "cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "outputs = model(input_ids[20].reshape(1,-1),attention_masks[20].reshape(1,-1))\n",
        "test_poincare_tensor = test_poincare_tensor.to('cuda')\n",
        "distances = (F.normalize(outputs,p=2,dim=1) - F.normalize(test_poincare_tensor,p=2,dim=1)).pow(2).sum(1)\n",
        "print(\"distances\",torch.topk(distances,3,largest=False))\n",
        "print(outputs.shape,test_poincare_tensor.shape)\n",
        "print(cos(outputs,test_poincare_tensor).shape)\n",
        "print(torch.topk(cos(outputs,test_poincare_tensor),5,largest=True))\n",
        "predictions.append(test_labels[indices.cpu().numpy()])\n",
        "predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "distances torch.return_types.topk(\n",
            "values=tensor([1.1455, 1.1635, 1.2580], device='cuda:0', grad_fn=<TopkBackward>),\n",
            "indices=tensor([149, 310, 333], device='cuda:0'))\n",
            "torch.Size([1, 700]) torch.Size([335, 700])\n",
            "torch.Size([335])\n",
            "torch.return_types.topk(\n",
            "values=tensor([0.4272, 0.4182, 0.3710, 0.3655, 0.3589], device='cuda:0',\n",
            "       grad_fn=<TopkBackward>),\n",
            "indices=tensor([149, 310, 333, 289, 292], device='cuda:0'))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array(['science>>tissues', 'science>>control and coordination', 'science',\n",
              "        'science>>forests: our lifeline',\n",
              "        'science>>reaching the age of adolescence', 'science>>gravitation',\n",
              "        'science>>acids, bases and salts', 'science>>force and pressure',\n",
              "        'science>>water', 'science>>soil', 'science>>why do we fall ill?',\n",
              "        'science>>body movements', 'science>>getting to know plants',\n",
              "        'science>>light', 'science>>life processes', 'science>>sound',\n",
              "        'science>>heat', 'science>>friction',\n",
              "        'science>>garbage in, garbage out', 'science>>fibre to fabric'],\n",
              "       dtype='<U116')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6wOPMWKrLqG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "508e72ac-a23b-49cf-8d26-9439fce5aa5a"
      },
      "source": [
        "len(test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "312"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tA-1RvWKfV7C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fda1c505-e8d4-4023-8cc5-0ea329c71e3a"
      },
      "source": [
        "test_poincare_tensor.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([312, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-TfIR41U9WN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b88cbee5-3e20-4c64-a897-9af260ed5f21"
      },
      "source": [
        "len(label_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "312"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPCktQT9DVT4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "283cdd17-b3d4-4769-ed34-ac42df0d1dcd"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(test_input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "\n",
        "input_ids = test_input_ids.to('cuda')\n",
        "attention_masks = test_attention_masks.to('cuda')\n",
        "test_poincare_tensor = test_poincare_tensor.to('cuda')\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "for input_id,attention_mask in zip(input_ids, attention_masks):\n",
        "  with torch.no_grad():\n",
        "    outputs = model(input_id.reshape(1,-1),attention_mask.reshape(1,-1))\n",
        "    \n",
        "  distances = cos(outputs,test_poincare_tensor) #torch.topk(cos(outputs,test_poincare_tensor),20,largest=True)\n",
        "  distances,indices = torch.topk(distances,20,largest=True)\n",
        "  predictions.append(label_set[indices.cpu().numpy()])\n",
        "print(len(predictions))\n",
        "  # max_distance =100000000000000\n",
        "  # label=None\n",
        "  # for index,test_poincare in enumerate(test_poincare_tensor):\n",
        "\n",
        "  #   distance = distanceTo(test_poincare, outputs)\n",
        "  #   if distance < max_distance:\n",
        "  #     max_distance = distance\n",
        "  #     label = index\n",
        "  # predictions.append(labels[label])\n",
        "    \n",
        "# Predict \n",
        "# for batch in prediction_dataloader:\n",
        "#   # Add batch to GPU\n",
        "#   batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "#   # Unpack the inputs from our dataloader\n",
        "#   b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "#   # Telling the model not to compute or store gradients, saving memory and \n",
        "#   # speeding up prediction\n",
        "#   with torch.no_grad():\n",
        "#       # Forward pass, calculate logit predictions\n",
        "#       outputs = model(b_input_ids,b_input_mask)\n",
        "\n",
        "#   logits = outputs\n",
        "#   for logit in logits:\n",
        "#     max_similarity = 0\n",
        "\n",
        "\n",
        "#   # Move logits and labels to CPU\n",
        "#   logits = logits.detach().cpu().numpy()\n",
        "#   label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "#   # Store predictions and true labels\n",
        "#   predictions.append(logits)\n",
        "#   true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')\n",
        "# predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 4,784 test sentences...\n",
            "4784\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNKgkK7-fCcQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5126fc9b-8a77-472a-ade9-ed1935f88a9c"
      },
      "source": [
        "labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 66, 237, 116, ...,  49,   8, 152])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJCr2Bi89Zw5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "841fdea0-021e-48cf-d02b-11ed0d9fe8fc"
      },
      "source": [
        "!pip install tensorflow==1.13.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.13.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/63/a9fa76de8dffe7455304c4ed635be4aa9c0bacef6e0633d87d5f54530c5c/tensorflow-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (92.5MB)\n",
            "\u001b[K     |████████████████████████████████| 92.5MB 44kB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.8.1)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.15.0)\n",
            "Collecting tensorboard<1.14.0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 46.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.3.3)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.18.5)\n",
            "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 43.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.10.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (3.12.4)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.35.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.1.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.33.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.1) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.3.3)\n",
            "Collecting mock>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/cd/74/d72daf8dff5b6566db857cfd088907bb0355f5dd2914c4b3ef065c790735/mock-4.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.13.1) (50.3.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.4.0)\n",
            "Installing collected packages: keras-applications, tensorboard, mock, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed keras-applications-1.0.8 mock-4.0.2 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfr9QGQkKGpx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd320ac8-1119-4084-b3b3-6713179a8e1b"
      },
      "source": [
        "from sklearn .preprocessing import LabelEncoder\n",
        "LE= LabelEncoder()\n",
        "LE.fit_transform(train_data[\"board_syllabus\"].values)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([229, 293, 183, ..., 253, 127, 161])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5wj2gXYFkrQ"
      },
      "source": [
        "labels=test_data['board_syllabus'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOt8hvs-CZfn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0c5a08a-2bff-457e-b491-e39f649f090a"
      },
      "source": [
        "\n",
        "labels = LE.transform(labels)\n",
        "labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 66, 237, 116, ...,  49,   8, 152])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YsAzgxhQPP1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adb4gTNgGKUP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e776d580-5e2a-4bc3-b774-15354712617f"
      },
      "source": [
        "labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 66, 237, 116, ...,  49,   8, 152])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbohQzAhlYRN"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azkCfK-bCoXd"
      },
      "source": [
        "final_predictions = []\n",
        "for prediction in predictions:\n",
        "  final_predictions.append(LE.transform(prediction))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQrlczKxMwzZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "492c3f00-d581-409c-e1e2-c0c4c27a6a0e"
      },
      "source": [
        "final_predictions[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 66,  79,   6,  56, 119])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3T9K5Gd6MMWK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8d05560-347b-4f25-e685-b342df7de196"
      },
      "source": [
        "y_true"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'Identity_44:0' shape=(2664,) dtype=int64>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Is-KTAENfB6C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "791a4b10-382b-4c15-94d4-2c4c4473b268"
      },
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 20\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, k=20)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, k=20)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 20)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    # print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",s|ess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4784, 20) (4784,)\n",
            "update_recall:  0.9423076923076923\n",
            "recall 0.9423076923076923\n",
            "STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4508.0, 276.0, 0.0, 0.0]\n",
            "TMP_RANK:  TopKV2(values=array([[169, 140, 119, ...,  14,   9,   6],\n",
            "       [248, 246, 245, ..., 176, 170, 113],\n",
            "       [246, 245, 243, ..., 124, 116, 104],\n",
            "       ...,\n",
            "       [ 55,  54,  52, ...,  33,  32,  29],\n",
            "       [166, 142, 135, ...,   8,   6,   2],\n",
            "       [225, 166, 152, ...,   4,   3,   1]]), indices=array([[13, 16,  4, ..., 12, 19,  2],\n",
            "       [13, 14,  3, ...,  2, 11, 19],\n",
            "       [17,  7, 11, ...,  9,  0, 19],\n",
            "       ...,\n",
            "       [ 4, 12, 17, ..., 11,  9,  1],\n",
            "       [19, 16, 11, ...,  2, 17,  5],\n",
            "       [ 8,  0,  2, ..., 14,  3,  4]], dtype=int32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kI1jhndp6cEW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f40c300-6269-4bf6-a030-1b8a3606098f"
      },
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 8\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 15)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 15)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 15)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",sess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4784, 15) (4784,)\n",
            "precision 0.06099498327759197\n",
            "update_recall:  0.9149247491638796\n",
            "recall 0.9149247491638796\n",
            "STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4377.0, 407.0, 4377.0, 67383.0]\n",
            "TMP_RANK:  TopKV2(values=array([[169, 119, 118, ...,  56,  14,   6],\n",
            "       [248, 246, 245, ..., 202, 176, 170],\n",
            "       [245, 243, 242, ..., 170, 124, 116],\n",
            "       ...,\n",
            "       [ 55,  54,  50, ...,  33,  32,  29],\n",
            "       [135, 103,  71, ...,   9,   8,   2],\n",
            "       [225, 166, 152, ...,   4,   3,   1]]), indices=array([[13,  4,  8, ...,  3, 12,  2],\n",
            "       [13, 14,  3, ...,  5,  2, 11],\n",
            "       [ 7, 11,  4, ...,  1,  9,  0],\n",
            "       ...,\n",
            "       [ 4, 12, 10, ..., 11,  9,  1],\n",
            "       [11, 13,  9, ...,  0,  2,  5],\n",
            "       [ 8,  0,  2, ..., 14,  3,  4]], dtype=int32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaA9z5n3mZz0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1f587fb-f0be-465e-d862-651bc907532d"
      },
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 8\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 10)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 10)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 10)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",sess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4784, 10) (4784,)\n",
            "precision 0.08584866220735786\n",
            "update_recall:  0.8584866220735786\n",
            "recall 0.8584866220735786\n",
            "STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4107.0, 677.0, 4107.0, 43733.0]\n",
            "TMP_RANK:  TopKV2(values=array([[119, 118, 117, ...,  66,  56,   6],\n",
            "       [245, 243, 237, ..., 221, 202, 176],\n",
            "       [245, 242, 240, ..., 170, 124, 116],\n",
            "       ...,\n",
            "       [ 55,  49,  46, ...,  35,  32,  29],\n",
            "       [ 71,  70,  66, ...,   9,   8,   2],\n",
            "       [225, 166, 152, ...,  11,   3,   1]]), indices=array([[4, 8, 9, ..., 0, 3, 2],\n",
            "       [3, 0, 1, ..., 4, 5, 2],\n",
            "       [7, 4, 8, ..., 1, 9, 0],\n",
            "       ...,\n",
            "       [4, 0, 5, ..., 8, 9, 1],\n",
            "       [9, 7, 8, ..., 0, 2, 5],\n",
            "       [8, 0, 2, ..., 7, 3, 4]], dtype=int32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkKaMSEJnJUX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c9c1924-57a6-4998-ab38-b914ea91a56d"
      },
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 8\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 5)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 5)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 5)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",sess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4784, 5) (4784,)\n",
            "precision 0.14460702341137124\n",
            "update_recall:  0.7230351170568562\n",
            "recall 0.7230351170568562\n",
            "STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3459.0, 1325.0, 3459.0, 20461.0]\n",
            "TMP_RANK:  TopKV2(values=array([[119,  79,  66,  56,   6],\n",
            "       [245, 243, 237, 221, 176],\n",
            "       [242, 227, 176, 170, 116],\n",
            "       ...,\n",
            "       [ 55,  49,  42,  37,  29],\n",
            "       [ 64,  15,  10,   9,   8],\n",
            "       [166, 152, 103,   3,   1]]), indices=array([[4, 1, 0, 3, 2],\n",
            "       [3, 0, 1, 4, 2],\n",
            "       [4, 3, 2, 1, 0],\n",
            "       ...,\n",
            "       [4, 0, 3, 2, 1],\n",
            "       [4, 1, 3, 0, 2],\n",
            "       [0, 2, 1, 3, 4]], dtype=int32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPqYvRNIrRg1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09d536a5-30cd-444b-878e-19720b899dc7"
      },
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 8\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 1)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 1)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 1)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",sess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4784, 1) (4784,)\n",
            "precision 0.4280936454849498\n",
            "update_recall:  0.4280936454849498\n",
            "recall 0.4280936454849498\n",
            "STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2048.0, 2736.0, 2048.0, 2736.0]\n",
            "TMP_RANK:  TopKV2(values=array([[ 66],\n",
            "       [176],\n",
            "       [116],\n",
            "       ...,\n",
            "       [ 49],\n",
            "       [  8],\n",
            "       [152]]), indices=array([[0],\n",
            "       [0],\n",
            "       [0],\n",
            "       ...,\n",
            "       [0],\n",
            "       [0],\n",
            "       [0]], dtype=int32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGbi4DEZkwhh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1da4cea1-95bb-4a08-ca59-ccd817ede6b5"
      },
      "source": [
        "y_true = np.array(labels)\n",
        "final_predictions = np.array(final_predictions).squeeze()\n",
        "final_predictions.shape\n",
        "len(final_predictions[final_predictions==y_true])/len(labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.43415551839464883"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IN1UA_4uBu_S"
      },
      "source": [
        "categories"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdD0JiYgEX4k"
      },
      "source": [
        "!cp /content/model_euclidean_cos.zip \"/content/drive/My Drive/research_lo_content_taxonomy_classification\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_WchmXtDspr"
      },
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (final_data.label.sum(), len(final_data.label), (final_data.label.sum() / len(final_data.label) * 100.0)))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5BoY2hKGb7_"
      },
      "source": [
        "pred =  np.argmax(predictions[0],axis=1).flatten()\n",
        "pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPuK0-vzGp3R"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  # pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  \n",
        "  # Calculate and store the coef for this batch.  \n",
        "  matthews = matthews_corrcoef(np.array(labels[i]), np.array(predictions[i])   )             \n",
        "  matthews_set.append(matthews)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_vxvq7rHlgr"
      },
      "source": [
        "ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n",
        "\n",
        "plt.title('MCC Score per Batch')\n",
        "plt.ylabel('MCC Score (-1 to +1)')\n",
        "plt.xlabel('Batch #')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v48rDl4JHmhv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df36f340-8ae9-41d6-d481-61b7bc086b3c"
      },
      "source": [
        "flat_predictions = np.array(predictions)\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "# flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.array(labels)\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('Total MCC: %.3f' % mcc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total MCC: 0.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MI8-HrJ6MSEk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6320849-0f91-41bf-dd5d-e67a37d860d9"
      },
      "source": [
        "list_bool = (flat_true_labels==flat_predictions)\n",
        "print(list_bool)\n",
        "print(len([i for i, val in enumerate(list_bool) if val]))\n",
        "len(flat_predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[False False False ... False False False]\n",
            "68\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2664"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drJC0xYkHr_8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1a888f5-f796-4afa-d2bb-d386f0538f5a"
      },
      "source": [
        "print('Total MCC: %.3f' % mcc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total MCC: 0.023\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3r6f8jW4BN3j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "071a5587-f337-437a-94ff-4f47b7997a8d"
      },
      "source": [
        "len(flat_predictions[flat_predictions==flat_true_labels])/len(flat_predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlA88cTuvlNA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd4b4d4b-023e-4323-cbd1-59c034cf32ce"
      },
      "source": [
        "flat_predictions[:40]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['social science>>civics : social and political life - ii>>how the state government works',\n",
              "       'physical science>>physical science (chemistry)>>synthetic fibres and plastics>>plastics',\n",
              "       'science>>physical and chemical changes',\n",
              "       'social science>>civics : social and political life - ii>>how the state government works',\n",
              "       'computer science[c++]>>arrays',\n",
              "       'computer science[c++]>>standard library functions',\n",
              "       'computer science[c++]>>inheritance: extending classes',\n",
              "       'computer science[c++]>>inheritance: extending classes',\n",
              "       'science>>reproduction in animals',\n",
              "       'social science>>history : our pasts - iii>>weavers, iron smelter & factory owners',\n",
              "       'social science>>civics : social and political life-i>>key elements of a democratic government',\n",
              "       'science>>materials : metals and non-metals',\n",
              "       'physics>>physics : part - i>>physical world',\n",
              "       'computer science[c++]>>inheritance: extending classes',\n",
              "       'science>>sources of energy',\n",
              "       'science>>materials : metals and non-metals',\n",
              "       'science>>human eye and colourful world',\n",
              "       'science>>human eye and colourful world',\n",
              "       'social science>>civics : social and political life>>judiciary',\n",
              "       'social science>>history : our pasts - i>>vital villages, thriving towns',\n",
              "       'computer science[c++]>>standard library functions',\n",
              "       'science>>the living organisms — characteristics and habitats',\n",
              "       'chemistry>>chemistry : part i>>d and f- block elements',\n",
              "       'social science>>civics : social and political life>>confronting marginalisation',\n",
              "       'science>>how do organisms reproduce?',\n",
              "       'science>>weather, climate and adaptations of animals to climate',\n",
              "       'social science>>political science : democratic politics - i>>what is democracy? why democracy?',\n",
              "       'science>>is matter around us pure',\n",
              "       'social science>>history : our pasts - ii>>the mughal empire',\n",
              "       'science>>sources of energy',\n",
              "       'computer science[c++]>>inheritance: extending classes',\n",
              "       'science>>weather, climate and adaptations of animals to climate',\n",
              "       'physics>>physics : part - i>>laws of motion',\n",
              "       'physics>>physics : part - ii>>mechanical properties of fluids',\n",
              "       'computer science[c++]>>arrays',\n",
              "       'social science>>geography : our environment>>human environment-settlement, transport and communication',\n",
              "       'social science>>civics : social and political life>>confronting marginalisation',\n",
              "       'social science>>history : our pasts - ii>>the mughal empire',\n",
              "       'chemistry>>chemistry : part ii>>the s-block elements',\n",
              "       'science>>improvement in food resources'], dtype='<U102')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qa48dokzvnq8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a7efcd3-1b36-4ade-d198-d11d37163e0a"
      },
      "source": [
        "flat_true_labels[:40]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['social science>>civics : social and political life - ii>>how the state government works',\n",
              "       'science>>electricity and circuits', 'science>>changes around us',\n",
              "       'social science>>civics : social and political life - ii>>understanding advertising',\n",
              "       'computer science[c++]>>programming methodology',\n",
              "       'computer science[c++]>>structured query language',\n",
              "       'computer science[c++]>>object oriented programming',\n",
              "       'computer science[c++]>>general oop concepts',\n",
              "       'science>>how do organisms reproduce?',\n",
              "       'social science>>history : our pasts - iii>>ruling the countryside',\n",
              "       'social science>>civics : social and political life>>the indian constitution',\n",
              "       'physical science>>physical science (chemistry)>>metals and non-metals>>metals',\n",
              "       'physics>>physics : part - i>>motion in straight line',\n",
              "       'computer science[c++]>>structured query language',\n",
              "       'physics>>physics : part - i>>laws of motion',\n",
              "       'social science>>civics : social and political life - ii>>role of the government in health',\n",
              "       'science>>friction',\n",
              "       'physical science>>physical science (physics)>>friction>>friction',\n",
              "       'social science>>history : our pasts - iii>>india after independence',\n",
              "       'social science>>history : our pasts - i>>new questions and ideas',\n",
              "       'computer science[c++]>>c++ revision tour',\n",
              "       'science>>getting to know plants',\n",
              "       'chemistry>>chemistry : part i>>chemical bonding and molecular structure',\n",
              "       'social science>>civics : social and political life>>public facilities',\n",
              "       'science>>getting to know plants',\n",
              "       'science>>forests: our lifeline',\n",
              "       'social science>>political science : democratic politics - i>>democracy in the contemporary world',\n",
              "       'science>>atoms and molecules',\n",
              "       'social science>>history : our pasts - ii>>the mughal empire',\n",
              "       'physics>>sources of energy>>sources of energy',\n",
              "       'computer science[c++]>>classes and objects',\n",
              "       'science>>forests: our lifeline',\n",
              "       'physics>>physics : part - i>>system of particles and rotational motion',\n",
              "       'science>>gravitation', 'computer science[c++]>>boolean algebra',\n",
              "       'social science>>geography : our environment>>air',\n",
              "       'social science>>disaster management - together, towards a safer india-ii>>specific hazards and mitigation',\n",
              "       'social science>>the mughal empire>>the mughal empire',\n",
              "       'chemistry>>chemistry : part i>>classification of elements and periodicity in properties',\n",
              "       'science>>getting to know plants'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlDkbovu0rg5"
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "precision_recall_fscore_support(flat_true_labels, flat_predictions, average='micro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "av3GeuiBHock",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "outputId": "b26059ca-4c1e-4b2e-ff53-d01a08318bb7"
      },
      "source": [
        "precision_recall_fscore_support(flat_true_labels, flat_predictions, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-95-bccf3861f92d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_true_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'flat_true_labels' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKxxgz1AFAkM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "120ff3ec-6c34-465d-8f16-c33b8ab205c1"
      },
      "source": [
        "precision_recall_fscore_support(flat_true_labels, flat_predictions, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.1922086736219466, 0.2357500283089443, 0.18486435529602976, None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "it0TjEdVE-eH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b005a06b-cbc2-4f70-cb8a-1034bb84ffef"
      },
      "source": [
        "precision_recall_fscore_support(flat_true_labels, flat_predictions, average='weighted')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.2265830482911008, 0.26238738738738737, 0.21514243361084723, None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPts-dvGHsZj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4e8016f-dfbf-4e77-e838-705ea6331bd7"
      },
      "source": [
        "precision_recall_fscore_support(flat_true_labels, flat_predictions, average='weighted')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.2265830482911008, 0.26238738738738737, 0.21514243361084723, None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bq9ymZTM3_j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "c0d0fe3a-4aa7-4e88-813b-d5a6b124cfe0"
      },
      "source": [
        "import sys\n",
        "!test -d bertviz_repo && echo \"FYI: bertviz_repo directory already exists, to pull latest version uncomment this line: !rm -r bertviz_repo\"\n",
        "# !rm -r bertviz_repo # Uncomment if you need a clean pull from repo\n",
        "!test -d bertviz_repo || git clone https://github.com/jessevig/bertviz bertviz_repo\n",
        "if not 'bertviz_repo' in sys.path:\n",
        "  sys.path += ['bertviz_repo']\n",
        "!pip install regex"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bertviz_repo'...\n",
            "remote: Enumerating objects: 1074, done.\u001b[K\n",
            "remote: Total 1074 (delta 0), reused 0 (delta 0), pack-reused 1074\u001b[K\n",
            "Receiving objects: 100% (1074/1074), 99.41 MiB | 27.17 MiB/s, done.\n",
            "Resolving deltas: 100% (687/687), done.\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (2019.12.20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yCzNQ6ZBYtI"
      },
      "source": [
        "!7z x model_save.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kbAQwaydsyl"
      },
      "source": [
        "!pip install transformers==3.0.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xV9m2pTXybLf"
      },
      "source": [
        "!pip list | grep transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPpDi44ySCjH"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import BertTokenizer\n",
        "smodel = BertForSequenceClassification.from_pretrained('/content/model_save_categorized_reduced_oct', num_labels = 335,  cache_dir=None, \n",
        "    output_attentions = True, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = True)\n",
        "tokenizer = BertTokenizer.from_pretrained('model_save_categorized_reduced_oct', do_lower_case=True)\n",
        "# model.to(device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gr9EyWoVSZk-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "outputId": "e20c3b84-d6e8-4312-9d4d-d08eb3fe6f67"
      },
      "source": [
        "from bertviz.transformers_neuron_view import BertModel, BertTokenizer\n",
        "from bertviz.neuron_view import show"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-d03fb6cb4ce1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbertviz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformers_neuron_view\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbertviz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneuron_view\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/bertviz_repo/bertviz/transformers_neuron_view/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"1.1.0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtokenization_bert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBasicTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWordpieceTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtokenization_openai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAIGPTTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtokenization_transfo_xl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTransfoXLTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransfoXLCorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtokenization_gpt2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGPT2Tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/bertviz_repo/bertviz/transformers_neuron_view/tokenization_bert.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtokenization_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPreTrainedTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/bertviz_repo/bertviz/transformers_neuron_view/tokenization_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfile_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcached_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/bertviz_repo/bertviz/transformers_neuron_view/file_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mboto3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbotocore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClientError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'boto3'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtPPmu9rcGRV"
      },
      "source": [
        "def call_html():\n",
        "  import IPython\n",
        "  display(IPython.core.display.HTML('''\n",
        "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
        "        <script>\n",
        "          requirejs.config({\n",
        "            paths: {\n",
        "              base: '/static/base',\n",
        "              \"d3\": \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.8/d3.min\",\n",
        "              jquery: '//ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min',\n",
        "            },\n",
        "          });\n",
        "        </script>\n",
        "        '''))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEq2YAbed5Fl"
      },
      "source": [
        "\n",
        "def show_head_view(model, tokenizer, sentence_a, sentence_b=None):\n",
        "    inputs = tokenizer.encode_plus(sentence_a, sentence_b, return_tensors='pt', add_special_tokens=True)\n",
        "    input_ids = inputs['input_ids']\n",
        "    if sentence_b:\n",
        "        token_type_ids = inputs['token_type_ids']\n",
        "        attention = model(input_ids, token_type_ids=token_type_ids)[-1]\n",
        "        sentence_b_start = token_type_ids[0].tolist().index(1)\n",
        "    else:\n",
        "        attention = model(input_ids)[-1]\n",
        "        sentence_b_start = None\n",
        "    input_id_list = input_ids[0].tolist() # Batch index 0\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_id_list)    \n",
        "    head_view(attention, tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oUiRZRdcIFC"
      },
      "source": [
        "sentence_a = \"The cat sat on the mat\"\n",
        "sentence_b = \"The cat lay on the rug\"\n",
        "\n",
        "model_type = 'bert'\n",
        "model_version = 'bert-base-uncased'\n",
        "model.to('cpu')\n",
        "show_head_view(model, tokenizer, sentence_a, sentence_b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2x-6JL3cNPz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}